"1803.03291","Shubho Banerjee","Shubho Banerjee and Blake Wilkerson","Rapidly converging formulae for $\zeta(4k\pm 1)$","16 pages. Submitted for publication",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide rapidly converging formulae for the Riemann zeta function at odd
integers using the Lambert series $\mathscr{L}_q(s) = \sum_{n=1}^\infty n^{s}
q^{n}/(1-q^n)$, $s=-(4k\pm 1)$. Our main formula for $\zeta(4k-1)$ converges at
rate of about $e^{-\sqrt{15}\pi}$ per term, and the formula for $\zeta(4k+1)$,
at the rate of $e^{-4\pi}$ per term. For example, the first order approximation
yields $\zeta(3)\approx\frac{\pi ^3 \sqrt{15}}{100} +e^{-\sqrt{15} \pi
}\left[\frac{9}{4}+\frac{4}{\sqrt{15}}\sinh (\frac{\sqrt{15} \pi }{2})\right]$
which has an error only of order $10^{-10}$.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:50:20 GMT""}]","2018-03-12"
"1803.03582","Moses Kim","Kiyoshi Igusa and Moses Kim","Weighted quivers","11 pages, 2 figures",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A ""weight"" on a quiver $Q$ with values in a group $G$ is a function which
assigns an element of $G$ for each arrow in $Q$. This paper shows that the
essential steps in the mutation of quivers with potential [DWZ] goes through
with weights provided that the weights on each cycle in the potential have
trivial product. This gives another proof of the sign coherence of $c$-vectors.
We also classify all weights on tame quivers.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:02:34 GMT""}]","2018-03-12"
"1803.03583","Daniel Tamas Soukup","D\'aniel T. Soukup","A model with Suslin trees but no minimal uncountable linear orders other
  than $\omega_1$ and $-\omega_1$","19 pages, 4 figures, first public version. Comments are very welcome.
  +minor corrections",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the existence of a Suslin tree does not necessarily imply that
there are uncountable minimal linear orders other than $\omega_1$ and
$-\omega_1$, answering a question of J. Baumgartner. This is done by a
Jensen-type iteration, proving that one can force CH together with a restricted
form of ladder system uniformization on trees, all while preserving a rigid
Suslin tree.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:03:23 GMT""},{""version"":""v2"",""created"":""Mon, 12 Mar 2018 11:27:03 GMT""}]","2018-03-13"
"1803.03584","Brett Morris","Aislynn Wallach, Brett M. Morris, Doug Branton, Teagan O'Reilly,
  Brittany Platt, Ada Beale, Andrew Yetter, Katie Reil, Kristen Garofali, Eric
  Agol","Pre-MAP Search for Transiting Objects Orbiting White Dwarfs","Accepted to RNAAS",,,,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metal pollution in white dwarf atmospheres may be the accreted remnants of
planetary objects. After the discovery of disintegrating planetary objects
transiting WD 1145+017 (Vanderburg et al. 2015), undergraduates in the
University of Washington's Pre- Major in Astronomy Program (Pre-MAP) were
inspired to collect photometry of the brightest white dwarfs to hunt for
similar transiting objects around other metal-polluted white dwarfs. Prior
surveys have yet to make a detection of a transiting planet orbiting a white
dwarf, yet white dwarfs are still an attractive target for searches of small,
rocky planetary material. Since a typical white dwarf is Earth-sized, transits
of Earth-sized planets could have depths >50%, so even low S/N photometry has a
chance at discovering transiting material. We identified bright, northern,
metal-polluted white dwarfs in the SDSS DR10 white dwarf catalog, and observed
five targets with the Astrophysical Research Consortium Small Aperture
Telescope (ARCSAT) 0.5-meter telescope at Apache Point Observatory. The ARCSAT
photometry had sufficient precision to detect Moon-sized objects or larger at
short orbital periods, though no such planets were detected for these targets.
We look forward to surveys which may find planets orbiting white dwarfs, such
as NASA's TESS, ESA's PLATO, and the Evryscope.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:04:03 GMT""}]","2018-03-12"
"1803.03585","Ke Tran","Ke Tran and Arianna Bisazza and Christof Monz","The Importance of Being Recurrent for Modeling Hierarchical Structure","EMNLP 2018",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work has shown that recurrent neural networks (RNNs) can implicitly
capture and exploit hierarchical information when trained to solve common
natural language processing tasks such as language modeling (Linzen et al.,
2016) and neural machine translation (Shi et al., 2016). In contrast, the
ability to model structured data with non-recurrent neural networks has
received little attention despite their success in many NLP tasks (Gehring et
al., 2017; Vaswani et al., 2017). In this work, we compare the two
architectures---recurrent versus non-recurrent---with respect to their ability
to model hierarchical structure and find that recurrency is indeed important
for this purpose.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:13:02 GMT""},{""version"":""v2"",""created"":""Tue, 28 Aug 2018 04:40:49 GMT""}]","2018-08-29"
"1803.03586","Qi Zhang","Qi Zhang, Jianhui Liu, and Guodong Zhao","Towards 5G Enabled Tactile Robotic Telesurgery",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robotic telesurgery has a potential to provide extreme and urgent health care
services and bring unprecedented opportunities to deliver highly specialized
skills globally. It has a significant societal impact and is regarded as one of
the appealing use cases of Tactile Internet and 5G applications. However, the
performance of robotic telesurgery largely depends on the network performance
in terms of latency, jitter and packet loss, especially when telesurgical
system is equipped with haptic feedback. This imposes significant challenges to
design a reliable and secure but cost-effective communication solution. This
article aims to give a better understanding of the characteristics of robotic
telesurgical system, and the limiting factors, the possible telesurgery
services and the communication quality of service (QoS) requirements of the
multi-modal sensory data. Based on this, a viable network architecture enabled
by the converged edge and core cloud is presented and the relevant research
challenges, open issues and enabling technologies in the 5G communication
system are discussed.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:16:42 GMT""}]","2018-03-12"
"1803.03587","Adam Kawash","A. M. Kawash (1 and 2), M. A. McLaughlin (1 and 2), D. L. Kaplan (3),
  M. E. DeCesar (4), L. Levin (5), D. R. Lorimer (1 and 2), R. S. Lynch (6 and
  1), K. Stovall (7), J. K. Swiggum (3), E. Fonseca (8), A. M. Archibald (9 and
  10), S. Banaszak (3), C. M. Biwer (11), J. Boyles (12), B. Cui (1 and 2), L.
  P. Dartez (13), D. Day (13), S. Ernst (14), A. J. Ford (13), J. Flanigan (3),
  S. A. Heatherly (3), J. W. T. Hessels (9 and 10), J. Hinojosa (13), F. A.
  Jenet (13), C. Karako-Argaman (8), V. M. Kaspi (8), V. I. Kondratiev (9 and
  15), S. Leake (13), G. Lunsford (13), J. G. Martinez (16), A. Mata (13), T.
  D. Matheny (1 and 2), A. E. Mcewen (1 and 2), M. G. Mingyar (1 and 2), A. L.
  Orsini (1 and 2), S. M. Ransom (17), M. S. E. Roberts (18), M. D. Rohr (3),
  X. Siemens (3), R. Spiewak (19 and 3), I. H. Stairs (20), J. van Leeuwen (9
  and 10), A. N. Walker (3), B. L. Wells (21 and 3) ((1) Center for
  Gravitational Waves and Cosmology, (2) West Virginia University, (3)
  University of Wisconsin-Milwaukee, (4) Lafayette College, (5) The University
  of Manchester, (6) Green Bank Observatory, (7) National Radio Astronomy
  Observatory, (8) McGill University, (9) ASTRON, (10) University of Amsterdam,
  (11) Syracuse University, (12) Western Kentucky University, (13) University
  of Texas Rio Grande Valley, (14) Morehead State University, (15) Astro Space
  Center of the Lebedev Physical Institute, (16) Max-Planck-Institut f\""u
  Radioastronomie, (17) National Radio Astronomy Observatory, (18) Eureka
  Scientific, Inc., (19) Swinburne University of Technology, (20) University of
  British Columbia, (21) Colorado State University)","The Green Bank Northern Celestial Cap Pulsar Survey II: The Discovery
  and Timing of Ten Pulsars","9 pages, 5 figures",,"10.3847/1538-4357/aab61d",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present timing solutions for ten pulsars discovered in 350 MHz searches
with the Green Bank Telescope. Nine of these were discovered in the Green Bank
Northern Celestial Cap survey and one was discovered by students in the Pulsar
Search Collaboratory program in analysis of drift-scan data. Following
discovery and confirmation with the Green Bank Telescope, timing has yielded
phase-connected solutions with high precision measurements of rotational and
astrometric parameters. Eight of the pulsars are slow and isolated, including
PSR J0930$-$2301, a pulsar with nulling fraction lower limit of $\sim$30\% and
nulling timescale of seconds to minutes. This pulsar also shows evidence of
mode changing. The remaining two pulsars have undergone recycling, accreting
material from binary companions, resulting in higher spin frequencies. PSR
J0557$-$2948 is an isolated, 44 \rm{ms} pulsar that has been partially recycled
and is likely a former member of a binary system which was disrupted by a
second supernova. The paucity of such so-called `disrupted binary pulsars'
(DRPs) compared to double neutron star (DNS) binaries can be used to test
current evolutionary scenarios, especially the kicks imparted on the neutron
stars in the second supernova. There is some evidence that DRPs have larger
space velocities, which could explain their small numbers. PSR J1806+2819 is a
15 \rm{ms} pulsar in a 44 day orbit with a low mass white dwarf companion. We
did not detect the companion in archival optical data, indicating that it must
be older than 1200 Myr.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:26:32 GMT""}]","2018-05-02"
"1803.03588","Alexander Scott","Maria Chudnovsky, Jacob Fox, Alex Scott, Paul Seymour and Sophie
  Spirkl","Towards Erdos-Hajnal for graphs with no 5-hole",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Erdos-Hajnal conjecture says that for every graph $H$ there exists $c>0$
such that $\max(\alpha(G),\omega(G))\ge n^c$ for every $H$-free graph $G$ with
$n$ vertices, and this is still open when $H=C_5$. Until now the best bound
known on $\max(\alpha(G),\omega(G))$ for $C_5$-free graphs was the general
bound of Erdos and Hajnal, that for all $H$, $\max(\alpha(G),\omega(G))\ge
2^{\Omega(\sqrt{\log n })}$ if $G$ is $H$-free. We improve this when $H=C_5$ to
$\max(\alpha(G),\omega(G))\ge 2^{\Omega(\sqrt{\log n \log \log n})}.$
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:29:58 GMT""}]","2018-03-12"
"1803.03589","Raghav Kunnawalkam Elayavalli","Yang-Ting Chien and Raghav Kunnawalkam Elayavalli","Probing heavy ion collisions using quark and gluon jet substructure","36 pages, 20 figures",,,"MIT-CTP 4947, WSU-HEP 1802","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the phenomenon of jet quenching utilizing quark and gluon jet
substructures as independent probes of heavy ion collisions. We exploit jet and
subjet features to highlight differences between quark and gluon jets in vacuum
and in a medium with the jet-quenching model implemented in JEWEL. We begin
with a physics-motivated, multivariate analysis of jet substructure observables
including the jet mass, the radial moments, the $p_T^D$ and the pixel
multiplicity. In comparison, we employ state-of-the-art image-recognition
techniques by training a deep convolutional neutral network on jet images. To
systematically extract jet substructure information, we introduce the
telescoping deconstruction framework exploiting subjet kinematics at multiple
angular scales. We draw connections to the soft-drop subjet distribution and
illuminate medium-induced jet modifications using Lund diagrams. We find that
the quark gluon discrimination performance worsens in heavy ion jets due to
significant soft event activity affecting the soft jet substructure. Our work
suggests a systematically improvable framework for studying modifications to
quark and gluon jet substructures and facilitating direct comparisons between
theoretical calculations, simulations and measurements in heavy ion collisions.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:30:18 GMT""}]","2018-03-12"
"1803.03590","Graeme Weir","Graeme Weir, Catherine Hughes, Stephen M. Barnett, Sarah Croke","Optimal measurement strategies for the trine states with arbitrary prior
  probabilities",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the optimal measurement strategy for state discrimination of
the trine ensemble of qubit states prepared with arbitrary prior probabilities.
Our approach generates the minimum achievable probability of error and also the
maximum confidence strategy. Although various cases with symmetry have been
considered and solution techniques put forward in the literature, to our
knowledge this is only the second such closed form, analytical, arbitrary
prior, example available for the minimum-error figure of merit, after the
simplest and well-known two-state example.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:46:07 GMT""}]","2018-03-12"
"1803.03592","Chandreyee Maitra","C. Maitra, S. Roy, F.Acero and Y. Gupta","Discovery of a radio nebula around PSR J0855-4644","4 pages, 2 figures, accepted for publication in MNRAS Letters",,"10.1093/mnrasl/sly038",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the discovery of a diffuse radio emission around PSR J0855--4644
using an upgraded GMRT (uGMRT) observation at 1.35 GHz. The radio emission is
spatially coincident with the diffuse X-ray pulsar wind nebula (PWN) seen with
XMM but is much larger in extent compared to the compact axisymmetric PWN seen
with Chandra. The morphology of the emission, with a bright partial ring-like
structure and two faint tail-like features strongly resembles a bow shock
nebula, and indicates a velocity of 100 km/s through the ambient medium. We
conclude that the emission is most likely to be associated with the radio PWN
of PSR J0855-4644. From the integrated flux density, we estimate the energetics
of the PWN.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:50:20 GMT""}]","2018-04-04"
"1803.03593","Nima Monshizadeh <","Claudio De Persis, Nima Monshizadeh","A feedback control algorithm to steer networks to a Cournot-Nash
  equilibrium",,"IEEE Transactions on Control of Network Systems, 6(4), 1486-1497,
  2019","10.1109/TCNS.2019.2897907",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a distributed feedback control that steers a dynamical network to
a prescribed equilibrium corresponding to the so-called Cournot-Nash
equilibrium. The network dynamics considered here are a class of passive
nonlinear second-order systems, where production and demands act as external
inputs to the systems. While productions are assumed to be controllable at each
node, the demand is determined as a function of local prices according to the
utility of the consumers. Using reduced information on the demand, the proposed
controller guarantees the convergence of the closed loop system to the optimal
equilibrium point dictated by the Cournot-Nash competition.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:55:26 GMT""}]","2020-01-28"
"1803.03594","Tania Robens","Agnieszka Ilnicka, Tania Robens, Tim Stefaniak","Constraining Extended Scalar Sectors at the LHC and beyond","18 pages, 8 figures; prepared for submission to MPLA (invited review)
  v2: several references and small text modification added to align with
  journal version. 2 small errors in plots corrected","Published in Mod.Phys.Lett. A33 (2018) no.10n11, 1830007","10.1142/S0217732318300070","DESY 18-031","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a brief overview of beyond the Standard Model (BSM) theories with an
extended scalar sector and their phenomenological status in the light of recent
experimental results. We discuss the relevant theoretical and experimental
constraints, and show their impact on the allowed parameter space of two
specific models: the real scalar singlet extension of the Standard Model (SM)
and the Inert Doublet Model. We emphasize the importance of the LHC
measurements, both the direct searches for additional scalar bosons, as well as
the precise measurements of properties of the Higgs boson of mass 125 GeV. We
show the complementarity of these measurements to electroweak and dark matter
observables.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:56:05 GMT""},{""version"":""v2"",""created"":""Sat, 28 Apr 2018 13:28:10 GMT""}]","2018-05-01"
"1803.03595","Justin Feuto","Zobo Vincent de Paul Abl\'e and Justin Feuto","Duals of Hardy-amalgam spaces $\mathcal{H}_{\mathrm{loc}}^{(q,p)}$ and
  Pseudo-differential operators","49 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we carry on with the study of the Hardy-Amalgam spaces
$\mathcal{H}_{\mathrm{loc}}^{(q,p)}$ spaces introduced in \cite{AbFt}. We
investigate their dual spaces and establish some results of boundedness of
pseudo-differential operators in these spaces.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:57:01 GMT""}]","2018-03-12"
"1803.03596","Nikhil Karthik","Nikhil Karthik and Rajamani Narayanan","Parity anomaly cancellation in a three-dimensional QED with single
  massless Dirac fermion","V2: matches the version to be published in PRL","Phys. Rev. Lett. 121, 041602 (2018)","10.1103/PhysRevLett.121.041602",,"hep-lat cond-mat.str-el hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a three-dimensional non-compact QED with a single two-component
massless fermion and two infinitely massive regulator fermions of half the
charge using lattice overlap formalism. The parity anomaly is expected to
cancel exactly between the massless and regulator fermions in the continuum,
but this cancellation is inexact on lattice akin to lattice chiral gauge
theories. We show non-perturbatively that parity-breaking terms vanish in the
continuum limit at any finite volume. We present numerical evidences that the
resulting parity-invariant theory spontaneously breaks parity in the infinite
volume limit.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:59:44 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jun 2018 12:04:48 GMT""}]","2018-08-01"
"1803.03597","Michael Vaiana","Michael Vaiana, Sarah Muldoon","Resolution Limits for Detecting Community Changes in Multilayer Networks",,,,,"physics.soc-ph cs.SI physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multilayer networks capture pairwise relationships between the components of
complex systems across multiple modes or scales of interactions. An important
meso-scale feature of these networks is measured though their community
structure, which defines groups of strongly connected nodes that exist within
and across network layers. Because interlayer edges can describe relationships
between different modalities, scales, or time points, it is essential to
understand how communities change and evolve across layers. A popular method
for detecting communities in multilayer networks consists of maximizing a
quality function known as modularity. However, in the multilayer setting the
modularity function depends on an interlayer coupling parameter, $\omega$, and
how this parameter affects community detection is not well understood. Here, we
expose an upper bound for $\omega$ beyond which community changes across layers
can not be detected. This upper bound has non-trivial, purely multilayer
effects and acts as a resolution limit for detecting evolving communities.
Further, we establish an explicit and previously undiscovered relationship
between the single layer resolution parameter, $\gamma$, and interlayer
coupling parameter, $\omega,$ that provides new understanding of the modularity
parameter space. Our findings not only represent new theoretical considerations
but also have important practical implications for choosing interlayer coupling
values when using multilayer networks to model real-world systems whose
communities change across time or modality.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:00:38 GMT""}]","2018-03-12"
"1803.03598","Michael J. Kurtz","Michael J. Kurtz, Alberto Accomazzi, Edwin A. Henneken","Merging the Astrophysics and Planetary Science Information Systems","Whitepaper submitted to the Committee on an Exoplanet Science
  Strategy",,,,"astro-ph.IM cs.DL physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conceptually exoplanet research has one foot in the discipline of
Astrophysics and the other foot in Planetary Science. Research strategies for
exoplanets will require efficient access to data and information from both
realms. Astrophysics has a sophisticated, well integrated, distributed
information system with archives and data centers which are interlinked with
the technical literature via the Astrophysics Data System (ADS). The
information system for Planetary Science does not have a central component
linking the literature with the observational and theoretical data. Here we
propose that the Committee on an Exoplanet Science Strategy recommend that this
linkage be built, with the ADS playing the role in Planetary Science which it
already plays in Astrophysics. This will require additional resources for the
ADS, and the Planetary Data System (PDS), as well as other international
collaborators
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:05:18 GMT""}]","2018-03-12"
"1803.03599","Alexander Gorban","Alexander N. Gorban","Hilbert's Sixth Problem: the endless road to rigour","With portrait of David Hilbert, Courtesy the artist Anna Gorban","Phil. Trans. R. Soc. A volume 376, issue 2118, 20170238, 2018","10.1098/rsta.2017.0238",,"physics.hist-ph math-ph math.HO math.MP","http://creativecommons.org/licenses/by/4.0/","  Introduction to the special issue of Phil. Trans. R. Soc. A 376, 2018,
`Hilbert's Sixth Problem'. The essence of the Sixth Problem is discussed and
the content of this issue is introduced.
  In 1900, David Hilbert presented 23 problems for the advancement of
mathematical science. Hilbert's Sixth Problem proposed the expansion of the
axiomatic method outside of mathematics, in physics and beyond. Its title was
shocking: ""Mathematical Treatment of the Axioms of Physics."" Axioms of physics
did not exist and were not expected. During further explanation, Hilbert
specified this problem with special focus on probability and ""the limiting
processes, ... which lead from the atomistic view to the laws of motion of
continua"". The programmatic call was formulated ""to treat, by means of axioms,
those physical sciences in which already today mathematics plays an important
part."" This issue presents a modern slice of the work on the Sixth Problem,
from quantum probability to fluid dynamics and machine learning, and from
review of solid mathematical and physical results to opinion pieces with new
ambitious ideas. Some expectations were broken: The continuum limit of
atomistic kinetics may differ from the classical fluid dynamics. The ""curse of
dimensionality"" in machine learning turns into the ""blessing of dimensionality""
that is closely related to statistical physics. Quantum probability facilitates
the modelling of geological uncertainty and hydrocarbon reservoirs. And many
other findings are presented.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:06:23 GMT""}]","2018-03-20"
"1803.03600","Gregorio Malajovich","Gregorio Malajovich and Mike Shub","A theory of NP-completeness and ill-conditioning for approximate real
  computations",,"Journal of the ACM 66(4) Article 27 pp 1-38 (May 2019)","10.1145/3321479",,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a complexity theory for approximate real computations. We first
produce a theory for exact computations but with condition numbers. The input
size depends on a condition number, which is not assumed known by the machine.
The theory admits deterministic and nondeterministic polynomial time
recognizable problems. We prove that P is not NP in this theory if and only if
P is not NP in the BSS theory over the reals.
  Then we develop a theory with weak and strong approximate computations. This
theory is intended to model actual numerical computations that are usually
performed in floating point arithmetic. It admits classes P and NP and also an
NP-complete problem. We relate the P vs NP question in this new theory to the
classical P vs NP problem.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:06:54 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jan 2019 12:17:09 GMT""}]","2020-05-05"
"1803.03601","Yaniv Almog","Yaniv Almog and Bernard Helffer","The spectrum of a Schr\""odinger operator in a wire-like domain with a
  purely imaginary degenerate potential in the semiclassical limit",,,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider a two-dimensional domain shaped like a wire, not necessarily of
uniform cross section. Let $V$ denote an electric potential driven by a voltage
drop between the conducting surfaces of the wire. We consider the operator
${\mathcal A}_h=-h^2\Delta+iV$ in the semi-classical limit $h\to 0$. We obtain
both the asymptotic behaviour of the left margin of the spectrum, as well as
resolvent estimates on the left side of this margin. We extend here previous
results obtained for potentials for which the set where the current (or $\nabla
V$) is normal to the boundary is discrete, in contrast with the present case
where $V$ is constant along the conducting surfaces.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:13:46 GMT""}]","2018-03-12"
"1803.03602","Viswambhara Makam","Harm Derksen and Visu Makam","Weyl's polarization theorem in positive characteristic","17 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $V$ be an $n$-dimensional algebraic representation over an algebraically
closed field $K$ of a group $G$. For $m > 0$, we study the invariant rings
$K[V^{ m}]^G$ for the diagonal action of $G$ on $V^m$. In characteristic zero,
a theorem of Weyl tells us that we can obtain all the invariants in $K[V^m]^G$
by the process of polarization and restitution from $K[V^n]^G$. In particular,
this means that if $K[V^n]^G$ is generated in degree $\leq d$, then so is
$K[V^m]^G$ no matter how large $m$ is.
  There are several explicit counterexamples to Weyl's theorem in positive
characteristic. However, when $G$ is a (connected) reductive affine group
scheme over $\mathbb{Z}$ and $V^*$ is a good $G$-module, we show that Weyl's
theorem holds in sufficiently large characteristic. As a special case, we
consider the ring of invariants $R(n,m)$ for the left-right action of ${\rm
SL}_n \times {\rm SL}_n$ on $m$-tuples of $n \times n$ matrices. In this case,
we show that the invariants of degree $\leq n^6$ suffice to generate $R(n,m)$
if the characteristic is larger than $2n^6 + n^2$.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:14:55 GMT""},{""version"":""v2"",""created"":""Mon, 26 Nov 2018 18:25:35 GMT""}]","2018-11-27"
"1803.03603","Stefanos Papanikolaou","Stefanos Papanikolaou","Learning local, quenched disorder in plasticity and other crackling
  noise phenomena","4 figures",,,,"cond-mat.mtrl-sci cond-mat.dis-nn cond-mat.mes-hall cond-mat.stat-mech nlin.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When far from equilibrium, many-body systems display behavior that strongly
depends on the initial conditions. A characteristic such example is the
phenomenon of plasticity of crystalline and amorphous materials that strongly
depends on the material history. In plasticity modeling, the history is
captured by a quenched, local and disordered flow stress distribution. While it
is this disorder that causes avalanches that are commonly observed during
nanoscale plastic deformation, the functional form and scaling properties have
remained elusive. In this paper, a generic formalism is developed for deriving
local disorder distributions from field-response (e.g. stress/strain)
timeseries in models of crackling noise. We demonstrate the efficiency of the
method in the hysteretic random-field Ising model and also, models of elastic
interface depinning that have been used to model crystalline and amorphous
plasticity. We show that the capacity to resolve the quenched disorder
distribution improves with the temporal resolution and number of samples.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:14:58 GMT""}]","2018-03-12"
"1803.03604","J. R. Brownstein","Michael S. Talbot, Joel R. Brownstein, Adam S. Bolton, Kevin Bundy,
  Brett H. Andrews, Brian Cherinka, Thomas E. Collett, Anupreeta More, Surhud
  More, Alessandro Sonnenfeld, Simona Vegetti, David A. Wake, Anne-Marie
  Weijmans, Kyle B. Westfall","SDSS-IV MaNGA: The Spectroscopic Discovery of Strongly Lensed Galaxies","Accepted for publication in MNRAS, March 8, 2018. In press. 16 pages,
  5 figures, 4 tables",,"10.1093/mnras/sty653",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a catalogue of 38 spectroscopically detected strong galaxy-galaxy
gravitational lens candidates identified in the Sloan Digital Sky Survey IV
(SDSS-IV). We were able to simulate narrow-band images for 8 of them
demonstrating evidence of multiple images. Two of our systems are compound lens
candidates, each with 2 background source-planes. One of these compound systems
shows clear lensing features in the narrow-band image. Our sample is based on
2812 galaxies observed by the Mapping Nearby Galaxies at APO (MaNGA) integral
field unit (IFU). This Spectroscopic Identification of Lensing Objects (SILO)
survey extends the methodology of the Sloan Lens ACS Survey (SLACS) and BOSS
Emission-Line Survey (BELLS) to lower redshift and multiple IFU spectra. We
searched ~ 1.5 million spectra, of which 3065 contained multiple high
signal-to-noise background emission-lines or a resolved [OII] doublet, that are
included in this catalogue. Upon manual inspection, we discovered regions with
multiple spectra containing background emission-lines at the same redshift,
providing evidence of a common source-plane geometry which was not possible in
previous SLACS and BELLS discovery programs. We estimate more than half of our
candidates have an Einstein radius > 1.7"", which is significantly greater than
seen in SLACS and BELLS. These larger Einstein radii produce more extended
images of the background galaxy increasing the probability that a background
emission-line will enter one of the IFU spectroscopic fibres, making detection
more likely.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:16:14 GMT""}]","2018-03-12"
"1803.03607","Emilio Rafael Balda","Emilio Rafael Balda, Arash Behboodi, Rudolf Mathar","On Generation of Adversarial Examples using Convex Programming","Best Student Paper Award in ASILOMAR 2018","ASILOMAR 2018",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been observed that deep learning architectures tend to make erroneous
decisions with high reliability for particularly designed adversarial
instances. In this work, we show that the perturbation analysis of these
architectures provides a framework for generating adversarial instances by
convex programming which, for classification tasks, is able to recover variants
of existing non-adaptive adversarial methods. The proposed framework can be
used for the design of adversarial noise under various desirable constraints
and different types of networks. Moreover, this framework is capable of
explaining various existing adversarial methods and can be used to derive new
algorithms as well. We make use of these results to obtain novel algorithms.
The experiments show the competitive performance of the obtained solutions, in
terms of fooling ratio, when benchmarked with well-known adversarial methods.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:24:45 GMT""},{""version"":""v2"",""created"":""Tue, 27 Mar 2018 11:32:36 GMT""},{""version"":""v3"",""created"":""Tue, 10 Jul 2018 08:33:19 GMT""},{""version"":""v4"",""created"":""Mon, 3 Dec 2018 22:14:52 GMT""}]","2018-12-05"
"1803.03608","Dick Maryopi","Dick Maryopi, Manijeh Bashar and Alister Burr","On The Uplink Throughput of Zero-Forcing in Cell-Free Massive MIMO with
  Coarse Quantization","Accepted for publication in IEEE Transactions on Vehicular Technology",,"10.1109/TVT.2019.2920070",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recently proposed Cell-Free massive MIMO architecture is studied for the
uplink. In contrast to most previous works, joint detection is performed using
global CSI. Therefore, we study strategies for transferring CSI to the CPU
taking into account the fronthaul capacity which limits CSI quantization. Two
strategies for pilot-based CSI acquisition are considered:
estimate-and-quantize and quantize-and-estimate. These are analysed using the
Bussgang decomposition. For a given quantization constraint for the data and
CSI the achievable rate per user with Zero-Forcing is determined. Numerical
results show that quantize-and-estimate (the simpler strategy) is similar to or
better than estimate-and-quantize, especially for 1-bit resolution.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:29:24 GMT""},{""version"":""v2"",""created"":""Fri, 25 May 2018 01:02:06 GMT""},{""version"":""v3"",""created"":""Fri, 15 Feb 2019 11:35:16 GMT""},{""version"":""v4"",""created"":""Wed, 3 Jul 2019 16:05:53 GMT""}]","2019-07-04"
"1803.03609","Gernot Schaller","Sina B\""ohling and Georg Engelhardt and Gloria Platero and Gernot
  Schaller","Thermoelectric performance of topological boundary modes","16 pages, 8 figures, to appear in PRB","Phys. Rev. B 98, 035132 (2018)","10.1103/PhysRevB.98.035132",,"cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate quantum transport and thermoelectrical properties of a
finite-size Su-Schrieffer-Heeger model, a paradigmatic model for a
one-dimensional topological insulator, which displays topologically protected
edge states. By coupling the model to two fermionic reservoirs at its ends, we
can explore the non-equilibrium dynamics of the system. Investigating the
energy-resolved transmission, the current and the noise, we find that these
observables can be used to detect the topologically non-trivial phase. With
specific parameters and asymmetric reservoir coupling strengths, we show that
we can dissipatively prepare the edge states as stationary states of a
non-equilibrium configuration. In addition, we point out that the edge states
can be exploited to design a refrigerator driven by chemical work or a heat
engine driven by a thermal gradient, respectively. These thermal devices do not
require asymmetric couplings and are topologically protected against
symmetry-preserving perturbations. Their maximum efficiencies significantly
exceed that of a single quantum dot device at comparable coupling strengths.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:33:10 GMT""},{""version"":""v2"",""created"":""Mon, 16 Apr 2018 09:29:56 GMT""},{""version"":""v3"",""created"":""Sun, 1 Jul 2018 09:35:43 GMT""}]","2018-07-25"
"1803.03610","Anders Ellersgaard Kal{\o}r","Anders Ellersgaard Kal{\o}r and Osama A. Hanna and Petar Popovski","Random Access Schemes in Wireless Systems With Correlated User Activity","Submitted to SPAWC 2018",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional random access schemes are designed based on the aggregate process
of user activation, which is created on the basis of independent activations of
the users. However, in Machine-Type Communications (MTC), some users are likely
to exhibit a high degree of correlation, e.g. because they observe the same
physical phenomenon. This paves the way to devise access schemes that combine
scheduling and random access, which is the topic of this work. The underlying
idea is to schedule highly correlated users in such a way that their
transmissions are less likely to result in a collision. To this end, we propose
two greedy allocation algorithms. Both attempt to maximize the throughput using
only pairwise correlations, but they rely on different assumptions about the
higher-order dependencies. We show that both algorithms achieve higher
throughput compared to the traditional random access schemes, suggesting that
user correlation can be utilized effectively in access protocols for MTC.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:37:27 GMT""}]","2018-03-12"
"1803.03611","Arun Padakandla","Arun Padakandla and P. R. Kumar and Wojciech Szpankowski","The Trade-off between Privacy and Fidelity via Ehrhart Theory","Submitted to IEEE Transactions on Information Theory","10.1109/TIT.2019.2959976",,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As an increasing amount of data is gathered nowadays and stored in databases
(DBs), the question arises of how to protect the privacy of individual records
in a DB even while providing accurate answers to queries on the DB.
Differential Privacy (DP) has gained acceptance as a framework to quantify
vulnerability of algorithms to privacy breaches. We consider the problem of how
to sanitize an entire DB via a DP mechanism, on which unlimited further
querying is performed. While protecting privacy, it is important that the
sanitized DB still provide accurate responses to queries. The central
contribution of this work is to characterize the amount of information
preserved in an optimal DP DB sanitizing mechanism (DSM). We precisely
characterize the utility-privacy trade-off of mechanisms that sanitize DBs in
the asymptotic regime of large DBs. We study this in an information-theoretic
framework by modeling a generic distribution on the data, and a measure of
fidelity between the histograms of the original and sanitized DBs. We consider
the popular $\mathbb{L}_{1}-$distortion metric that leads to the formulation as
a linear program (LP). This optimization problem is prohibitive in complexity
with the number of constraints growing exponentially in the parameters of the
problem. Leveraging tools from discrete geometry, analytic combinatorics, and
duality theorems of optimization, we fully characterize the optimal solution in
terms of a power series whose coefficients are the number of integer points on
a multidimensional convex polytope studied by Ehrhart in 1967. Employing
Ehrhart theory, we determine a simple closed form computable expression for the
asymptotic growth of the optimal privacy-fidelity trade-off to infinite
precision. At the heart of the findings is a deep connection between the
minimum expected distortion and the Ehrhart series of an integral convex
polytope.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:37:35 GMT""}]","2022-03-02"
"1803.03612","Diego Trancanelli","Carlos Bercini, Diego Trancanelli","Supersymmetric integrable theories from no particle production","14 pages, 9 figures; v2: minor changes, reference added","Phys. Rev. D 97, 105013 (2018)","10.1103/PhysRevD.97.105013",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a theory of scalar superfields in two dimensions with arbitrary
superpotential. By imposing no particle production in tree level scattering, we
constrain the form of the admissible interactions, recovering a supersymmetric
extension of the sinh-Gordon model.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:39:45 GMT""},{""version"":""v2"",""created"":""Mon, 30 Apr 2018 22:14:07 GMT""}]","2018-05-23"
"1803.03613","Pascal Sch\""ottle","Pascal Sch\""ottle, Alexander Schl\""ogl, Cecilia Pasquini, and Rainer
  B\""ohme","Detecting Adversarial Examples - A Lesson from Multimedia Forensics","Submitted to EUSIPCO 2018, Special Session on Adversarial Multimedia
  Forensics",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial classification is the task of performing robust classification in
the presence of a strategic attacker. Originating from information hiding and
multimedia forensics, adversarial classification recently received a lot of
attention in a broader security context. In the domain of machine
learning-based image classification, adversarial classification can be
interpreted as detecting so-called adversarial examples, which are slightly
altered versions of benign images. They are specifically crafted to be
misclassified with a very high probability by the classifier under attack.
Neural networks, which dominate among modern image classifiers, have been shown
to be especially vulnerable to these adversarial examples.
  However, detecting subtle changes in digital images has always been the goal
of multimedia forensics and steganalysis. In this paper, we highlight the
parallels between these two fields and secure machine learning.
  Furthermore, we adapt a linear filter, similar to early steganalysis methods,
to detect adversarial examples that are generated with the projected gradient
descent (PGD) method, the state-of-the-art algorithm for this task. We test our
method on the MNIST database and show for several parameter combinations of PGD
that our method can reliably detect adversarial examples.
  Additionally, the combination of adversarial re-training and our detection
method effectively reduces the attack surface of attacks against neural
networks. Thus, we conclude that adversarial examples for image classification
possibly do not withstand detection methods from steganalysis, and future work
should explore the effectiveness of known techniques from multimedia forensics
in other adversarial settings.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:40:20 GMT""}]","2018-03-12"
"1803.03614","Patrick Schulte M. Sc.","Patrick Schulte, Fabian Steiner","Divergence-Optimal Fixed-to-Fixed Length Distribution Matching With
  Shell Mapping","accepted for IEEE Wireless Communication Letters",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distribution matching (DM) transforms independent and Bernoulli(1/2)
distributed bits into a sequence of output symbols with a desired distribution.
A fixed-to-fixed length, invertible DM architecture based on shell mapping is
presented. It is shown that shell mapping for distribution matching (SMDM) is
the optimum DM for the informational divergence metric and that finding energy
optimal sequences is a special case of divergence minimization. Additionally,
it is shown how to find the required shell mapping weight function to
approximate arbitrary output distributions. SMDM is combined with probabilistic
amplitude shaping (PAS) to operate close to the Shannon limit. SMDM exhibits
excellent performance for short blocklengths as required by ultra-reliable
low-latency (URLLC) applications. SMDM outperforms constant composition DM
(CCDM) by 0.6 dB when used with 64-QAM at a spectral efficiency of 3
bits/channel use and a 5G low-density parity-check code with a short
blocklength of 192 bits
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:42:54 GMT""},{""version"":""v2"",""created"":""Thu, 13 Dec 2018 09:31:33 GMT""}]","2018-12-14"
"1803.03615","Nils A. Nilsson","Nils A. Nilsson and Ewa Czuchry","Ho\v{r}ava-Lifshitz cosmology in light of new data","Added comments and clarifications as per the referee's suggestions.
  Accepted for publication in Physics of the Dark Universe","Physics of the Dark Universe 23C (2019) 100253","10.1016/j.dark.2018.100253",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new observational constraints on Lorentz violating
Ho\v{r}ava-Lifshitz cosmological scenarios using an updated cosmological data
set from Cosmic Microwave Background (Planck CMB), expansion rates of
elliptical and lenticular galaxies, JLA compilation (Joint Light-Curve
Analysis) data for Type Ia supernovae (SneIa), Baryon Acoustic Oscillations
(BAO) and priors on the Hubble parameter with an alternative parametrisation of
the equations. Unlike in other approaches we consider the curvature parameter
$\Omega_k$ as a free parameter in the analysis we considered the parameters
$\Omega_k$ and $\Delta N_\nu$ as completely free, which helped to place new,
updated bounds on several of the theory parameters. Remarkably, the detailed
balance scenario exhibits positive spatial curvature to more than 3$\sigma$,
whereas for further theory generalizations we found evidence for positive
spatial curvature at 1$\sigma$. This could create circumstantial evidence from
observations and could be used to single out distinct formulations and
scenarios.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:43:25 GMT""},{""version"":""v2"",""created"":""Mon, 16 Apr 2018 10:11:46 GMT""},{""version"":""v3"",""created"":""Fri, 28 Dec 2018 09:12:29 GMT""}]","2018-12-31"
"1803.03616","Yuanzhang Xiao","Yuanzhang Xiao and Yin Sun","A Dynamic Jamming Game for Real-Time Status Updates","7 pages, 3 figures, INFOCOM 2018 Workshop on Age of Information",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study timely status updates of a real-time system in an adversarial
setting. The system samples a physical process, and sends the samples from the
source (e.g., a sensor) to the destination (e.g, a control center) through a
channel. For real-time monitoring/control tasks, it is crucial for the system
to update the status of the physical process ""timely"". We measure the
timeliness of status updates by the time elapsed since the latest update at the
destination was generated at the source, and define the time elapsed as age of
information, or age in short. To sabotage the system, an attacker aims to
maximize the age by jamming the channel and hence causing delay in status
updates. The system aims to minimize the age by judiciously choosing when to
sample and send the updates. We model the ongoing repeated interaction between
the attacker and the system as a dynamic game. In each stage game, the attacker
chooses the jamming time according to the jamming time distribution, and the
system responds by delaying the sampling according to the sampling policy. We
prove that there exists a unique stationary equilibrium in the game, and
provide a complete analytical characterization of the equilibrium. Our results
shed lights on how the attacker sabotages the system and how the system should
defend against the attacker.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:47:06 GMT""}]","2018-03-12"
"1803.03617","Michele Celebrano","Michele Celebrano, Andrea Locatelli, Lavinia Ghirardini, Giovanni
  Pellegrini, Paolo Biagioni, Attilio Zilli, Xiaofei Wu, Swen Grossmann, Luca
  Carletti, Costantino De Angelis, Lamberto Du\`o, Bert Hecht, Marco Finazzi","Evidence for cascaded third harmonic generation in non-centrosymmetric
  gold nanoantennas","25 pages, 4 figures",,"10.1021/acs.nanolett.9b02427",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The optimization of nonlinear optical processes at the nanoscale is a crucial
step for the development of nanoscale photon sources for quantum-optical
networks. The development of innovative plasmonic nanoantenna designs and
hybrid nanostructures to enhance optical nonlinearities in very small volumes
represents one of the most promising routes. In such systems, the upconversion
of photons can be achieved with high efficiencies via third-order processes,
such as third harmonic generation (THG), thanks to the resonantly-enhanced
volume currents. Conversely, second-order processes, such as second harmonic
generation (SHG), are often inhibited by the symmetry of metal lattices and of
common nanoantenna geometries. SHG and THG processes in plasmonic
nanostructures are generally treated independently, since they both represent a
small perturbation in the light-matter interaction mechanisms. In this work, we
demonstrate that this paradigm does not hold in general, by providing evidence
of a cascaded process in THG, which is fueled by SHG and sizably contributes to
the overall yield. We address this mechanism by unveiling an anomalous
fingerprint in the polarization state of the nonlinear emission from
non-centrosymmetric gold nanoantennas and point out that such cascaded
processes may also appear for structures that exhibit only moderate SHG yields
- signifying its general relevance in plasmon-enhanced nonlinear optics. The
presence of this peculiar mechanism in THG from plasmonic nanoantennas at
telecommunication wavelengths allows gaining further insight on the physics of
plasmon-enhanced nonlinear optical processes. This could be crucial in the
realization of nanoscale elements for photon conversion and manipulation
operating at room-temperature.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:47:42 GMT""},{""version"":""v2"",""created"":""Tue, 2 Jul 2019 17:24:54 GMT""}]","2019-10-23"
"1803.03618","Uygar Sasmaz","A. Bing\""ul, U. \c{S}a\c{s}maz, A. J. Beddall","A Ranking Method For Selection Of $\Eta$ Mesons In High Multiplicity
  Events",,,"10.5506/APhysPolB.49.727",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The selection of $\eta$ mesons with a high efficiency and a high purity can
be important in the formation of statistically significant invariant mass
spectra in the reconstruction of short-lived particles such as $\eta'
\rightarrow \pi^{+} \pi^{-} \eta$. In this study, a cut-based standard method
and a Ranking method to reduce combinatorial background in the reconstruction
of $\eta \rightarrow \gamma \gamma$ decays in high multiplicity hadronic events
are presented. By using recorded ALEPH data and fully simulated events, the
performances of the methods are compared. Results show that the Ranking method
yields significant improvements in the purity of the selected $\eta$ meson
relative to the standard method.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:49:59 GMT""}]","2018-05-23"
"1803.03619","Geza Kovacs","Geza Kovacs","Signature of non-isotropic distribution of stellar rotation inclination
  angles in the Praesepe cluster","Accepted for publication in Astronomy & Astrophysics: 5 pages with 4
  figures",,"10.1051/0004-6361/201731355",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The distribution of the stellar rotation axes of 113 main sequence stars in
the open cluster Praesepe are examined by using current photometric rotation
periods, spectroscopic rotation velocities, and estimated stellar radii. Three
different samples of stellar rotation data on spotted stars from the Galactic
field and two independent samples of planetary hosts are used as control
samples to support the consistency of the analysis. Considering the high
completeness of the Praesepe sample and the behavior of the control samples, we
find that the main sequence F - K stars in this cluster are susceptible to
rotational axis alignment. Using a cone model, the most likely inclination
angle is 76+/-14 degrees with a half opening angle of 47+/-24 degrees.
Non-isotropic distribution of the inclination angles is preferred over the
isotropic distribution, except if the rotation velocities used in this work are
systematically overestimated. We found no indication of this being the case on
the basis of the currently available data.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 17:53:43 GMT""}]","2018-05-02"
"1803.03620","Lalith Suresh","Lalith Suresh, Dahlia Malkhi, Parikshit Gopalan, Ivan Porto Carreiro,
  Zeeshan Lokhandwala","Stable and Consistent Membership at Scale with Rapid","15 pages",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the design and evaluation of Rapid, a distributed membership
service. At Rapid's core is a scheme for multi-process cut detection (CD) that
revolves around two key insights: (i) it suspects a failure of a process only
after alerts arrive from multiple sources, and (ii) when a group of processes
experience problems, it detects failures of the entire group, rather than
conclude about each process individually. Implementing these insights
translates into a simple membership algorithm with low communication overhead.
  We present evidence that our strategy suffices to drive unanimous detection
almost-everywhere, even when complex network conditions arise, such as one-way
reachability problems, firewall misconfigurations, and high packet loss.
Furthermore, we present both empirical evidence and analyses that proves that
the almost-everywhere detection happens with high probability. To complete the
design, Rapid contains a leaderless consensus protocol that converts
multi-process cut detections into a view-change decision. The resulting
membership service works both in fully decentralized as well as logically
centralized modes.
  We present an evaluation of Rapid in moderately scalable cloud settings.
Rapid bootstraps 2000 node clusters 2-5.8x faster than prevailing tools such as
Memberlist and ZooKeeper, remains stable in face of complex failure scenarios,
and provides strong consistency guarantees. It is easy to integrate Rapid into
existing distributed applications, of which we demonstrate two.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:05:02 GMT""}]","2018-03-12"
"1803.03621","Daniel Stilck Franca","Daniel Stilck Fran\c{c}a, Anna-Lena Hashagen","Approximate Randomized Benchmarking for Finite Groups","36 pages, 2 figures, close to published version","Journal of Physics A: Mathematical and Theoretical, 2018","10.1088/1751-8121/aad6fa",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate randomized benchmarking in a general setting with quantum
gates that form a representation, not necessarily an irreducible one, of a
finite group. We derive an estimate for the average fidelity, to which
experimental data may then be calibrated. Furthermore, we establish that
randomized benchmarking can be achieved by the sole implementation of quantum
gates that generate the group as well as one additional arbitrary group
element. In this case, we need to assume that the noise is close to being
covariant. This yields a more practical approach to randomized benchmarking.
Moreover, we show that randomized benchmarking is stable with respect to
approximate Haar sampling for the sequences of gates. This opens up the
possibility of using Markov chain Monte Carlo methods to obtain the random
sequences of gates more efficiently. We demonstrate these results numerically
using the well-studied example of the Clifford group as well as the group of
monomial unitary matrices. For the latter, we focus on the subgroup with
nonzero entries consisting of n-th roots of unity, which contains T gates.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:11:42 GMT""},{""version"":""v2"",""created"":""Tue, 14 Aug 2018 09:40:48 GMT""}]","2019-01-23"
"1803.03622","Matthias Rost","Matthias Rost and Stefan Schmid","Virtual Network Embedding Approximations: Leveraging Randomized Rounding","Extended version of our paper which will be presented at IFIP
  Networking 2018; v2 is a major revision of v1 and includes the results of our
  computational evaluation",,,,"cs.NI cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Virtual Network Embedding Problem (VNEP) captures the essence of many
resource allocation problems of today's infrastructure providers, which offer
their physical computation and networking resources to customers. Customers
request resources in the form of Virtual Networks, i.e. as a directed graph
which specifies computational requirements at the nodes and communication
requirements on the edges. An embedding of a Virtual Network on the shared
physical infrastructure is the joint mapping of (virtual) nodes to physical
servers together with the mapping of (virtual) edges onto paths in the physical
network connecting the respective servers.
  This work initiates the study of approximation algorithms for the VNEP.
Concretely, we study the offline setting with admission control: given multiple
request graphs the task is to embed the most profitable subset while not
exceeding resource capacities. Our approximation is based on the randomized
rounding of Linear Programming (LP) solutions. Interestingly, we uncover that
the standard LP formulation for the VNEP exhibits an inherent structural
deficit when considering general virtual network topologies: its solutions
cannot be decomposed into valid embeddings. In turn, focusing on the class of
cactus request graphs, we devise a novel LP formulation, whose solutions can be
decomposed into convex combinations of valid embedding. Proving performance
guarantees of our rounding scheme, we obtain the first approximation algorithm
for the VNEP in the resource augmentation model.
  We propose two types of rounding heuristics and evaluate their performance in
an extensive computational study. Our results indicate that randomized rounding
can yield good solutions (even without augmentations). Specifically, heuristic
rounding achieves 73.8% of the baseline's profit, while not exceeding
capacities.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:15:31 GMT""},{""version"":""v2"",""created"":""Fri, 4 May 2018 12:05:44 GMT""}]","2018-05-07"
"1803.03623","Cong Feng","Cong Feng and Jie Zhang","Hourly-Similarity Based Solar Forecasting Using Multi-Model Machine
  Learning Blending","2018 IEEE PES General Meeting",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  With the increasing penetration of solar power into power systems,
forecasting becomes critical in power system operations. In this paper, an
hourly-similarity (HS) based method is developed for 1-hour-ahead (1HA) global
horizontal irradiance (GHI) forecasting. This developed method utilizes diurnal
patterns, statistical distinctions between different hours, and hourly
similarities in solar data to improve the forecasting accuracy. The HS-based
method is built by training multiple two-layer multi-model forecasting
framework (MMFF) models independently with the same-hour subsets. The final
optimal model is a combination of MMFF models with the best-performed blending
algorithm at every hour. At the forecasting stage, the most suitable model is
selected to perform the forecasting subtask of a certain hour. The HS-based
method is validated by 1-year data with six solar features collected by the
National Renewable Energy Laboratory (NREL). Results show that the HS-based
method outperforms the non-HS (all-in-one) method significantly with the same
MMFF architecture, wherein the optimal HS- based method outperforms the best
all-in-one method by 10.94% and 7.74% based on the normalized mean absolute
error and normalized root mean square error, respectively.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:17:52 GMT""}]","2018-03-12"
"1803.03624","Aleksander Kurek","A. R. Kurek, A. Stachowski, K. Banaszek, A. Pollo","The usability of the optical parametric amplification of light for
  high-angular-resolution imaging and fast astrometry","Received: 11 November 2017, revision received: 31 January 2018,
  accepted: 31 January 2018","MNRAS, vol. 476, iss. 2, p. 1696-1704 (11 May 2018)","10.1093/mnras/sty307",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-angular-resolution imaging is crucial for many applications in modern
astronomy and astrophysics. The fundamental diffraction limit constrains the
resolving power of both ground-based and spaceborne telescopes. The recent idea
of a quantum telescope based on the optical parametric amplification (OPA) of
light aims to bypass this limit for the imaging of extended sources by an order
of magnitude or more. We present an updated scheme of an OPA-based device and a
more accurate model of the signal amplification by such a device. The
semiclassical model that we present predicts that the noise in such a system
will form so-called light speckles as a result of light interference in the
optical path. Based on this model, we analysed the efficiency of OPA in
increasing the angular resolution of the imaging of extended targets and the
precise localization of a distant point source. According to our new model, OPA
offers a gain in resolved imaging in comparison to classical optics. For a
given time-span, we found that OPA can be more efficient in localizing a single
distant point source than classical telescopes.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:18:27 GMT""}]","2018-03-12"
"1803.03625","Ana Cecilia Soja","Ana Cec\'ilia Soja, Laerte Sodr\'e Jr, Rog\'erio Monteiro-Oliveira,
  Eduardo Serra Cypriano and Gast\~ao Lima Neto","A Gemini view of the galaxy cluster RXC J1504-0248: insights on the
  nature of the central gaseous filaments","13 pages, 12 figures - Accepted for publication in MNRAS in 2018
  March 07",,"10.1093/mnras/sty638",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the galaxy cluster RXC J1504-0248, a remarkable example of a
structure with a strong cool core in a near redshift ($z = 0.216$). We
performed a combined analysis using photometric and spectroscopic data obtained
at Gemini South Telescope. We estimated the cluster mass through gravitational
lensing, obtaining $M_{200} = 5.3\pm0.4 \times 10^{14}$ $h_{70}^{-1}$ M$_\odot$
within $R_{200} = 1.56 \pm 0.04$ $h^{-1}_{70}$ Mpc, in agreement with a virial
mass estimate. This cluster presents a prominent filamentary structure
associated to its BCG, located mainly along its major axis and aligned with the
X-ray emission. A combined study of three emission line diagnostic diagrams has
shown that the filament emission falls in the so-called transition region of
these diagrams. Consequently, several ionizing sources should be playing an
meaningful role. We have argued that old stars, often invoked to explain LINER
emission, should not be the major source of ionization. We have noticed that
most of the filamentary emission has line ratios consistent with the shock
excitation limits obtained from shock models. We also found that line fluxes
are related to gas velocities (here estimated from line widths) by power-laws
with slopes in the range expected from shock models. These models also show,
however, that only ~10% of H$\alpha$ luminosity can be explained by shocks. We
conclude that shocks probably associated to the cooling of the intracluster gas
in a filamentary structure may indeed be contributing to the filament nebular
emission, but can not be the major source of ionizing photons.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:25:11 GMT""}]","2018-06-26"
"1803.03626","Maria Gamal'","Maria Gamal'","Examples of cyclic polynomially bounded operators that are not similar
  to contractions, II","Submitted to Acta Sci. Math. (Szeged). Lemma 2.3 is improved, Lemma
  2.5 is added, misprint in the proof of Lemma 2.12 (old 2.11) is corrected.
  Improved Sec. 4 will appear separately",,"10.14232/actasm-018-797-y",,"math.FA","http://creativecommons.org/licenses/by-sa/4.0/","  The question if polynomially bounded operator is similar to a contraction was
posed by Halmos and was answered in the negative by Pisier. His counterexample
is an operator of infinite multiplicity, while all its restrictions on
invariant subspaces of finite multiplicity are similar to contractions. In
[G16], cyclic polynomially bounded operators which are not similar to
contractions was constructed. The construction was based on a perturbation of
the sequence of finite dimensional operators which is uniformly polynomially
bounded, but is not uniformly completely polynomially bounded, constructed by
Pisier. In this paper, a cyclic polynomially bounded operator $T_0$ such that
$T_0$ is not similar to a contraction and $\omega_a(T_0)=\mathbb O$, is
constructed. Here $\omega_a(z)=\exp(a\frac{z+1}{z-1})$, $z\in\mathbb D$, $a>0$,
and $\mathbb D$ is the open unit disk. To obtain such $T_0$, a slight
modification of the construction from [G16] is needed.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:25:12 GMT""},{""version"":""v2"",""created"":""Tue, 15 May 2018 19:38:30 GMT""}]","2019-06-03"
"1803.03627","Marcela Svarc","Lucas Fernandez-Piana and Marcela Svarc","A local depth measure for general data",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the Integrated Dual Local Depth which is a local depth measure
for data in a Banach space based on the use of one-dimensional projections. The
properties of a depth measure are analyzed under this setting and a proper
definition of local symmetry is given. Moreover, strong consistency results for
the local depth and also for the local depth regions are attained. Finally,
applications to descriptive data analysis and classification are analyzed,
making the special focus on multivariate functional data, where we obtain very
promising results.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:27:22 GMT""},{""version"":""v2"",""created"":""Tue, 3 Jul 2018 18:21:27 GMT""},{""version"":""v3"",""created"":""Mon, 28 Dec 2020 22:00:05 GMT""}]","2021-01-01"
"1803.03628","Ulrich Breunig","Ulrich Breunig, Roberto Baldacci, Richard F. Hartl, Thibaut Vidal","The Electric Two-echelon Vehicle Routing Problem",,,"10.1016/j.cor.2018.11.005",,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-echelon distribution systems are attractive from an economical standpoint
and help to keep large vehicles out of city centers. Large trucks can be used
to deliver goods to intermediate facilities in accessible locations, whereas
smaller vehicles allow to reach the final customers. Due to their reduced size
and emissions, companies consider using an electric fleet of terrestrian or
aerial vehicles for last mile deliveries. Route planning in multi-tier
logistics leads to notoriously difficult problems. This difficulty is accrued
in the presence of an electric fleet, since each vehicle operates on a smaller
range, and may require visits to charging stations. To study these challenges,
we introduce the Electric Two-echelon Vehicle Routing Problem as a prototypical
problem. We propose a large neighbourhood search metaheuristic as well as an
exact mathematical programming algorithm, which uses decomposition techniques
to enumerate promising first-level solutions, in conjunction with bounding
functions and route enumeration for the second-level routes. These algorithms
produce optimal or near-optimal solutions for the problem, and allow us to
evaluate the impact of several defining features of optimized battery-powered
distribution networks. We created representative E2EVRP benchmark instances to
simulate realistic metropolitan areas. In particular, we observe that the
detour miles due to recharging decrease proportionally to $1/\rho^x$ with $x
\approx 5/4$ as a function of the charging stations density $\rho$; e.g., in a
scenario where the density of charging stations is doubled, recharging detours
are reduced by 58\%. Finally, we evaluate the trade-off between battery
capacity and detour miles. This estimate is critical for strategic
fleet-acquisition decisions, in a context where large batteries are generally
more costly and less environment-friendly.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:28:17 GMT""},{""version"":""v2"",""created"":""Sun, 15 Jul 2018 10:55:01 GMT""},{""version"":""v3"",""created"":""Thu, 15 Nov 2018 13:59:09 GMT""}]","2018-11-16"
"1803.03629","Alessandro Strumia","Guido D'Amico, Paolo Panci, Alessandro Strumia","Bounds on Dark Matter annihilations from 21 cm data","8 pages. v2: improved treatment of energy deposition","Phys. Rev. Lett. 121, 011103 (2018)","10.1103/PhysRevLett.121.011103","CERN-TH-2018-052, IFUP-TH/2018","astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The observation of an absorption feature in the 21 cm spectrum at redshift
$z\approx 17$ implies bounds on Dark Matter annihilations for a broad range of
masses, given that significant heating of the intergalactic medium would have
erased such feature. The resulting bounds on the DM annihilation cross sections
are comparable to the strongest ones from all other observables.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:31:11 GMT""},{""version"":""v2"",""created"":""Tue, 24 Apr 2018 17:18:20 GMT""}]","2018-07-11"
"1803.03630","Yannick Klein","Yannick Klein, Michele Casula, David Santos-Cottin, Alain Audouard,
  David Vignolles, Gwendal F\`eve, Vincent Freulon, Bernard Pla\c{c}ais, Marine
  Verseils, Hancheng Yang, Lorenzo Paulatto, Andrea Gauzzi","Importance of non-local electron correlations in BaNiS$_{2}$ semimetal
  from quantum oscillations studies","8 figures","Physical Review B 97, 075140 (2018)","10.1103/PhysRevB.97.075140",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By means of Shubnikov-de-Haas and de-Haas-van-Alphen oscillations, and ab
initio calculations, we have studied the Fermi surface of high-quality
BaNiS$_2$ single crystals, with mean free path $l \sim 400 ~\text{\AA}$. The
angle and temperature dependence of quantum oscillations indicates a
quasi-two-dimensional Fermi surface, made of an electron-like tube centred at
$\Gamma$, and of 4 hole-like cones, generated by Dirac bands, weakly dispersive
in the out-of-plane direction. Ab initio electronic structure calculations, in
the density functional theory framework, show that the inclusion of screened
exchange is necessary to account for the experimental Fermi pockets. Therefore,
the choice of the functional becomes crucial. A modified HSE hybrid functional
with 7% of exact exchange outperforms both GGA and GGA+U density functionals,
signalling the importance of non-local screened-exchange interactions in
BaNiS$_2$, and, more generally, in $3d$ compensated semimetals.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:32:34 GMT""}]","2018-03-12"
"1803.03631","Alexander Simakin G.","A. G. Simakin, A. Ghassemi","Mechanics of magma chamber with the implication of the effect of CO2
  fluxing","Chapter to be published, 33 pages, 9 figures",,,,"physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the magma ascends from its depth of generation to the surface, it is often
stored in a series of chambers along the way. The rheological contrast between
the viscous magma in the magmatic chambers and the surrounding rocks disturbed
the stress field which can give rise to various modes of rock failure at
magmatic pressures less than the lithostatic stress, leading to an eruption.
Different modes of mechanical failure of the chamber walls are considered
depending on the geometry and the sign the relative pressure. Relaxation of
viscous stress around magmatic chambers, which is important on the time scale
of weeks to months is considered in the analysis of stability with application
to both large and extra-large magmatic chambers such as Yellowstone. The
effects of a strong deep CO2 flux in Yellowstone are considered in detail. The
analysis shows that variations in the flow rate around the observed mean value
of 40 kg/m2/yr in the hydrothermally active areas can change the composition of
the magma for several hundred thousand years, and cause periodic uplift and
subsidence of the caldera surface with a period of several decades.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:43:12 GMT""}]","2018-03-12"
"1803.03632","Marcin Bownik","Marcin Bownik, Marcin Szyszkowski","Measurable selector in Kadison's carpenter's theorem",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show the existence of a measurable selector in Carpenter's Theorem due to
Kadison. This solves a problem posed by Jasper and the first author. As an
application we obtain a characterization of all possible spectral functions of
shift-invariant subspaces of $L^2(\mathbb R^d)$ and Carpenter's Theorem for
type I$_\infty$ von Neumann algebras.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:45:55 GMT""}]","2018-03-12"
"1803.03633","Alice Bernamonti","Alice Bernamonti, Federico Galli, Robert C. Myers and Jonathan
  Oppenheim","Holographic second laws of black hole thermodynamics","81 pages, 19 figures; v2: clarifications and reference added, minor
  typos corrected, published version",,"10.1007/JHEP07(2018)111",,"hep-th gr-qc quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, it has been shown that for out-of-equilibrium systems, there are
additional constraints on thermodynamical evolution besides the ordinary second
law. These form a new family of second laws of thermodynamics, which are
equivalent to the monotonicity of quantum R\'enyi divergences. In black hole
thermodynamics, the usual second law is manifest as the area increase theorem.
Hence one may ask if these additional laws imply new restrictions for
gravitational dynamics, such as for out-of-equilibrium black holes? Inspired by
this question, we study these constraints within the AdS/CFT correspondence.
First, we show that the R\'enyi divergence can be computed via a Euclidean path
integral for a certain class of excited CFT states. Applying this construction
to the boundary CFT, the R\'enyi divergence is evaluated as the renormalized
action for a particular bulk solution of a minimally coupled gravity-scalar
system. Further, within this framework, we show that there exist transitions
which are allowed by the traditional second law, but forbidden by the
additional thermodynamical constraints. We speculate on the implications of our
findings.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:46:29 GMT""},{""version"":""v2"",""created"":""Tue, 9 Oct 2018 16:31:06 GMT""}]","2018-10-10"
"1803.03634","Marcin Bownik","Marcin Bownik, Karol Dziedziul, Anna Kamont","Smooth orthogonal projections on Riemannian manifold",,,,,"math.CA math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a decomposition of the identity operator on a Riemannian
manifold $M$ as a sum of smooth orthogonal projections subordinate to an open
cover of $M$. This extends a decomposition of the real line by smooth
orthogonal projection due to Coifman, Meyer and Auscher, Weiss, Wickerhauser,
and a similar decomposition when $M$ is the sphere by the first two authors.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:48:16 GMT""}]","2018-03-12"
"1803.03635","Jonathan Frankle","Jonathan Frankle and Michael Carbin","The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks","ICLR camera ready","ICLR 2019",,,"cs.LG cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural network pruning techniques can reduce the parameter counts of trained
networks by over 90%, decreasing storage requirements and improving
computational performance of inference without compromising accuracy. However,
contemporary experience is that the sparse architectures produced by pruning
are difficult to train from the start, which would similarly improve training
performance.
  We find that a standard pruning technique naturally uncovers subnetworks
whose initializations made them capable of training effectively. Based on these
results, we articulate the ""lottery ticket hypothesis:"" dense,
randomly-initialized, feed-forward networks contain subnetworks (""winning
tickets"") that - when trained in isolation - reach test accuracy comparable to
the original network in a similar number of iterations. The winning tickets we
find have won the initialization lottery: their connections have initial
weights that make training particularly effective.
  We present an algorithm to identify winning tickets and a series of
experiments that support the lottery ticket hypothesis and the importance of
these fortuitous initializations. We consistently find winning tickets that are
less than 10-20% of the size of several fully-connected and convolutional
feed-forward architectures for MNIST and CIFAR10. Above this size, the winning
tickets that we find learn faster than the original network and reach higher
test accuracy.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:51:28 GMT""},{""version"":""v2"",""created"":""Mon, 23 Apr 2018 19:58:09 GMT""},{""version"":""v3"",""created"":""Sun, 20 May 2018 19:46:47 GMT""},{""version"":""v4"",""created"":""Tue, 27 Nov 2018 20:03:01 GMT""},{""version"":""v5"",""created"":""Mon, 4 Mar 2019 15:51:11 GMT""}]","2019-03-05"
"1803.03636","Marcin Lis","Tim van de Brug, Federico Camia, Marcin Lis","Spin systems from loop soups","17 pages","Electron. J. Probab. 23 (2018), paper no. 81, 17 pp",,,"math-ph math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study spin systems defined by the winding of a random walk loop soup. For
a particular choice of loop soup intensity, we show that the corresponding spin
system is reflection-positive and is dual, in the Kramers-Wannier sense, to the
spin system $\text{sgn}(\varphi)$ where $\varphi$ is a discrete Gaussian free
field.
  In general, we show that the spin correlation functions have conformally
covariant scaling limits corresponding to the one-parameter family of functions
studied by Camia, Gandolfi and Kleban (Nuclear Physics B, 902, 2016) and
defined in terms of the winding of the Brownian loop soup. These functions have
properties consistent with the behavior of correlation functions of conformal
primaries in a conformal field theory. Here, we prove that they do correspond
to correlation functions of continuum fields (random generalized functions) for
values of the intensity of the Brownian loop soup that are not too large.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:51:36 GMT""},{""version"":""v2"",""created"":""Tue, 13 Nov 2018 10:16:04 GMT""}]","2018-11-14"
"1803.03637","Gerhard Roehrle","Nils Amend, Tilman Moeller, Gerhard Roehrle","Restrictions of aspherical arrangements","6 pages","Topology and Applications vol 249 (2018) 67 - 72",,,"math.AT math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we present examples of $K(\pi,1)$-arrangements which admit a
restriction which fails to be $K(\pi,1)$. This shows that asphericity is not
hereditary among hyperplane arrangements.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:59:25 GMT""},{""version"":""v2"",""created"":""Thu, 20 Sep 2018 07:12:32 GMT""}]","2018-09-21"
"1803.03638","Rixin Li","Rixin Li, Andrew N. Youdin, and Jacob B. Simon","On the Numerical Robustness of the Streaming Instability: Particle
  Concentration and Gas Dynamics in Protoplanetary Disks","20 pages, 14 figures, accepted for publication in the ApJ",,"10.3847/1538-4357/aaca99",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Streaming Instability (SI) is a mechanism to concentrate solids in
protoplanetary disks. Nonlinear particle clumping from the SI can trigger
gravitational collapse into planetesimals. To better understand the numerical
robustness of the SI, we perform a suite of vertically-stratified 3D
simulations with fixed physical parameters known to produce strong clumping. We
vary the numerical implementation, namely the computational domain size and the
vertical boundary conditions (vBCs), comparing newly-implemented outflow vBCs
to the previously-used periodic and reflecting vBCs. We find strong particle
clumping by the SI is mostly independent of the vBCs. However, peak particle
densities are higher in larger simulation domains due to a larger particle mass
reservoir. We report SI-triggered zonal flows, i.e., azimuthally-banded radial
variations of gas pressure. These structures have low amplitudes, insufficient
to halt particle radial drift, confirming that particle trapping in gas
pressure maxima is not the mechanism of the SI. We find that outflow vBCs
produce artificially large gas outflow rates at vertical boundaries. However,
the outflow vBCs reduce artificial reflections at vertical boundaries, allowing
more particle sedimentation, and showing less temporal variation and better
convergence with box size. The radial spacing of dense particle filaments is
$\sim0.15$ gas scale heights ($H$) for all vBCs, which sets the feeding zone
for planetesimal growth in self-gravitating simulations. Our results validate
the use of the outflow vBCs in SI simulations, even with vertical boundaries
close ($\leq 0.4H$) to the disk midplane. Overall, our study demonstrates the
numerical robustness of nonlinear particle clumping by the SI.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:59:41 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jun 2018 23:51:45 GMT""}]","2018-08-01"
"1803.03643","Asja Radja","Asja Radja, Eric M. Horsley, Maxim O. Lavrentovich, and Alison M.
  Sweeney","Pollen Patterns Form from Modulated Phases",,,"10.1016/j.cell.2019.01.014",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pollen grains are known for their impressive variety of species-specific,
microscale surface patterning. Despite having similar biological developmental
steps, pollen grain surface features are remarkably geometrically varied.
Previous work suggests that a physical process may drive this pattern formation
and that the observed diversity of patterns can be explained by viewing pollen
pattern development as a phase transition to a spatially modulated phase.
Several studies have shown that the polysaccharide material of plant cell walls
undergoes phase separation in the absence of cross-linking stabilizers of the
mixed phase. Here we show experimental evidence of a change in density of the
extracellular polysaccharide material (primexine) during pollen cell
development leads to a spatially modulated phase. The spatial pattern of this
phase-separated primexine is also mechanically coupled to the undulation of the
pollen cell membrane. The resulting patterned pools of denser primexine form
the negative template of the ultimate sites of sporopollenin deposition,
leading to the final micropattern observed in the mature pollen. We then
present a general physical model of pattern formation via modulated phases.
Using analytical and numerical techniques, we find that most of the pollen
micropatterns observed in biological evolution could result from a physical
process of modulated phases. However, an analysis of the relative rates of
transitions from states that are equilibrated to or from states that are not
equilibrated suggests that while equilibrium states of this process have
occurred throughout evolutionary history, there has been no particular
evolutionary selection for distinctly patterned equilibrated states.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:11:39 GMT""}]","2019-02-15"
"1803.03644","Felix Kahlhoefer","Torsten Bringmann, Felix Kahlhoefer, Kai Schmidt-Hoberg and Parampreet
  Walia","Converting non-relativistic dark matter to radiation","23 pages revtex4, 15 figures; v2: improved treatment of perturbations
  and choice of priors; v3: matches published version","Phys. Rev. D 98, 023543 (2018)","10.1103/PhysRevD.98.023543","DESY-18-032, TTK-18-10","astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  Dark matter in the cosmological concordance model is parameterised by a
single number, describing the covariantly conserved energy density of a
non-relativistic fluid. Here we test this assumption in a model-independent and
conservative way by considering the possibility that, at any point during the
cosmological evolution, dark matter may be converted into a non-interacting
form of radiation. This scenario encompasses, but is more general than, the
cases where dark matter decays or annihilates into these states. We show that
observations of the cosmic microwave background allow to strongly constrain
this scenario for any conversion time after big bang nucleosynthesis. We
discuss in detail, both from a Bayesian and frequentist point of view, in which
sense adding large-scale structure observations may even provide a certain
preference for a conversion of dark matter to radiation at late times. Finally
we apply our general results to a specific particle physics realisation of such
a scenario, featuring late kinetic decoupling and Sommerfeld-enhanced dark
matter annihilation. We identify a small part of parameter space that both
mitigates the tension between cosmic microwave and large-scale structure data
and allows for velocity-dependent dark matter self-interactions strong enough
to address the small-scale problems of structure formation.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 16 Apr 2018 20:31:48 GMT""},{""version"":""v3"",""created"":""Fri, 3 Aug 2018 09:44:24 GMT""}]","2018-08-08"
"1803.03645","Zhong-Bo Kang","Zhong-Bo Kang, Kyle Lee, Xiaohui Liu, Felix Ringer","The groomed and ungroomed jet mass distribution for inclusive jet
  production at the LHC","38 pages, 9 figures, published version","JHEP 1810 (2018) 137","10.1007/JHEP10(2018)137",,"hep-ph hep-ex nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study jet mass distributions measured in the single inclusive jet
production in proton-proton collisions $pp\to \text{jet}+X$ at the LHC. We
consider both standard ungroomed jets as well as soft drop groomed jets. Within
the Soft Collinear Effective Theory (SCET), we establish QCD factorization
theorems for both cases and we study their relation. The developed framework
allows for the joint resummation of several classes of logarithmic corrections
to all orders in the strong coupling constant. For the ungroomed case, we resum
logarithms in the jet radius parameter and in the small jet mass. For the
groomed case, we resum in addition the logarithms in the soft threshold
parameter $z_{\text{cut}}$ which is introduced by the soft drop grooming
algorithm. In this way, we are able to reliably determine the absolute
normalization of the groomed jet mass distribution in proton-proton collisions.
All logarithmic corrections are resummed to the next-to-leading logarithmic
accuracy. We present numerical results and compare with the available data from
the LHC. For both the groomed and ungroomed jet mass distributions we find very
good agreement after including non-perturbative corrections.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 8 Jun 2018 20:24:16 GMT""},{""version"":""v3"",""created"":""Thu, 25 Oct 2018 01:11:56 GMT""}]","2018-10-26"
"1803.03646","Niloufar Afsariardchi","Niloufar Afsariardchi, Christopher D. Matzner","Aspherical Supernovae: Effects on Early Light Curves","23 pages, 20 figures, Accepted for publication in ApJ",,"10.3847/1538-4357/aab3d4",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Early light from core-collapse supernovae, now detectable in high-cadence
surveys, holds clues to a star and its environment just before it explodes.
However, effects that alter the early light have not been fully explored. We
highlight the possibility of non-radial flows at the time of shock breakout.
These develop in sufficiently non-spherical explosions if the progenitor is not
too diffuse. When they do develop, non-radial flows limit ejecta speeds and
cause ejecta-ejecta collisions. We explore these phenomena and their
observational implications, using global, axisymmetric, non-relativistic FLASH
simulations of simplified polytropic progenitors, which we scale to
representative stars. We develop a method to track photon production within the
ejecta, enabling us to estimate band-dependent light curves from adiabatic
simulations. Immediate breakout emission becomes hidden as an oblique flow
develops. Non-spherical effects lead the shock-heated ejecta to release a more
constant luminosity at a higher, evolving color temperature at early times,
effectively mixing breakout light with the early light curve. Collisions
between non-radial ejecta thermalize a small fraction of the explosion energy;
we address emission from these collisions in a subsequent paper.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:00 GMT""}]","2018-04-18"
"1803.03647","Timothy Cohen","Timothy Cohen, Nathaniel Craig, Gian F. Giudice, and Matthew
  McCullough","The Hyperbolic Higgs","25 pages, 3 figures; v2: minor changes, JHEP version; v3 minor
  correction",,"10.1007/JHEP05(2018)091",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the Hyperbolic Higgs, a novel solution to the little hierarchy
problem that features Standard Model neutral scalar top partners. At one-loop
order, the protection from ultraviolet sensitivity is due to an accidental
non-compact symmetry of the Higgs potential that emerges in the infrared. Once
the general features of the effective description are detailed, a completion
that relies on a five dimensional supersymmetric framework is provided. Novel
phenomenology is compared and contrasted with the Twin Higgs scenario.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 24 Jul 2018 22:50:19 GMT""},{""version"":""v3"",""created"":""Wed, 11 Sep 2019 16:54:04 GMT""}]","2019-09-12"
"1803.03648","Jeffrey Fung","Jeffrey Fung and Eve Lee","Inner Super-Earths, Outer Gas Giants: How Pebble Isolation and Migration
  Feedback Keep Jupiters Cold","Accepted to ApJ",,"10.3847/1538-4357/aabaf7",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The majority of gas giants (planets of masses $\gtrsim10^2 M_\oplus$) are
found to reside at distances beyond $\sim1$ au from their host stars. Within 1
au, the planetary population is dominated by super-Earths of $2-20 M_\oplus$.
We show that this dichotomy between inner super-Earths and outer gas giants can
be naturally explained should they form in nearly inviscid disks. In laminar
disks, a planet can more easily repel disk gas away from its orbit. The
feedback torque from the pile-up of gas inside the planet's orbit slows down
and eventually halts migration. A pressure bump outside the planet's orbit
traps pebbles and solids, starving the core. Gas giants are born cold and stay
cold: more massive cores are preferentially formed at larger distances, and
they barely migrate under disk feedback. We demonstrate this using 2D
hydrodynamical simulations of disk-planet interaction lasting up to $10^5$
years: we track planet migration and pebble accretion until both come to an end
by disk feedback. Whether cores undergo runaway gas accretion to become gas
giants or not is determined by computing 1D gas accretion models. Our
simulations show that in an inviscid minimum mass solar nebula, gas giants do
not form inside $\sim$0.5 au, nor can they migrate there while the disk is
present. We also explore the dependence on disk mass, and find that gas giants
form further out in less massive disks.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 16 May 2018 04:06:11 GMT""}]","2018-06-13"
"1803.03649","Carlo R. Contaldi","Carlo R. Contaldi and Joao Magueijo","Unsqueezing of standing waves due to inflationary domain structure",,"Phys. Rev. D 98, 043523 (2018)","10.1103/PhysRevD.98.043523","Imperial/TP/18/CRC/1","astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The so-called ""trans-Planckian"" problem of inflation may be evaded by
positing that modes come into existence only when they became ""cis-Planckian""
by virtue of expansion. However, this would imply that for any mode a new
random realization would have to be drawn every $N$ wavelengths, with $N$
typically of order 1000 (but it could be larger or smaller). Such a re-drawing
of realizations leads to a heteroskodastic distribution if the region under
observation contains several such independent domains. This has no effect on
the sampled power spectrum for a scale-invariant raw spectrum, but at very
small scales it leads to a spectral index bias towards scale-invariance and
smooths oscillations in the spectrum. The domain structure would also
""unsqueeze"" some of the propagating waves, i.e., dismantle their standing wave
character. By describing standing waves as travelling waves of the same
amplitude moving in opposite directions we determine the observational effects
of unsqueezing. We find that it would erase the Doppler peaks in the CMB, but
only on very small angular scales, where the primordial signal may not be
readily accessible. The standing waves in a primordial gravitational wave
background would also be turned into travelling waves. This unsqueezing of the
gravitational wave background may constitute a detectable phenomenon.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:01 GMT""}]","2019-01-31"
"1803.03650","Yuber F. Perez-Gonzalez","M. C. Gonzalez-Garcia, Michele Maltoni, Yuber F. Perez-Gonzalez and
  Renata Zukanovich Funchal","Neutrino Discovery Limit of Dark Matter Direct Detection Experiments in
  the Presence of Non-Standard Interactions","21 pages, 4 figures. Matches version published in the JHEP. Corrected
  exposure and results for CRESST phase III","JHEP07(2018)019","10.1007/JHEP07(2018)019",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The detection of coherent neutrino-nucleus scattering by the COHERENT
collaboration has set on quantitative grounds the existence of an irreducible
neutrino background in direct detection searches of Weakly Interacting Massive
Dark Matter candidates. This background leads to an ultimate discovery limit
for these experiments: a minimum Dark Matter interaction cross section below
which events produced by the coherent neutrino scattering will mimic the Dark
Matter signal, the so-called \emph{neutrino floor}. In this work we study the
modification of such neutrino floor induced by non-standard neutrino
interactions within their presently allowed values by the global analysis of
oscillation and COHERENT data. By using the full likelihood information of such
global analysis we consistently account for the correlated effects of
non-standard neutrino interactions both in the neutrino propagation in matter
and in its interaction in the detector. We quantify their impact on the
neutrino floor for five future experiments: DARWIN (Xe), ARGO (Ar), Super-CDMS
HV (Ge and Si) and CRESST phase III (CaWO$_4$). Quantitatively, we find that
non-standard neutrino interactions allowed at the $3\sigma$ level can result in
an increase of the neutrino floor of up to a factor $\sim 5$ with respect to
the Standard Model expectations and impact the expected sensitivities of the
ARGO, CRESST phase III and DARWIN experiments.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:02 GMT""},{""version"":""v2"",""created"":""Thu, 5 Jul 2018 12:00:38 GMT""}]","2018-07-06"
"1803.03651","Christopher Verhaaren","Hsin-Chia Cheng, Lingfeng Li, Ennio Salvioni, and Christopher B.
  Verhaaren","Singlet Scalar Top Partners from Accidental Supersymmetry","41 pages, 9 Figures; v2: updated to published version","JHEP 1805 (2018) 057","10.1007/JHEP05(2018)057","TUM-HEP-1134-18","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a model wherein the Higgs mass is protected from the quadratic
one-loop top quark corrections by scalar particles that are complete singlets
under the Standard Model (SM) gauge group. While bearing some similarity to
Folded Supersymmetry, the construction is purely four dimensional and enjoys
more parametric freedom, allowing electroweak symmetry breaking to occur
easily. The cancelation of the top loop quadratic divergence is ensured by a
$Z_3$ symmetry that relates the SM top sector and two hidden top sectors, each
charged under its own hidden color group. In addition to the singlet scalars,
the hidden sectors contain electroweak-charged supermultiplets below the TeV
scale, which provide the main access to this model at colliders. The
phenomenology presents both differences and similarities with respect to other
realizations of neutral naturalness. Generally, the glueballs of hidden color
have longer decay lengths. The production of hidden sector particles results in
quirk or squirk bound states, which later annihilate. We survey the possible
signatures and corresponding experimental constraints.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:04 GMT""},{""version"":""v2"",""created"":""Tue, 17 Jul 2018 00:11:31 GMT""}]","2018-07-18"
"1803.03652","Alexander Arth","Bernhard R\""ottgers and Alexander Arth","SPH to Grid: a new integral conserving method","14 pages, 7 figures, 1 table Submitted to Astronomy & Computing",,,,"astro-ph.IM physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analysing data from Smoothed Particle Hydrodynamics (SPH) simulations is
about understanding global fluid properties rather than individual fluid
elements. Therefore, in order to properly understand the outcome of such
simulations it is crucial to transition from a particle to a grid based
picture. In this paper we briefly summarise different methods of calculating a
representative volume discretisation from SPH data and propose an improved
version of commonly used techniques. We present a possibility to generate
accurate 2D data directly without the CPU time and memory consuming detour over
a 3D grid. We lay out the importance of an accurate algorithm to conserve
integral fluid properties and to properly treat small scale structures using a
typical galaxy simulation snapshot. For demonstration purposes we additionally
calculate velocity power spectra and as expected find the main differences on
small scales. Finally we propose two new multi-purpose analysis packages which
utilise the new algorithms: Pygad and SPHMapper.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:04 GMT""}]","2018-03-13"
"1803.03653","Lodovico Coccato","Lodovico Coccato (1), Maximilian H. Fabricius (2 and 3), Roberto P.
  Saglia (2 and 3), Ralf Bender (3 and 2), Peter Erwin (2), Niv Drory (4), and
  Lorenzo Morelli (5) ((1) European Southern Observatory, Garching, Germany,
  (2) Max Planck Institute for Extraterrestrial Physics, Garching, Germany, (3)
  University Observatory Munich, Munich, Germany, (4) McDonald Observatory, The
  University of Texas at Austin, Texas, USA, (5) Dipartimento di Fisica e
  Astronomia ""G. Galilei"", Universit\`a di Padova, Padova, Italy)","Spectroscopic decomposition of NGC 3521: unveiling the properties of the
  bulge and disc","13 pages, 11 figures, accepted for publication in MNRAS",,"10.1093/mnras/sty705",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the kinematics and the stellar populations of the bulge and disc of
the spiral galaxy NGC 3521. At each position in the field of view, we separate
the contributions of the bulge and the disc from the total observed spectrum
and study their kinematics, age, and metallicities independently. Their
properties are clearly distinct: the bulge rotates more slowly, has a higher
velocity dispersion, and is less luminous than the disc. We identify three main
populations of stars in NGC 3521: old ($\geq7$ Gyr), intermediate ($\approx$ 3
Gyr), and young ($\leq$1 Gyr). The mass and light of NGC 3521 are dominated by
the intermediate stellar population. The youngest population contributes mostly
to the disc component and its contribution increases with radius. We also study
the luminosity-weighed properties of the stars in NGC 3521. Along the
photometric major axis, we find: i) no age gradient for the stars in the bulge,
and a negative age gradient for the stars in the disc; ii) negative metallicity
gradients and sub-solar $\alpha$-enhancement for both the bulge and the disc.
We propose the following picture for the formation of NGC 3521: initial
formation a long time ago ($\geq 7$ Gyr), followed by a second burst of star
formation or a merger ($\approx$ 3 Gyrs ago), which contributed predominantly
to the mass-build up of the bulge. Recently ($\leq 1$ Gyr), the disc of NGC
3521 experienced an additional episode of star formation that started in the
innermost regions.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:05 GMT""}]","2018-03-28"
"1803.03654","David Breen","Sean Grimes, Linge Bai, Andrew W.E. McDonald, David E. Breen","Directing Chemotaxis-Based Spatial Self-Organization via Biased, Random
  Initial Conditions",,,,,"cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by the chemotaxis interaction of living cells, we have developed an
agent-based approach for self-organizing shape formation. Since all our
simulations begin with a different uniform random configuration and our agents
move stochastically, it has been observed that the self-organization process
may form two or more stable final configurations. These differing
configurations may be characterized via statistical moments of the agents'
locations. In order to direct the agents to robustly form one specific
configuration, we generate biased initial conditions whose statistical moments
are related to moments of the desired configuration. With this approach, we are
able to successfully direct the aggregating swarms to produced a desired
macroscopic shape, starting from randomized initial conditions with controlled
statistical properties.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:00:15 GMT""}]","2018-03-13"
"1803.03655","John Chisholm","J. Chisholm, S. Gazagnes, D. Schaerer, A. Verhamme, J. R. Rigby, M.
  Bayliss, K. Sharon, M. Gladders, and H. Dahle","Accurately predicting the escape fraction of ionizing photons using
  restframe ultraviolet absorption lines","Accepted for publication in A&A. 12 pages, 5 figures","A&A 616, A30 (2018)","10.1051/0004-6361/201832758",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fraction of ionizing photons that escape high-redshift galaxies
sensitively determines whether galaxies reionized the early universe. However,
this escape fraction cannot be measured from high-redshift galaxies because the
opacity of the intergalactic medium is large at high redshifts. Without methods
to indirectly measure the escape fraction of high-redshift galaxies, it is
unlikely that we will know what reionized the universe. Here, we analyze the
far-ultraviolet (UV) H I (Lyman series) and low-ionization metal absorption
lines of nine low-redshift, confirmed Lyman continuum emitting galaxies. We use
the H I covering fractions, column densities, and dust attenuations measured in
a companion paper to predict the escape fraction of ionizing photons. We find
good agreement between the predicted and observed Lyman continuum escape
fractions (within $1.4\sigma$) using both the H I and ISM absorption lines. The
ionizing photons escape through holes in the H I, but we show that dust
attenuation reduces the fraction of photons that escape galaxies. This means
that the average high-redshift galaxy likely emits more ionizing photons than
low-redshift galaxies. Two other indirect methods accurately predict the escape
fractions: the Ly$\alpha$ escape fraction and the optical [O III]/[O II] flux
ratio. We use these indirect methods to predict the escape fraction of a sample
of 21 galaxies with rest-frame UV spectra but without Lyman continuum
observations. Many of these galaxies have low escape fractions ($f_{\rm esc}
\le 1$\%), but 11 have escape fractions $>1$\%. The methods presented here will
measure the escape fractions of high-redshift galaxies, enabling future
telescopes to determine whether star-forming galaxies reionized the early
universe.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:01:28 GMT""},{""version"":""v2"",""created"":""Wed, 4 Apr 2018 10:08:11 GMT""}]","2018-08-08"
"1803.03656","Kyle Bednar","Kyle D. Bednar, Ian C. Clo\""et, Peter C. Tandy","Nucleon Quark Distribution Functions from the Dyson-Schwinger Equations","8 pages, 5 figures",,"10.1016/j.physletb.2018.06.020",,"nucl-th hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present results for the nucleon's leading-twist spin-independent valence
parton distribution functions obtained from a theoretical framework based on
the Dyson-Schwinger equations (DSEs) of QCD that previously gave an excellent
description of nucleon electromagnetic form factors. We employ the
rainbow-ladder truncation of the DSEs and utilize nucleon bound state
amplitudes from the Poincar\'e-covariant Faddeev equation, where the dominant
scalar and axial-vector quark-quark correlations are included. This DSE
framework is used to numerically evaluate the first 20 moments of the valence
$u$ and $d$ quark distribution functions, from which the $x$-dependence of the
distributions is found to be well constrained. We find good agreement with
empirical parameterizations of experimental data and make the prediction that
the $d/u$ ratio in the $x\to 1$ limit, invariant under scale evolution, takes
the value $d/u \to 0.087 \pm 0.010$. We find that this ratio is rather
sensitive to the strength of axial-vector diquark correlations. However,
contrary to a naive expectation, our result for the $d/u$ ratio in the $x\to 1$
limit does not vanish when only scalar diquark correlations are present,
although it is an order of magnitude smaller than our $d/u$ result that also
includes axial-vector diquarks. The valence quark distribution results are set
in a broader context via a simple pion cloud model estimate of sea-quark
light-cone momenta and gluon light-cone momentum.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:02:27 GMT""}]","2018-08-01"
"1803.03657","Alex Moylett","Alexandra E. Moylett and Peter S. Turner","Quantum simulation of partially distinguishable boson sampling","25 pages, 4 figures, 2 algorithms, comments welcome","Phys. Rev. A 97, 062329 (2018)","10.1103/PhysRevA.97.062329",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Boson Sampling is the problem of sampling from the same output probability
distribution as a collection of indistinguishable single photons input into a
linear interferometer. It has been shown that, subject to certain computational
complexity conjectures, in general the problem is difficult to solve
classically, motivating optical experiments aimed at demonstrating quantum
computational ""supremacy"". There are a number of challenges faced by such
experiments, including the generation of indistinguishable single photons. We
provide a quantum circuit that simulates bosonic sampling with arbitrarily
distinguishable particles. This makes clear how distinguishabililty leads to
decoherence in the standard quantum circuit model, allowing insight to be
gained. At the heart of the circuit is the quantum Schur transform, which
follows from a representation theoretic approach to the physics of
distinguishable particles in first quantisation. The techniques are quite
general and have application beyond boson sampling.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:04:06 GMT""}]","2018-06-21"
"1803.03658","Jan Piclum","A. Czarnecki, S. Groote, J.G. K\""orner and J.H. Piclum","NNLO QCD corrections to the polarized top quark decay $t(\uparrow) \to
  X_b+W^+$","17 pages, 3 figures; v2: added Fig. 2 and 3 and corresponding
  discussion","Phys. Rev. D 97, 094008 (2018)","10.1103/PhysRevD.97.094008","Alberta Thy 3-18, MITP/18-008, SI-HEP-2018-11","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the next-to-next-to-leading order (NNLO) QCD corrections to the
decay $t(\uparrow) \to X_b +W^+$ of a polarized top quark. The spin-momentum
correlation in this quasi two-body decay is described by the polar angle
distribution $\mathrm{d}\Gamma/\mathrm{d}\cos\theta_P=\frac{\Gamma}{2}(1+P_t\,
\alpha_P\, \cos\theta_P)$ where $P_t$ is the polarization of the top quark and
$\alpha_P$ denotes the asymmetry parameter of the decay. For the latter we find
$\alpha^{\mathrm{NNLO}}_P=0.3792\pm 0.0037$.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:09:13 GMT""},{""version"":""v2"",""created"":""Mon, 14 May 2018 12:23:31 GMT""}]","2018-05-16"
"1803.03659","Andrea Marino","Alessio Conte and Roberto Grossi and Andrea Marino and Luca Versari","Listing Maximal Subgraphs in Strongly Accessible Set Systems",,,,,"cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Algorithms for listing the subgraphs satisfying a given property (e.g.,being
a clique, a cut, a cycle, etc.) fall within the general framework of set
systems. A set system (U, F) uses a ground set U (e.g., the network nodes) and
an indicator F, subset of 2^U, of which subsets of U have the required
property. For the problem of listing all sets in F maximal under inclusion, the
ambitious goal is to cover a large class of set systems, preserving at the same
time the efficiency of the enumeration. Among the existing algorithms, the
best-known ones list the maximal subsets in time proportional to their number
but may require exponential space. In this paper we improve the state of the
art in two directions by introducing an algorithmic framework that, under
standard suitable conditions, simultaneously (i) extends the class of problems
that can be solved efficiently to strongly accessible set systems, and (ii)
reduces the additional space usage from exponential in |U| to stateless, thus
accounting for just O(q) space, where q <= |U| is the largest size of a maximal
set in F
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:13:00 GMT""}]","2018-03-13"
"1803.03660","Yongjia Zhang","Yongjia Zhang","A note on Perelman's no shrinking breather theorem",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As an application of his entropy formula, Perelman proved that every compact
shrinking breather is a shrinking gradient Ricci soliton. We give a proof for
the complete noncompact case by using Perelman's $\mathcal{L}$-geometry. Our
proof follows the argument in Lu and Zheng of constructing an ancient solution,
and removes a technical assumption made by them.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:14:23 GMT""},{""version"":""v2"",""created"":""Thu, 26 Apr 2018 04:54:37 GMT""}]","2018-04-27"
"1803.03661","Armen Sedrakian","Jia Jie Li (ITP, Frankfurt), Armen Sedrakian (FIAS), Fridolin Weber
  (SDSU)","Competition between delta isobars and hyperons and properties of compact
  stars","7 pages, 4 figures; v2: minor changes, matches published version","Phys. Lett. B 783 (2018) 234-240","10.1016/j.physletb.2018.06.051",,"nucl-th astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $\Delta$-isobar degrees of freedom are included in the covariant
  density functional (CDF) theory to study the equation of state (EoS)
  and composition of dense matter in compact stars. In addition to
  $\Delta$'s we include the full octet of baryons, which allows us to
  study the interplay between the onset of delta isobars and hyperonic
  degrees of freedom. Using both the Hartree and Hartree-Fock
  approximation we find that $\Delta$'s appear already at densities
  slightly above the saturation density of nuclear matter for a wide
  range of the meson-$\Delta$ coupling constants. This delays the
  appearance of hyperons and significantly affects the gross
  properties of compact stars. Specifically, $\Delta$'s soften the
  EoS at low densities but stiffen it at high densities. This
  softening reduces the radius of a canonical $1.4 M_\odot$ star by up
  to 2~km for a reasonably attractive $\Delta$ potential in matter,
  while the stiffening results in larger maximum masses of compact
  stars. We conclude that the hypernuclear CDF parametrizations that
  satisfy the 2$M_\odot$ maximum mass constraint remain valid when
  $\Delta$ isobars are included, with the important consequence that
  the resulting stellar radii are shifted toward lower values, which
  is in agreement with the analysis of neutron star radii.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:15:07 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jun 2018 14:33:03 GMT""}]","2018-07-17"
"1803.03663","Daniel Paulusma","Barnaby Martin, Daniel Paulusma, Erik Jan van Leeuwen","Disconnected Cuts in Claw-free Graphs",,,,,"cs.DS cs.CC cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A disconnected cut of a connected graph is a vertex cut that itself also
induces a disconnected subgraph. The decision problem whether a graph has a
disconnected cut is called Disconnected Cut. This problem is closely related to
several homomorphism and contraction problems, and fits in an extensive line of
research on vertex cuts with additional properties. It is known that
Disconnected Cut is NP-hard on general graphs, while polynomial-time algorithms
are known for several graph classes. However, the complexity of the problem on
claw-free graphs remained an open question. Its connection to the complexity of
the problem to contract a claw-free graph to the 4-vertex cycle $C_4$ led Ito
et al. (TCS 2011) to explicitly ask to resolve this open question.
  We prove that Disconnected Cut is polynomial-time solvable on claw-free
graphs, answering the question of Ito et al. The centerpiece of our result is a
novel decomposition theorem for claw-free graphs of diameter 2, which we
believe is of independent interest and expands the research line initiated by
Chudnovsky and Seymour (JCTB 2007-2012) and Hermelin et al. (ICALP 2011). On
our way to exploit this decomposition theorem, we characterize how disconnected
cuts interact with certain cobipartite subgraphs, and prove two further novel
algorithmic results, namely Disconnected Cut is polynomial-time solvable on
circular-arc graphs and line graphs.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:23:03 GMT""}]","2018-03-13"
"1803.03666","Chi-Ken Lu","Chi-Ken Lu, Scott Cheng-Hsin Yang, Patrick Shafto","Standing Wave Decomposition Gaussian Process","10 pages, 8 figures; updated version includes a modified introduction
  and a new discussion on time complexity of our approximated GP method. New
  references are added. Simulation package will be announced later; updated
  with discussion of validity of perturbation treatment of Eq. (25) with added
  Fig. 6 as evidence; simulation code at https://github.com/CoDaS-Lab/LG-SWD-GP","Phys. Rev. E 98, 032303 (2018)","10.1103/PhysRevE.98.032303",,"stat.ML cond-mat.dis-nn cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a Standing Wave Decomposition (SWD) approximation to Gaussian
Process regression (GP). GP involves a costly matrix inversion operation, which
limits applicability to large data analysis. For an input space that can be
approximated by a grid and when correlations among data are short-ranged, the
kernel matrix inversion can be replaced by analytic diagonalization using the
SWD. We show that this approach applies to uni- and multi-dimensional input
data, extends to include longer-range correlations, and the grid can be in a
latent space and used as inducing points. Through simulations, we show that our
approximate method applied to the squared exponential kernel outperforms
existing methods in predictive accuracy per unit time in the regime where data
are plentiful. Our SWD-GP is recommended for regression analyses where there is
a relatively large amount of data and/or there are constraints on computation
time.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:26:11 GMT""},{""version"":""v2"",""created"":""Thu, 24 May 2018 15:56:06 GMT""},{""version"":""v3"",""created"":""Fri, 10 Aug 2018 16:37:59 GMT""},{""version"":""v4"",""created"":""Mon, 17 Sep 2018 15:41:39 GMT""}]","2018-09-19"
"1803.03669","Mihai Cucuringu","Mihai Cucuringu, Hemant Tyagi","Provably robust estimation of modulo 1 samples of a smooth function with
  applications to phase unwrapping","68 pages, 32 figures. arXiv admin note: text overlap with
  arXiv:1710.10210",,,,"stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider an unknown smooth function $f: [0,1]^d \rightarrow \mathbb{R}$, and
say we are given $n$ noisy mod 1 samples of $f$, i.e., $y_i = (f(x_i) +
\eta_i)\mod 1$, for $x_i \in [0,1]^d$, where $\eta_i$ denotes the noise. Given
the samples $(x_i,y_i)_{i=1}^{n}$, our goal is to recover smooth, robust
estimates of the clean samples $f(x_i) \bmod 1$. We formulate a natural
approach for solving this problem, which works with angular embeddings of the
noisy mod 1 samples over the unit circle, inspired by the angular
synchronization framework. This amounts to solving a smoothness regularized
least-squares problem -- a quadratically constrained quadratic program (QCQP)
-- where the variables are constrained to lie on the unit circle. Our approach
is based on solving its relaxation, which is a trust-region sub-problem and
hence solvable efficiently. We provide theoretical guarantees demonstrating its
robustness to noise for adversarial, and random Gaussian and Bernoulli noise
models. To the best of our knowledge, these are the first such theoretical
results for this problem. We demonstrate the robustness and efficiency of our
approach via extensive numerical simulations on synthetic data, along with a
simple least-squares solution for the unwrapping stage, that recovers the
original samples of $f$ (up to a global shift). It is shown to perform well at
high levels of noise, when taking as input the denoised modulo $1$ samples.
  Finally, we also consider two other approaches for denoising the modulo 1
samples that leverage tools from Riemannian optimization on manifolds,
including a Burer-Monteiro approach for a semidefinite programming relaxation
of our formulation. For the two-dimensional version of the problem, which has
applications in radar interferometry, we are able to solve instances of
real-world data with a million sample points in under 10 seconds, on a personal
laptop.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:31:53 GMT""},{""version"":""v2"",""created"":""Fri, 25 Oct 2019 16:50:52 GMT""}]","2019-10-29"
"1803.03671","Szymon Starzonek","Szymon Starzonek, Aleksandra K\k{e}dzierska-Sar, Aleksandra
  Drozd-Rzoska, Miko{\l}aj Szafran, Sylwester J. Rzoska","Unique dynamic crossover in supercooled x,3-dihydroxypropyl acrylate (x
  = 1, 2) isomers mixture",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The previtreous dynamics in glass forming monomer, glycerol monoacrylate
(GMA), using broadband dielectric spectroscopy (BDS) was tested. Measurements
revealed the clear dynamic crossover at temperature $T_B = 254$ K and the time
scale $\tau(T_B) = 5.4$ ns for the primary (structural) relaxation time and no
hallmarks for the crossover for the DC electric conductivity $\sigma_{DC}$.
This result was revealed via the derivative-based and distortions-sensitive
analysis $dln{H_{a}}/d(1/T)$ vs. $1/T$, where $H_a$ is for the apparent
activation energy. Subsequent tests of the fractional Debye-Stokes-Einsten
relation $\sigma_{DC}(\tau_{\alpha})^S = const$ showed that the crossover is
associated with $S = 1$ (for $T>T_B$)->$S = 0.84$ (for $T<T_B$). The crossover
is associated with the emergence of the secondary beta relaxation which
smoothly develops deeply into the solid amorphous phase below the glass
temperature $T_g$.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:38:35 GMT""}]","2018-03-13"
"1803.03672","Amin  Khajehnejad","Amin Khajehnejad and Shima Hajimirza","Competitive Machine Learning: Best Theoretical Prediction vs
  Optimization",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning is often used in competitive scenarios: Participants learn
and fit static models, and those models compete in a shared platform. The
common assumption is that in order to win a competition one has to have the
best predictive model, i.e., the model with the smallest out-sample error. Is
that necessarily true? Does the best theoretical predictive model for a target
always yield the best reward in a competition? If not, can one take the best
model and purposefully change it into a theoretically inferior model which in
practice results in a higher competitive edge? How does that modification look
like? And finally, if all participants modify their prediction models towards
the best practical performance, who benefits the most? players with inferior
models, or those with theoretical superiority? The main theme of this paper is
to raise these important questions and propose a theoretical model to answer
them. We consider a study case where two linear predictive models compete over
a shared target. The model with the closest estimate gets the whole reward,
which is equal to the absolute value of the target. We characterize the reward
function of each model, and using a basic game theoretic approach, demonstrate
that the inferior competitor can significantly improve his performance by
choosing optimal model coefficients that are different from the best
theoretical prediction. This is a preliminary study that emphasizes the fact
that in many applications where predictive machine learning is at the service
of competition, much can be gained from practical (back-testing) optimization
of the model compared to static prediction improvement.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:42:54 GMT""}]","2018-03-14"
"1803.03674","Mohammadreza Mohaghegh Neyshabouri","Mohammadreza Mohaghegh Neyshabouri, Suleyman Serdar Kozat","Sequential Outlier Detection based on Incremental Decision Trees",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce an online outlier detection algorithm to detect outliers in a
sequentially observed data stream. For this purpose, we use a two-stage
filtering and hedging approach. In the first stage, we construct a multi-modal
probability density function to model the normal samples. In the second stage,
given a new observation, we label it as an anomaly if the value of
aforementioned density function is below a specified threshold at the newly
observed point. In order to construct our multi-modal density function, we use
an incremental decision tree to construct a set of subspaces of the observation
space. We train a single component density function of the exponential family
using the observations, which fall inside each subspace represented on the
tree. These single component density functions are then adaptively combined to
produce our multi-modal density function, which is shown to achieve the
performance of the best convex combination of the density functions defined on
the subspaces. As we observe more samples, our tree grows and produces more
subspaces. As a result, our modeling power increases in time, while mitigating
overfitting issues. In order to choose our threshold level to label the
observations, we use an adaptive thresholding scheme. We show that our adaptive
threshold level achieves the performance of the optimal pre-fixed threshold
level, which knows the observation labels in hindsight. Our algorithm provides
significant performance improvements over the state of the art in our wide set
of experiments involving both synthetic as well as real data.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:48:13 GMT""}]","2018-03-13"
"1803.03675","DooSoo Yoon","Doosoo Yoon, Feng Yuan, Zhao-Ming Gan, Jeremiah P. Ostriker, Ya-Ping
  Li, Luca Ciotti","Active Galactic Nuclei Feedback in an Elliptical Galaxy with the Most
  Updated AGN Physics (II): High-Angular Momentum Case","20 pages, 14 figures, accepted for publication to ApJ (Revised to
  match version published in ApJ)",,"10.3847/1538-4357/aad37e",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the second paper of our series of works of studying the effects of
active galactic nuclei (AGN) feedback on the cosmological evolution of an
isolated elliptical galaxy by performing two-dimensional high-resolution
hydrodynamical numerical simulations. In these simulations, the inner boundary
is chosen so that the Bondi radius is resolved. Physical processes like star
formation, SNe Ia and II are taken into account. Compared to previous works,
the main improvements is that we adopt the most updated AGN physics, which is
described in detail in the first paper of this series (Yuan et al. 2018, Paper
I). These improvements include the discrimination of the two accretion modes of
the central AGN and the most updated descriptions of the wind and radiation in
the two modes. In Paper I, we consider the case that the specific angular
momentum of the gas in the galaxy is very low. In this paper, we consider the
case that the specific angular momentum of the gas is high. In the galactic
scale, we adopt the gravitational torques raised due to non-axisymmetric
structure in the galaxy as the mechanism of the transfer of angular momentum of
gas, as proposed in some recent works. Since our simulations are axisymmetric,
we make use of a parameterized prescription to mimic this mechanism. Same as
Paper I, we investigate the AGN light curve, typical AGN lifetime, growth of
the black hole mass, AGN duty-cycle, star formation, and the X-ray surface
brightness of the galaxy. Special attention is paid to the effects of specific
angular momentum of the galaxy on these properties. We find that some results
are qualitatively similar to those shown in Paper I, while some results such as
star formation and black hole growth do show a significant difference due to
the mass concentration in the galactic disk as a consequence of galactic
rotation.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 19:48:50 GMT""},{""version"":""v2"",""created"":""Wed, 18 Jul 2018 02:32:24 GMT""}]","2018-09-05"
"1803.03676","Sridip Pal","Benjamin Grinstein and Sridip Pal","Existence and Construction of Galilean invariant $z\neq2$ Theories","7 pages and a little bit more; two column, 1 appendix","Phys. Rev. D 97, 125006 (2018)","10.1103/PhysRevD.97.125006",,"hep-th cond-mat.quant-gas cond-mat.str-el math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a no-go theorem for the construction of a Galilean boost invariant
and $z\neq2$ anisotropic scale invariant field theory with a finite dimensional
basis of fields. Two point correlators in such theories, we show, grow
unboundedly with spatial separation. Correlators of theories with an infinite
dimensional basis of fields, for example, labeled by a continuous parameter, do
not necessarily exhibit this bad behavior. Hence, such theories behave
effectively as if in one extra dimension. Embedding the symmetry algebra into
the conformal algebra of one higher dimension also reveals the existence of an
internal continuous parameter. Consideration of isometries shows that the
non-relativistic holographic picture assumes a canonical form, where the bulk
gravitational theory lives in a space-time with one extra dimension. This can
be contrasted with the original proposal by Balasubramanian and McGreevy, and
by Son, where the metric of a $d+2$ dimensional space-time is proposed to be
dual of a $d$ dimensional field theory. We provide explicit examples of
theories living at fixed point with anisotropic scaling exponent
$z=\frac{2\ell}{\ell+1}\,,\ell\in \mathbb{Z}$
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:03:13 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jun 2018 20:38:34 GMT""}]","2018-06-14"
"1803.03677","Soroush Pakniat","Soroush Pakniat and Farzad Eskandari","Nonparametric Risk Assessment and Density Estimation for Persistence
  Landscapes",,,,,"stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents approximate confidence intervals for each function of
parameters in a Banach space based on a bootstrap algorithm. We apply kernel
density approach to estimate the persistence landscape. In addition, we
evaluate the quality distribution function estimator of random variables using
integrated mean square error (IMSE). The results of simulation studies show a
significant improvement achieved by our approach compared to the standard
version of confidence intervals algorithm. In the next step, we provide several
algorithms to solve our model. Finally, real data analysis shows that the
accuracy of our method compared to that of previous works for computing the
confidence interval.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:04:12 GMT""}]","2018-03-13"
"1803.03678","Juan Pablo Calderon","Juan P. Calder\'on, Lilia P. Bassino, Sergio A. Cellone and Mat\'ias
  G\'omez","Early-type galaxies in the Antlia Cluster: Catalogue and isophotal
  analysis","Accepted for publication in MNRAS",,"10.1093/mnras/sty611",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a statistical isophotal analysis of 138 early-type galaxies in the
Antlia cluster, located at a distance of ${\sim} 35$ Mpc. The observational
material consists of CCD images of four $36$ arcmin ${\times} 36$ arcmin fields
obtained with the MOSAIC II camera at the Blanco 4-m telescope at CTIO. Our
present work supersedes previous Antlia studies in the sense that the covered
area is four times larger, the limiting magnitude is $M_{B} {\sim} -9.6$ mag,
and the surface photometry parameters of each galaxy are derived from S\'ersic
model fits extrapolated to infinity. In a companion previous study we focused
on the scaling relations obtained by means of surface photometry, and now we
present the data, on which the previous paper is based, the parameters of the
isophotal fits as well as an isophotal analysis. For each galaxy, we derive
isophotal shape parameters along the semi-major axis and search for
correlations within different radial bins. Through extensive statistical tests,
we also analyse the behaviour of these values against photometric and global
parameters of the galaxies themselves. While some galaxies do display radial
gradients in their ellipticity (${\epsilon}$) and/or their Fourier
coefficients, differences in mean values between adjacent regions are not
statistically significant. Regarding Fourier coefficients, dwarf galaxies
usually display gradients between all adjacent regions, while non-dwarfs tend
to show this behaviour just between the two outermost regions. Globally, there
is no obvious correlation between Fourier coefficients and luminosity for the
whole magnitude range ($-12 {\gtrsim} M_{V} {\gtrsim} -22$); however, dwarfs
display much higher dispersions at all radii.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:06:31 GMT""}]","2018-03-13"
"1803.03679","Chun Ning (Jeanie) Lau","Shi Che, Petr Stepanov, Supeng Ge, Yongjin Lee, Kevin Myhro, Yanmeng
  Shi, Ruoyu Chen, Ziqi Pi, Cheng Pan, Bin Cheng, Takashi Taniguchi, Kenji
  Watanabe, Marc Bockrath, Yafis Barlas, Roger Lake, Chun Ning Lau","Twist Angle-Dependent Bands and Valley Inversion in 2D Materials/hBN
  Heterostructures",,"Phys. Rev. Lett. 125, 246401 (2020)","10.1103/PhysRevLett.125.246401",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of relative twist angle between adjacent atomic layers in a van der
Waals heterostructure, has emerged as a new degree of freedom to tune
electronic and optoelectronic properties of devices based on 2D materials.
Using ABA-stacked trilayer (TLG) graphene as the model system, we show that,
contrary to conventional wisdom, the band structures of 2D materials are
systematically tunable depending on their relative alignment angle between
hexagonal BN (hBN), even at very large twist angles. Moreover, addition or
removal of the hBN substrate results in an inversion of the K and K' valley in
TLG's lowest Landau level (LL). Our work illustrates the critical role played
by substrates in van der Waals heterostructures and opens the door towards band
structure modification and valley control via substrate and twist angle
engineering.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:06:46 GMT""}]","2021-01-04"
"1803.03680","Pietro Poggi-Corradini","Nathan Albin and Nethali Fernando and Pietro Poggi-Corradini","Modulus metrics on networks","To appear in Discrete and Continuous Dynamical Systems - B",,"10.3934/dcdsb.2018161",,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The concept of $p$-modulus gives a way to measure the richness of a family of
objects on a graph. In this paper, we investigate the families of connecting
walks between two fixed nodes and show how to use $p$-modulus to form a
parametrized family of graph metrics that generalize several well-known and
widely-used metrics. We also investigate a characteristic of metrics called the
""antisnowflaking exponent"" and present some numerical findings supporting a
conjecture about the new metrics. We end with explicit computations of the new
metrics on some selected graphs.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:07:10 GMT""}]","2021-02-09"
"1803.03681","Rostislav Stan\v{e}k","Rostislav Stan\v{e}k and Peter Greistorfer and Klaus Ladner and Ulrich
  Pferschy","Geometric and LP-based heuristics for the quadratic travelling salesman
  problem",,"Computers & Operations Research vol. 108, pp. 97--111, 2019","10.1016/j.cor.2019.01.016",,"cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A generalization of the classical TSP is the so-called quadratic travelling
salesman problem (QTSP), in which a cost coefficient is associated with the
transition in every vertex, i.e. with every pair of edges traversed in
succession. In this paper we consider two geometrically motivated special cases
of the QTSP known from the literature, namely the angular-metric TSP, where
transition costs correspond to turning angles in every vertex, and the
angular-distance-metric TSP, where a linear combination of turning angles and
Euclidean distances is considered.
  At first we introduce a wide range of heuristic approaches, motivated by the
typical geometric structure of optimal solutions. In particular, we exploit
lens-shaped neighborhoods of edges and a decomposition of the graph into layers
of convex hulls, which are then merged into a tour by a greedy-type procedure
or by utilizing an ILP model. Secondly, we consider an ILP model for a standard
linearization of QTSP and compute fractional solutions of a relaxation. By
rounding we obtain a collection of subtours, paths and isolated points, which
are combined into a tour by various strategies, all of them involving auxiliary
ILP models. Finally, different improvement heuristics are proposed, most
notably a matheuristic which locally reoptimizes the solution for rectangular
sectors of the given point set by an ILP approach.
  Extensive computational experiments for benchmark instances from the
literature and extensions thereof illustrate the Pareto-efficient frontier of
algorithms in a (running time, objective value)-space. It turns out that our
new methods clearly dominate the previously published heuristics.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:09:51 GMT""}]","2021-09-30"
"1803.03682","Katina Kralevska","Danilo Gligoroski, Katina Kralevska, Rune E. Jensen and Per Simonsen","Network Traffic Driven Storage Repair","arXiv admin note: text overlap with arXiv:1701.06664",,"10.1504/IJBDI.2019.100888","Published in International Journal of Big Data Intelligence, 2018","cs.IT cs.DC math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently we constructed an explicit family of locally repairable and locally
regenerating codes. Their existence was proven by Kamath et al. but no explicit
construction was given. Our design is based on HashTag codes that can have
different sub-packetization levels. In this work we emphasize the importance of
having two ways to repair a node: repair only with local parity nodes or repair
with both local and global parity nodes. We say that the repair strategy is
network traffic driven since it is in connection with the concrete system and
code parameters: the repair bandwidth of the code, the number of I/O
operations, the access time for the contacted parts and the size of the stored
file. We show the benefits of having repair duality in one practical example
implemented in Hadoop. We also give algorithms for efficient repair of the
global parity nodes.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:16:05 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jun 2018 15:04:24 GMT""}]","2020-02-14"
"1803.03684","Luciana Ferrer","Luciana Ferrer","Scoring Formulation for Multi-Condition Joint PLDA",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The joint PLDA model, is a generalization of PLDA where the nuisance variable
is no longer considered independent across samples, but potentially shared
(tied) across samples that correspond to the same nuisance condition. The
original work considered a single nuisance condition, deriving the EM and
scoring formulas for this scenario. In this document, we show how to obtain
likelihood ratios for scoring when multiple nuisance conditions are allowed in
the model.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:29:18 GMT""}]","2018-03-14"
"1803.03685","Ethan Bloch","Margaret Allardice and Ethan D. Bloch","Lattice Diagrams of Knots and Diagrams of Lattice Stick Knots","14 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a simple example showing that a knot or link diagram that lies in the
${\mathbb{Z}}^2$ lattice is not necessarily the projection of a lattice stick
knot or link in the ${\mathbb{Z}}^3$ lattice, and we give a necessary and
sufficient condition for when a knot or link diagram that lies in the
${\mathbb{Z}}^2$ lattice is in fact the projection of a lattice stick knot or
link.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:30:13 GMT""}]","2018-03-13"
"1803.03686","Raghav Kunnawalkam Elayavalli","Raghav Kunnawalkam Elayavalli","Jetting Through The Primordial Universe","PhD Thesis: Defended on June 6th 2017 at Rutgers University, New
  Brunswick. Advised by Prof. Sevil Salur. Includes material from 1707.01539,
  1609.05383, 1608.03099, 1601.02001 and 1510.03373",,"10.7282/T3W09926",,"hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collisions of heavy ion nuclei at relativistic speeds (close to the speed of
light) creates a high temperature and very dense form of matter, now known to
consist of de-confined quarks and gluons, named the quark gluon plasma (QGP).
In this thesis, Run1 experimental data from pp and heavy ion collisions at the
CERN LHC is analyzed with the CMS detector. The pp jet cross section is
compared with next to leading order theoretical calculations supplemented with
non perturbative corrections for three different jet radii highlighting better
comparisons for larger radii jets. Measurement of the jet yield followed by the
nuclear modification factors in proton-lead at 5.02 TeV and lead-lead
collisions at 2.76 TeV are presented. A new data driven technique is introduced
to estimate and correct for the fake jet contribution in PbPb for low
transverse momenta jets. The nuclear modification factors studied in this
thesis show jet quenching to be attributed to final state effects, have a
strong correlation to the event centrality, a weak inverse correlation to the
jet transverse momenta and an apparent independence on the jet radii in the
kinematic range studied. These measurements are compared with leading
theoretical model calculations and other experimental results at the LHC
leading to unanimous agreement on the qualitative nature of jet quenching. This
thesis also features novel updates to the Monte Carlo heavy ion event generator
JEWEL (Jet Evolution With Energy Loss) including the boson-jet production
channels and also background subtraction techniques to reduce the effect of the
thermal background. Keeping track of these jet-medium recoils in JEWEL due to
the background subtraction techniques significantly improves its descriptions
of several jet structure and sub-structure measurements at the LHC. [Shortened
abstract]
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:38:05 GMT""}]","2018-03-13"
"1803.03687","Joris Kenanian","Joris Kenanian and Ayca Balkan and Raphael M. Jungers and Paulo
  Tabuada","Data Driven Stability Analysis of Black-box Switched Linear Systems",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Can we conclude the stability of an unknown dynamical system from the
knowledge of a finite number of snapshots of trajectories? We tackle this
black-box problem for switched linear systems. We show that, for any given
random set of observations, one can give probabilistic stability guarantees.
The probabilistic nature of these guarantees implies a trade-off between their
quality and the desired level of confidence. We provide an explicit way of
computing the best stability-like guarantee, as a function of both the number
of observations and the required level of confidence. Our proof techniques rely
on geometrical analysis, chance-constrained optimization, and stability
analysis tools for switched systems, including the joint spectral radius.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:38:17 GMT""},{""version"":""v2"",""created"":""Mon, 23 Jul 2018 03:26:38 GMT""}]","2018-07-24"
"1803.03688","Alberto Delm\'as","Alberto Delmas, Patrick Judd, Dylan Malone Stuart, Zissis Poulos,
  Mostafa Mahmoud, Sayeh Sharify, Milos Nikolic, Andreas Moshovos","Bit-Tactical: Exploiting Ineffectual Computations in Convolutional
  Neural Networks: Which, Why, and How","An earlier version of this work titled ""JaZ: Enabling Innovation
  Towards Chaff-Free Deep Learning Computing"" was submitted for blind review",,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that, during inference with Convolutional Neural Networks (CNNs),
more than 2x to $8x ineffectual work can be exposed if instead of targeting
those weights and activations that are zero, we target different combinations
of value stream properties. We demonstrate a practical application with
Bit-Tactical (TCL), a hardware accelerator which exploits weight sparsity, per
layer precision variability and dynamic fine-grain precision reduction for
activations, and optionally the naturally occurring sparse effectual bit
content of activations to improve performance and energy efficiency. TCL
benefits both sparse and dense CNNs, natively supports both convolutional and
fully-connected layers, and exploits properties of all activations to reduce
storage, communication, and computation demands. While TCL does not require
changes to the CNN to deliver benefits, it does reward any technique that would
amplify any of the aforementioned weight and activation value properties.
Compared to an equivalent data-parallel accelerator for dense CNNs, TCLp, a
variant of TCL improves performance by 5.05x and is 2.98x more energy efficient
while requiring 22% more area.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:40:35 GMT""}]","2018-03-13"
"1803.03689","Matija Bucic","Matija Buci\'c, Shoham Letzter and Benny Sudakov","Three colour bipartite Ramsey number of cycles and paths","15 pages, 3 figures",,"10.1002/jgt.22463",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $k$-colour bipartite Ramsey number of a bipartite graph $H$ is the least
integer $n$ for which every $k$-edge-coloured complete bipartite graph
$K_{n,n}$ contains a monochromatic copy of $H$. The study of bipartite Ramsey
numbers was initiated, over 40 years ago, by Faudree and Schelp and,
independently, by Gy\'arf\'as and Lehel, who determined the $2$-colour Ramsey
number of paths. In this paper we determine asymptotically the $3$-colour
bipartite Ramsey number of paths and (even) cycles.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:41:43 GMT""},{""version"":""v2"",""created"":""Tue, 6 Aug 2019 09:35:36 GMT""}]","2019-08-07"
"1803.03690","Kelly Backes","L. Zhong, S. Al Kenany, K.M. Backes, B.M. Brubaker, S.B. Cahn, G.
  Carosi, Y.V. Gurevich, W.F. Kindel, S.K. Lamoreaux, K.W. Lehnert, S.M. Lewis,
  M. Malnou, R.H. Maruyama, D.A. Palken, N.M. Rapidis, J.R. Root, M.
  Simanovskaia, T.M. Shokair, D.H. Speller, I. Urdinaran, K.A. van Bibber","Results from phase 1 of the HAYSTAC microwave cavity axion experiment",,"Phys. Rev. D 97, 092001 (2018)","10.1103/PhysRevD.97.092001",,"hep-ex physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the results from a search for dark matter axions with the
HAYSTAC experiment using a microwave cavity detector at frequencies between
5.6-5.8$\, \rm Ghz$. We exclude axion models with two photon coupling
$g_{a\gamma\gamma}\,\gtrsim\,2\times10^{-14}\,\rm GeV^{-1}$, a factor of 2.7
above the benchmark KSVZ model over the mass range 23.15$\,<\,$$m_a
\,$<$\,$24.0$\,\mu\rm eV$. This doubles the range reported in our previous
paper. We achieve a near-quantum-limited sensitivity by operating at a
temperature $T<h\nu/2k_B$ and incorporating a Josephson parametric amplifier
(JPA), with improvements in the cooling of the cavity further reducing the
experiment's system noise temperature to only twice the Standard Quantum Limit
at its operational frequency, an order of magnitude better than any other dark
matter microwave cavity experiment to date. This result concludes the first
phase of the HAYSTAC program utilizing a conventional copper cavity and a
single JPA.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:45:10 GMT""}]","2018-05-09"
"1803.03691","Gregory L. Eyink","Gregory L. Eyink","Cascades and Dissipative Anomalies in Nearly Collisionless Plasma
  Turbulence","Several additions have been made that were requested by the referees
  of the PRX submission. In particular, discussion previously relegated to
  Supplemental Materials are now included in the main text as appendices","Phys. Rev. X 8, 041020 (2018)","10.1103/PhysRevX.8.041020",,"physics.plasm-ph astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop first-principles theory of kinetic plasma turbulence governed by
the Vlasov-Maxwell-Landau equations in the limit of vanishing collision rates.
Following an exact renormalization-group approach pioneered by Onsager, we
demonstrate the existence of a ""collisionless range"" of scales (lengths and
velocities) in 1-particle phase space where the ideal Vlasov-Maxwell equations
are satisfied in a ""coarse-grained sense"". Entropy conservation may
nevertheless be violated in that range by a ""dissipative anomaly"" due to
nonlinear entropy cascade. We derive ""4/5th-law"" type expressions for the
entropy flux, which allow us to characterize the singularities
(structure-function scaling exponents) required for its non-vanishing.
Conservation laws of mass, momentum and energy are not afflicted with anomalous
transfers in the collisionless limit. In a subsequent limit of small gyroradii,
however, anomalous contributions to inertial-range energy balance may appear
due both to cascade of bulk energy and to turbulent redistribution of internal
energy in phase space. In that same limit the ""generalized Ohm's law"" derived
from the particle momentum balances reduces to an ""ideal Ohm's law"", but only
in a coarse-grained sense that does not imply magnetic flux-freezing and that
permits magnetic reconnection at all inertial-range scales. We compare our
results with prior theory based on the gyrokinetic (high gyro-frequency) limit,
with numerical simulations, and with spacecraft measurements of the solar wind
and terrestrial magnetosphere.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:52:07 GMT""},{""version"":""v2"",""created"":""Sat, 12 May 2018 21:03:24 GMT""},{""version"":""v3"",""created"":""Wed, 11 Jul 2018 21:05:36 GMT""},{""version"":""v4"",""created"":""Fri, 28 Sep 2018 18:31:44 GMT""}]","2018-11-14"
"1803.03692","Zhinus Marzi","Zhinus Marzi, Joao Hespanha and Upamanyu Madhow","On the information in spike timing: neural codes derived from
  polychronous groups",,,,,"q-bio.NC cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is growing evidence regarding the importance of spike timing in neural
information processing, with even a small number of spikes carrying
information, but computational models lag significantly behind those for rate
coding. Experimental evidence on neuronal behavior is consistent with the
dynamical and state dependent behavior provided by recurrent connections. This
motivates the minimalistic abstraction investigated in this paper, aimed at
providing insight into information encoding in spike timing via recurrent
connections. We employ information-theoretic techniques for a simple reservoir
model which encodes input spatiotemporal patterns into a sparse neural code,
translating the polychronous groups introduced by Izhikevich into codewords on
which we can perform standard vector operations. We show that the distance
properties of the code are similar to those for (optimal) random codes. In
particular, the code meets benchmarks associated with both linear
classification and capacity, with the latter scaling exponentially with
reservoir size.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:53:31 GMT""}]","2018-03-13"
"1803.03693","Esra Bulbul","Esra Bulbul, Adam Foster, Gregory V. Brown, Mark W. Bautz, Peter
  Beiersdorfer, Natalie Hell, Caroline Kilbourne, Ralph Kraft, Richard Kelley,
  Maurice A. Leutenegger, Eric D. Miller, F. Scott Porter, and Randall K. Smith","Laboratory Measurements of X-Ray Emission from Highly Charged Argon Ions","Accepted for publication in ApJ. 11 pages, 5 figures",,"10.3847/1538-4357/aaee7d",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Uncertainties in atomic models will introduce noticeable additional
systematics in calculating the flux of weak dielectronic recombination (DR)
satellite lines, affecting the detection and flux measurements of other weak
spectral lines. One important example is the Ar XVII He-beta DR, which is
expected to be present in emission from the hot intracluster medium (ICM) of
galaxy clusters and could impact measurements of the flux of the 3.5 keV line
that has been suggested as a secondary emission from a dark matter interaction.
We perform a set of experiments using the Lawrence Livermore National
Laboratory's electron beam ion trap (EBIT-I) and the X-Ray Spectrometer quantum
calorimeter (XRS/EBIT), to test the Ar XVII He-beta DR origin of the 3.5 keV
line. We measured the X-ray emission following resonant DR onto helium-like and
lithium-like Argon using EBIT-I's Maxwellian simulator mode at a simulated
electron temperature of Te=1.74 keV. The measured flux of the Ar XVII He-beta
DR lined is too weak to account for the flux in the 3.5 keV line assuming
reasonable plasma parameters. We, therefore, rule out Ar XVII He-beta DR as a
significant contributor to the 3.5 keV line. A comprehensive comparison between
the atomic theory and the EBIT experiment results is also provided.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:03:33 GMT""},{""version"":""v2"",""created"":""Sat, 3 Nov 2018 01:16:17 GMT""}]","2019-01-09"
"1803.03694","Yichen Zhang","Yichen Zhang and M. Ehsan Raoufat and Kevin Tomsovic and Seddik M.
  Djouadi","Set Theory-Based Safety Supervisory Control for Wind Turbines to Ensure
  Adequate Frequency Response",,,,,"cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inadequate frequency response can arise due to a high penetration of wind
turbine generators (WTGs) and requires a frequency support function to be
integrated in the WTG. The appropriate design for these controllers to ensure
adequate response has not been investigated thoroughly. In this paper, a safety
supervisory control (SSC) is proposed to synthesize the supportive modes in
WTGs to guarantee performance. The concept, region of safety (ROS), is stated
for safe switching synthesis. An optimization formula is proposed to calculate
the largest ROS. By assuming a polynomial structure, the problem can be solved
by a sum of squares program. A feasible result will generate a polynomial, the
zero sublevel set of which represents the ROS and is employed as the safety
supervisor. A decentralized communication architecture is proposed for
small-scale systems. Moreover, a scheduling loop is suggested so that the
supervisor updates its boundary with respect to the renewable penetration level
to be robust with respect to variations in system inertia. The proposed
controller is first verified on a single-machine three-phase nonlinear
microgrid, and then implemented on the IEEE 39-bus system. Both results
indicate that the proposed framework and control configuration can guarantee
adequate response without excessive conservativeness.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:14:12 GMT""},{""version"":""v2"",""created"":""Tue, 28 Aug 2018 00:48:43 GMT""}]","2018-08-29"
"1803.03695","Max Nendel","Max Nendel","Markov chains under nonlinear expectation","A new section has been added, where price bounds for European
  contingent claims under model uncertainty are computed. 26 pages, 4 figures",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider continuous-time Markov chains with a finite state
space under nonlinear expectations. We define so-called Q-operators as an
extension of Q-matrices or rate matrices to a nonlinear setup, where the
nonlinearity is due to model uncertainty. The main result gives a full
characterization of convex Q-operators in terms of a positive maximum
principle, a dual representation by means of Q-matrices, continuous-time Markov
chains under convex expectations and nonlinear ordinary differential equations.
This extends a classical characterization of generators of Markov chains to the
case of model uncertainty in the generator. We further derive a primal and dual
representation of the convex semigroup arising from a Markov chain under a
convex expectation via the Fenchel-Legendre transformation of its generator. We
illustrate the results with several numerical examples, where we compute price
bounds for European contingent claims under model uncertainty in terms of the
rate matrix.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:14:27 GMT""},{""version"":""v2"",""created"":""Tue, 15 Oct 2019 21:30:14 GMT""}]","2019-10-17"
"1803.03696","Dong Ye","Yezhou Wu and Dong Ye","Minimum $T$-Joins and Signed-Circuit Covering",,,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be a graph and $T$ be a vertex subset of $G$ with even cardinality. A
$T$-join of $G$ is a subset $J$ of edges such that a vertex of $G$ is incident
with an odd number of edges in $J$ if and only if the vertex belongs to $T$.
Minimum $T$-joins have many applications in combinatorial optimizations. In
this paper, we show that a minimum $T$-join of a connected graph $G$ has at
most $|E(G)|-\frac 1 2 |E(\widehat{\, G\,})|$ edges where $\widehat{\,G\,}$ is
the maximum bidegeless subgraph of $G$. Further, we are able to use this result
to show that every flow-admissible signed graph $(G,\sigma)$ has a
signed-circuit cover with length at most $\frac{19} 6 |E(G)|$. Particularly, a
2-edge-connected signed graph $(G,\sigma)$ with even negativeness has a
signed-circuit cover with length at most $\frac 8 3 |E(G)|$.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:23:23 GMT""}]","2018-03-13"
"1803.03697","Srijan Kumar","Srijan Kumar, William L. Hamilton, Jure Leskovec, Dan Jurafsky","Community Interaction and Conflict on the Web","In WWW 2018: The Web Conference. Project website with data and code
  is https://snap.stanford.edu/conflict/",,"10.1145/3178876.3186141",,"cs.SI cs.CL cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Users organize themselves into communities on web platforms. These
communities can interact with one another, often leading to conflicts and toxic
interactions. However, little is known about the mechanisms of interactions
between communities and how they impact users.
  Here we study intercommunity interactions across 36,000 communities on
Reddit, examining cases where users of one community are mobilized by negative
sentiment to comment in another community. We show that such conflicts tend to
be initiated by a handful of communities---less than 1% of communities start
74% of conflicts. While conflicts tend to be initiated by highly active
community members, they are carried out by significantly less active members.
We find that conflicts are marked by formation of echo chambers, where users
primarily talk to other users from their own community. In the long-term,
conflicts have adverse effects and reduce the overall activity of users in the
targeted communities.
  Our analysis of user interactions also suggests strategies for mitigating the
negative impact of conflicts---such as increasing direct engagement between
attackers and defenders. Further, we accurately predict whether a conflict will
occur by creating a novel LSTM model that combines graph embeddings, user,
community, and text features. This model can be used toreate early-warning
systems for community moderators to prevent conflicts. Altogether, this work
presents a data-driven view of community interactions and conflict, and paves
the way towards healthier online communities.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:26:13 GMT""}]","2018-03-13"
"1803.03698","Samuel Bloom","Samuel Bloom","Almost prime values of the order of abelian varieties over finite fields","27 pages; comments welcome!",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $E/\mathbb Q$ be an elliptic curve, and denote by $N(p)$ the number of
$\mathbb{F}_p$-points of the reduction modulo $p$ of $E$. A conjecture of
Koblitz, refined by Zywina, states that the number of primes $p \leq X$ at
which $N(p)$ is also prime is asymptotic to $C_E \cdot X / \log(X)^2$, where
$C_E$ is an arithmetically-defined non-negative constant. Following Miri-Murty
(2001) and others, Y.R. Liu (2006) and David-Wu (2012) study the number of
prime factors of $N(p)$. We generalize their arguments to abelian varieties $A
/ \mathbb Q$ whose adelic Galois representation has open image in
$\textrm{GSp}_{2g} \widehat{\mathbb Z}$. Our main result, after David-Wu, finds
a conditional lower bound on the number of primes at which $\# A_p (
\mathbb{F}_p)$ has few prime factors. We also present some experimental
evidence in favor of a generalization of Koblitz's conjecture to this context.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:33:57 GMT""}]","2018-03-13"
"1803.03699","Micha{\l} Pop{\l}awski","Marek Balcerzak, Micha{\l} Pop{\l}awski and Artur Wachowicz","Ideal convergent subseries in Banach spaces",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Assume that $\mathcal{I}$ is an ideal on $\mathbb{N}$, and $\sum_n x_n$ is a
divergent series in a Banach space $X$. We study the Baire category, and the
measure of the set $A(\mathcal{I}):=\left\{t \in \{0,1\}^{\mathbb{N}} \colon
\sum_n t(n)x_n \textrm{ is } \mathcal{I}\textrm{-convergent}\right\}$. In the
category case, we assume that $\mathcal{I}$ has the Baire property and $\sum_n
x_n$ is not unconditionally convergent, and we deduce that $A(\mathcal{I})$ is
meager. We also study the smallness of $A(\mathcal{I})$ in the measure case
when the Haar probability measure $\lambda$ on $\{0,1\}^{\mathbb{N}}$ is
considered. If $\mathcal{I}$ is analytic or coanalytic, and $\sum_n x_n$ is
$\mathcal{I}$-divergent, then $\lambda(A(\mathcal{I}))=0$ which extends the
theorem of Dindo\v{s}, \v{S}al\'at and Toma. Generalizing one of their
examples, we show that, for every ideal $\mathcal{I}$ on $\mathbb{N}$, with the
property of long intervals, there is a divergent series of reals such that
$\lambda(A(Fin))=0$ and $\lambda(A(\mathcal{I}))=1$.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:34:00 GMT""}]","2018-03-13"
"1803.03700","Mariusz Niew\k{e}g{\l}owski","Tomasz R. Bielecki, Jacek Jakubowski, Monique Jeanblanc, Mariusz
  Niew\k{e}g{\l}owski","Semimartingales and Shrinkage of Filtration",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a complete probability space $(\Omega,\mathcal{F},\mathbb{P})$,
which is endowed with two filtrations, $\mathbb{G}$ and $\mathbb{F}$, assumed
to satisfy the usual conditions and such that $\mathbb{F} \subset \mathbb{G}$.
On this probability space we consider a real valued special
$\mathbb{G}$-semimartingale $X$. The purpose of this work is to study the
following two problems:
  A. If $X$ is $\mathbb{F}$-adapted, compute the $\mathbb{F}$-semimartingale
characteristics of $X$ in terms of the $\mathbb{G}$-semimartingale
characteristics of $X$.
  B. If $X$ is not $\mathbb{F}$-adapted, given that the $\mathbb{F}$-optional
projection of $X$ is a special semimartingale, compute the
$\mathbb{F}$-semimartingale characteristics of $\mathbb{F}$-optional projection
of $X$ in terms of the $\mathbb{G}$-canonical decomposition and
$\mathbb{G}$-semimartingale characteristics of $X$.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:34:37 GMT""},{""version"":""v2"",""created"":""Wed, 15 May 2019 09:00:28 GMT""},{""version"":""v3"",""created"":""Wed, 20 Nov 2019 15:18:28 GMT""}]","2019-11-21"
"1803.03701","Apoen\~a Passos Passamani","Stefano Montaldo, Irene I. Onnis, Apoena Passos Passamani","Biharmonic constant mean curvature surfaces in Killing submersions","14 pages",,"10.1016/j.geomphys.2018.05.028",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A $3$-dimensional Riemannian manifold is called Killing submersion if it
admits a Riemannian submersion over a surface such that its fibers are the
trajectories of a complete unit Killing vector field. In this paper, we give a
characterization of proper biharmonic CMC surfaces in a Killing submersion. In
the last part, we also classify the proper biharmonic Hopf cylinders in a
Killing submersion.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:36:42 GMT""}]","2018-09-26"
"1803.03702","Sven M\""oller","Sven M\""oller","Orbifold Vertex Operator Algebras and the Positivity Condition","10 pages, LaTeX; comments welcome",,,,"math.QA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we show that the irreducible twisted modules of a holomorphic,
$C_2$-cofinite vertex operator algebra $V$ have $L_0$-weights at least as large
as the smallest $L_0$-weight of $V$. Hence, if $V$ is of CFT-type, then the
twisted $V$-modules are almost strictly positively graded. This in turn implies
that the fixed-point vertex operator subalgebra $V^G$ for a finite, solvable
group of automorphisms of $V$ almost satisfies the positivity condition. These
and some further results are obtained by a careful analysis of Dong, Li and
Mason's twisted modular invariance.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:39:51 GMT""}]","2018-03-13"
"1803.03703","Yousef Bisabr","Yousef Bisabr","Gravitational Coupling and the Cosmological Constant","7 pages, no figure. To appear in IJMPD","Int. J. Mod. Phys. D 27, 1850086 (2018)","10.1142/S0218271818500864",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We deal with a dynamical mechanism in which a large cosmological constant, as
suggested by inflationary scenarios, decays due to expansion of the universe.
This mechanism has its origin in the gravitational coupling of the vacuum
density. We assume that the vacuum couples anomalously to gravity that is the
metric tensor that appears the gravitational part is not the same as that
appears the matter part as suggested by weak equivalence principle. Instead,
the two metric tensors are taken to be conformally related. We show that this
provides a dynamical mechanism which works during expansion of the universe. We
also consider some observational consequences of such a gravitational model.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:48:03 GMT""}]","2018-06-05"
"1803.03704","Tereza Klimo\v{s}ov\'a","Tereza Klimo\v{s}ov\'a, St\'ephan Thomass\'e","Edge-decomposing graphs into coprime forests",,,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Barat-Thomassen conjecture, recently proved in [Bensmail et al.: A proof
of the Barat-Thomassen conjecture. J. Combin. Theory Ser. B, 124:39-55, 2017.],
asserts that for every tree T, there is a constant $c_T$ such that every
$c_T$-edge connected graph G with number of edges (size) divisible by the size
of T admits an edge partition into copies of T (a T-decomposition). In this
paper, we investigate in which case the connectivity requirement can be dropped
to a minimum degree condition. For instance, it was shown in [Bensmail et al.:
Edge-partitioning a graph into paths: beyond the Barat-Thomassen conjecture.
arXiv:1507.08208] that when T is a path with k edges, there is a constant $d_k$
such that every 24-edge connected graph G with size divisible by k and minimum
degree $d_k$ has a T-decomposition. We show in this paper that when F is a
coprime forest (the sizes of its components being a coprime set of integers),
any graph G with sufficiently large minimum degree has an F-decomposition
provided that the size of F divides the size of G (no connectivity is
required). A natural conjecture asked in [Bensmail et al.: Edge-partitioning a
graph into paths: beyond the Barat-Thomassen conjecture. arXiv:1507.08208]
asserts that for a fixed tree T, any graph G of size divisible by the size of T
with sufficiently high minimum degree has a T-decomposition, provided that G is
sufficiently highly connected in terms of the maximal degree of T. The case of
maximum degree 2 is answered by paths. We provide a counterexample to this
conjecture in the case of maximum degree 3.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:49:50 GMT""}]","2018-03-13"
"1803.03705","Saeed Mehrabi","Prosenjit Bose, Paz Carmi, Vida Dujmovic, Saeed Mehrabi, Fabrizio
  Montecchiani, Pat Morin, and Luis Fernando Schultz Xavier da Silveira","Geodesic Obstacle Representation of Graphs",,,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An obstacle representation of a graph is a mapping of the vertices onto
points in the plane and a set of connected regions of the plane (called
obstacles) such that the straight-line segment connecting the points
corresponding to two vertices does not intersect any obstacles if and only if
the vertices are adjacent in the graph. The obstacle representation and its
plane variant (in which the resulting representation is a plane straight-line
embedding of the graph) have been extensively studied with the main objective
of minimizing the number of obstacles. Recently, Biedl and Mehrabi (GD 2017)
studied grid obstacle representations of graphs in which the vertices of the
graph are mapped onto the points in the plane while the straight-line segments
representing the adjacency between the vertices is replaced by the $L_1$
(Manhattan) shortest paths in the plane that avoid obstacles.
  In this paper, we introduce the notion of geodesic obstacle representations
of graphs with the main goal of providing a generalized model, which comes
naturally when viewing line segments as shortest paths in the Euclidean plane.
To this end, we extend the definition of obstacle representation by allowing
some obstacles-avoiding shortest path between the corresponding points in the
underlying metric space whenever the vertices are adjacent in the graph. We
consider both general and plane variants of geodesic obstacle representations
(in a similar sense to obstacle representations) under any polyhedral distance
function in $\mathbb{R}^d$ as well as shortest path distances in graphs. Our
results generalize and unify the notions of obstacle representations, plane
obstacle representations and grid obstacle representations, leading to a number
of questions on such embeddings.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:54:48 GMT""}]","2018-03-13"
"1803.03706","Mika Sillanpaa","Alpo Valimaa, Jorge Santos, Caspar Ockeloen-Korppi, and Mika Sillanpaa","Electrode configuration and electrical dissipation of mechanical energy
  in quartz crystal resonators",,"J. Micromech. Microeng. 28 (2018) 095014","10.1088/1361-6439/aac781",,"physics.app-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mechanical resonators made with monolithic piezoelectric quartz crystals are
promising for studying new physical phenomena. High mechanical quality factors
($Q$) exhibited by the mm-sized quartz resonators make them ideal for studying
weak couplings or long timescales in the quantum regime. However, energy losses
through mechanical supports pose a serious limiting factor for obtaining high
quality factors. Here we investigate how the $Q$ of quartz resonators at deep
cryogenic temperatures can be limited by several types of losses related to
anchoring. We first introduce means to reduce the mechanical losses by more
than an order of magnitude in a no-clamping scheme, obtaining $Q$-factors of
$10^8$ of the lowest shear mode. We can exclude a wide coverage of aluminum
metallization on the disk or bond wires as sources of dissipation. However, we
find a dramatic reduction of the $Q$-factor accompanying an electrode
configuration that involves strong focusing of the vibrations in the disk
center. We propose a circuit model that accounts for the reduced mechanical
$Q$-factor in terms of electrical losses. In particular, we show how the
limiting factor for losses can be small ohmic dissipation in a grounding
connection, which can be interpreted as electrical anchor losses of the
mechanical device.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:00:37 GMT""}]","2018-06-21"
"1803.03707","John Cotrina","John Cotrina and Javier Z\'u\~niga","Quasi-Equilibrium Problems with Non-self Constraint Map","24 pages. arXiv admin note: substantial text overlap with
  arXiv:1801.08581",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 2016 Aussel, Sultana and Vetrivel developed the concept of projected
solution for quasi-variational inequality problems and projected Nash
equilibrium. We introduce a new concept of solution for quasi-equilibrium
problems and we study the existence of such solutions. Additionally, as a
consequence of our results, we give existence results of projected solutions
for quasi-optimization problems, quasi-variational inequalities problems and
generalized Nash equilibrium problems.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:02:37 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jan 2019 18:54:05 GMT""}]","2019-01-25"
"1803.03708","Jeffrey Bosboom","Jeffrey Bosboom, Erik D. Demaine, Mikhail Rudoy","Computational Complexity of Generalized Push Fight","27 pages, 35 figures",,,,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the computational complexity of optimally playing the two-player
board game Push Fight, generalized to an arbitrary board and number of pieces.
We prove that the game is PSPACE-hard to decide who will win from a given
position, even for simple (almost rectangular) hole-free boards. We also
analyze the mate-in-1 problem: can the player win in a single turn? One turn in
Push Fight consists of up to two ""moves"" followed by a mandatory ""push"". With
these rules, or generalizing the number of allowed moves to any constant, we
show mate-in-1 can be solved in polynomial time. If, however, the number of
moves per turn is part of the input, the problem becomes NP-complete. On the
other hand, without any limit on the number of moves per turn, the problem
becomes polynomially solvable again.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:10:17 GMT""}]","2018-03-13"
"1803.03709","Daniel Kosov","Vincent F. Kershaw and Daniel S. Kosov","Nonadiabatic corrections to electric current in molecular junction due
  to nuclear motion at the molecule-electrode interfaces",,"Journal of Chemical Physics 149, 044121 (2018)","10.1063/1.5028333",,"cond-mat.mes-hall physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present quantum electron transport theory that incorporates dynamical
effects of motion of atoms on electrode-molecule interfaces in the calculations
of the electric current. The theory is based on non-equilibrium Green's
functions. We separate time scales in the Green's functions on fast relative
time and slow central time. The derivative with respect to the central time
serves as a small parameter in the theory. We solve the real-time Kadanoff-Baym
equations for molecular Green's functions using Wigner representation and keep
terms up to the second order with respect to the central time derivatives.
Molecular Green's functions and consequently the electric current are expressed
as functions of molecular junction coordinates as well as velocities and
accelerations of molecule-electrode interface nuclei. We apply the theory to
model a molecular system and study the effects of non-adiabatic nuclear motion
on molecular junction conductivity.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:11:44 GMT""},{""version"":""v2"",""created"":""Sat, 19 May 2018 20:42:24 GMT""},{""version"":""v3"",""created"":""Thu, 19 Jul 2018 21:25:40 GMT""}]","2018-08-14"
"1803.03710","Hilton Barbosa de Aguiar","Stephen H. Donaldson Jr. and Hilton B. de Aguiar","Label-free imaging of cholesterol and lipid distributions in model
  membranes",,"J. Phys. Chem. Lett. 9, 1528-1533 (2018)","10.1021/acs.jpclett.8b00235",,"physics.bio-ph cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over recent decades, lipid membranes have become standard models for
examining the biophysics and biochemistry of cell membranes. Interrogation of
lipid domains within biomembranes is generally done with fluorescence
microscopy via exogenous chemical probes. However, most fluorophores have
limited partitioning tunability, with the majority segregating in the least
biologically relevant domains (i.e., low-density liquid domains). Therefore, a
molecular-level picture of the majority of non-labeled lipids forming the
membrane is still elusive. Here, we present simple, label-free imaging of
domain formation in lipid monolayers, with chemical selectivity in unraveling
lipid and cholesterol composition in all domain types. Exploiting conventional
vibrational contrast in spontaneous Raman imaging, combined with chemometrics
analysis, allows for examination of ternary systems containing saturated
lipids, unsaturated lipids, and cholesterol. We confirm features commonly
observed by fluorescence microscopy, and provide an unprecedented analysis of
cholesterol distribution at the single-membrane level.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:12:15 GMT""}]","2018-03-30"
"1803.03711","Pascal Getreuer","Frank Ong and Peyman Milanfar and Pascal Getreuer","Local Kernels that Approximate Bayesian Regularization and Proximal
  Operators",,,"10.1109/TIP.2019.2893071",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we broadly connect kernel-based filtering (e.g. approaches such
as the bilateral filters and nonlocal means, but also many more) with general
variational formulations of Bayesian regularized least squares, and the related
concept of proximal operators. The latter set of variational/Bayesian/proximal
formulations often result in optimization problems that do not have closed-form
solutions, and therefore typically require global iterative solutions. Our main
contribution here is to establish how one can approximate the solution of the
resulting global optimization problems with use of locally adaptive filters
with specific kernels. Our results are valid for small regularization strength
but the approach is powerful enough to be useful for a wide range of
applications because we expose how to derive a ""kernelized"" solution to these
problems that approximates the global solution in one-shot, using only local
operations. As another side benefit in the reverse direction, given a local
data-adaptive filter constructed with a particular choice of kernel, we enable
the interpretation of such filters in the variational/Bayesian/proximal
framework.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:19:38 GMT""}]","2019-05-01"
"1803.03712","Giuseppe A Pablo Cirrone","GAP Cirrone, G Cuttone, L Manti, D.Margarone, G Petringa, L.Giuffrida,
  A.Minopoli, A.Picciotto, G.Russo, F.Cammarata, P.Pisciotta, F.M.Perozziello,
  F.Romano, V.Marchese, G.Milluzzo, V.Scuderi, G.Cuttone and G. Korn","Response to the authors of 'On the (un)effectiveness of Proton Boron
  Capture in Proton Therapy'","Response to the paper arXiv:1802.09482v2",,,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This manuscript provides a response to a recent report by Mazzone et al.
available online on arXiv that, in turn, tentatively aims at demonstrating the
inefficacy of proton boron capture in hadrotherapy. We clarify that Mazzone et
al. do not add any scientific or technical insights to the points extensively
discussed in the original manuscript by Cirrone et al., and/or in the series of
iterations had with the Referee, which ultimately lead to the publication of
our original and pioneering experimental work. Here we summarize some of the
key points of the long scientific debate we had during the review process of
paper by Cirrone et al., which are very similar to the considerations presented
by Mazzone et al.. In conclusion, no quantitative explanation of our robust
experimental achievements presented in Cirrone et al. is provided in Mazzone et
al.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:24:46 GMT""}]","2018-03-13"
"1803.03713","Dvira Segal","Dvira Segal","Current fluctuations in quantum absorption refrigerators",,"Phys. Rev. E 97, 052145 (2018)","10.1103/PhysRevE.97.052145",,"cond-mat.mes-hall cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Absorption refrigerators transfer thermal energy from a cold bath to a hot
bath without input power by utilizing heat from an additional ""work"" reservoir.
Particularly interesting is a three-level design for a quantum absorption
refrigerator, which can be optimized to reach the maximal (Carnot) cooling
efficiency. Previous studies of three-level chillers focused on the behavior of
the averaged cooling current. Here, we go beyond that and study the full
counting statistics of heat exchange in a three-level chiller model. We explain
how to obtain the complete cumulant generating function of the refrigerator in
steady state, then derive a partial cumulant generating function, which yields
closed-form expressions for both the averaged cooling current and its noise.
Our analytical results and simulations are beneficial for the design of
nanoscale engines and cooling systems far from equilibrium, with their
performance optimized according to different criteria, efficiency, power,
fluctuations and dissipation.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:29:18 GMT""},{""version"":""v2"",""created"":""Wed, 16 May 2018 20:21:27 GMT""}]","2018-06-06"
"1803.03714","Emrah  Bostan Mr.","Emrah Bostan, Mahdi Soltanolkotabi, David Ren, Laura Waller","Accelerated Wirtinger Flow for Multiplexed Fourier Ptychographic
  Microscopy","10 pages, 3 figures",,,,"eess.SP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fourier ptychographic microscopy enables gigapixel-scale imaging, with both
large field-of-view and high resolution. Using a set of low-resolution images
that are recorded under varying illumination angles, the goal is to
computationally reconstruct high-resolution phase and amplitude images. To
increase temporal resolution, one may use multiplexed measurements where the
sample is illuminated simultaneously from a subset of the angles. In this
paper, we develop an algorithm for Fourier ptychographic microscopy with such
multiplexed illumination. Specifically, we consider gradient descent type
updates and propose an analytical step size that ensures the convergence of the
iterates to a stationary point. Furthermore, we propose an accelerated version
of our algorithm (with the same step size) which significantly improves the
convergence speed. We demonstrate that the practical performance of our
algorithm is identical to the case where the step size is manually tuned.
Finally, we apply our parameter-free approach to real data and validate its
applicability.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:43:14 GMT""}]","2018-03-13"
"1803.03715","Jos\'e Roberto Nicol\'as Carlock","J. R. Nicol\'as-Carlock, J. M. Solano-Altamirano, and J. L.
  Carrillo-Estrada","The dynamics of the angular and radial density correlation scaling
  exponents in fractal to non-fractal morphodynamics",,,,,"nlin.PS cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fractal/non-fractal morphological transitions allow for the systematic study
of the physics behind fractal morphogenesis in nature. In these systems, the
fractal dimension is considered a non-thermal order parameter, commonly and
equivalently computed from the scaling of the two-point radial- or
angular-density correlations. However, these two quantities lead to
discrepancies during the analysis of basic systems, such as in the
diffusion-limited aggregation fractal. Hence, the corresponding clarification
regarding the limits of the radial/angular scaling equivalence is needed. In
this work, considering three fundamental fractal/non-fractal transitions in two
dimensions, we show that the unavoidable emergence of growth anisotropies is
responsible for the breaking-down of the radial/angular equivalence.
Specifically, we show that the angular scaling behaves as a critical power-law,
whereas the radial scaling as an exponential that, under the fractal dimension
interpretation, resemble first- and second-order transitions, respectively.
Remarkably, these and previous results can be unified under a single fractal
dimensionality equation.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:59:19 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jul 2019 02:00:11 GMT""},{""version"":""v3"",""created"":""Fri, 24 Jan 2020 04:45:40 GMT""}]","2020-01-27"
"1803.03716","Pedram Gharani","Pedram Gharani, Kenrick Fernande, Vineet Raghu","TRAJEDI: Trajectory Dissimilarity",,,"10.1007/978-3-319-98923-5_8",,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The vast increase in our ability to obtain and store trajectory data
necessitates trajectory analytics techniques to extract useful information from
this data. Pair-wise distance functions are a foundation building block for
common operations on trajectory datasets including constrained SELECT queries,
k-nearest neighbors, and similarity and diversity algorithms. The accuracy and
performance of these operations depend heavily on the speed and accuracy of the
underlying trajectory distance function, which is in turn affected by
trajectory calibration. Current methods either require calibrated data, or
perform calibration of the entire relevant dataset first, which is expensive
and time consuming for large datasets. We present TRAJEDI, a calibrationaware
pair-wise distance calculation scheme that outperforms naive approaches while
preserving accuracy. We also provide analyses of parameter tuning to trade-off
between speed and accuracy. Our scheme is usable with any diversity, similarity
or k-nearest neighbor algorithm.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 23:07:09 GMT""}]","2018-12-19"
"1803.03717","Howard Elman","Howard C. Elman and Tengfei Su","Low-Rank Solution Methods for Stochastic Eigenvalue Problems",,,,,"math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study efficient solution methods for stochastic eigenvalue problems
arising from discretization of self-adjoint partial differential equations with
random data. With the stochastic Galerkin approach, the solutions are
represented as generalized polynomial chaos expansions. A low-rank variant of
the inverse subspace iteration algorithm is presented for computing one or
several minimal eigenvalues and corresponding eigenvectors of
parameter-dependent matrices. In the algorithm, the iterates are approximated
by low-rank matrices, which leads to significant cost savings. The algorithm is
tested on two benchmark problems, a stochastic diffusion problem with some
poorly separated eigenvalues, and an operator derived from a discrete
stochastic Stokes problem whose minimal eigenvalue is related to the inf-sup
stability constant. Numerical experiments show that the low-rank algorithm
produces accurate solutions compared to the Monte Carlo method, and it uses
much less computational time than the original algorithm without low-rank
approximation.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 23:09:56 GMT""}]","2018-03-13"
"1803.03718","Jennifer Schloss","Jennifer M. Schloss, John F. Barry, Matthew J. Turner, and Ronald L.
  Walsworth","Simultaneous Broadband Vector Magnetometry Using Solid-State Spins","13 pages, 5 figures, 1 table, Supplemental Material included as
  ancillary file","Phys. Rev. Applied 10, 034044 (2018)","10.1103/PhysRevApplied.10.034044",,"quant-ph cond-mat.mes-hall physics.app-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate a vector magnetometer that simultaneously measures all
Cartesian components of a dynamic magnetic field using an ensemble of
nitrogen-vacancy (NV) centers in a single-crystal diamond. Optical NV-diamond
measurements provide high-sensitivity, broadband magnetometry under ambient or
extreme physical conditions; and the fixed crystallographic axes inherent to
this solid-state system enable vector sensing free from heading errors. In the
present device, multi-channel lock-in detection extracts the
magnetic-field-dependent spin resonance shifts of NVs oriented along all four
tetrahedral diamond axes from the optical signal measured on a single detector.
The sensor operates from near DC up to a $12.5$ kHz measurement bandwidth; and
simultaneously achieves $\sim\!50$ pT/$\sqrt{\text{Hz}}$ magnetic field
sensitivity for each Cartesian component, which is to date the highest
demonstrated sensitivity of a full vector magnetometer employing solid-state
spins. Compared to optimized devices interrogating the four NV orientations
sequentially, the simultaneous vector magnetometer enables a $4\times$
measurement speedup. This technique can be extended to pulsed-type sensing
protocols and parallel wide-field magnetic imaging.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 23:23:01 GMT""},{""version"":""v2"",""created"":""Mon, 26 Mar 2018 17:13:48 GMT""}]","2018-09-26"
"1803.03719","Pooyan Fazli","Mahmoud Hamandi, Mike D'Arcy, and Pooyan Fazli","DeepMoTIon: Learning to Navigate Like Humans","7 pages, In Proceedings of the IEEE International Conference on Robot
  and Human Interactive Communication, RO-MAN 2019",,,,"cs.RO cs.AI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel human-aware navigation approach, where the robot learns to
mimic humans to navigate safely in crowds. The presented model, referred to as
DeepMoTIon, is trained with pedestrian surveillance data to predict human
velocity in the environment. The robot processes LiDAR scans via the trained
network to navigate to the target location. We conduct extensive experiments to
assess the components of our network and prove their necessity to imitate
humans. Our experiments show that DeepMoTIion outperforms all the benchmarks in
terms of human imitation, achieving a 24% reduction in time series-based path
deviation over the next best approach. In addition, while many other approaches
often failed to reach the target, our method reached the target in 100% of the
test cases while complying with social norms and ensuring human safety.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 23:36:38 GMT""},{""version"":""v2"",""created"":""Sat, 2 Mar 2019 09:36:46 GMT""},{""version"":""v3"",""created"":""Thu, 1 Aug 2019 23:48:46 GMT""}]","2019-08-05"
"1803.03720","Baole Wen","Baole Wen and Gregory P. Chini","Reduced modeling of porous media convection in a minimal flow unit at
  large Rayleigh number",,,"10.1016/j.jcp.2018.06.001",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Direct numerical simulations (DNS) indicate that at large values of the
Rayleigh number ($Ra$) convection in porous media self-organizes into
narrowly-spaced columnar flows, with more complex spatiotemporal features being
confined to boundary layers near the top and bottom walls. In this
investigation of high-$Ra$ porous media convection in a minimal flow unit, two
reduced modeling strategies are proposed that exploit these specific flow
characteristics. Both approaches utilize the idea of decomposition since the
flow exhibits different dynamics in different regions of the domain:
small-scale cellular motions generally are localized within the thermal and
vorticity boundary layers near the upper and lower walls, while in the
interior, the flow exhibits persistent large-scale structures and only a few
low (horizontal) wavenumber Fourier modes are active. Accordingly, in the first
strategy, the domain is decomposed into two near-wall regions and one interior
region. Our results confirm that suppressing the interior high-wavenumber modes
has negligible impact on the essential structural features and transport
properties of the flow. In the second strategy, a hybrid reduced model is
constructed by using Galerkin projection onto a fully \emph{a priori}
eigenbasis drawn from energy stability and upper bound theory, thereby
extending the model reduction strategy developed by Chini \emph{et al.}
(\emph{Physica~D}, vol. 240, 2011, pp. 241--248) to large $Ra$. The results
indicate that the near-wall upper-bound eigenmodes can economically represent
the small-scale rolls within the exquisitely-thin thermal boundary layers.
Relative to DNS, the hybrid algorithm enables over an order-of-magnitude
increase in computational efficiency with only a modest loss of accuracy.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 23:37:49 GMT""}]","2018-08-01"
"1803.03721","Gurpreet Singh","Gurpreet Singh, Wingtat Leung, Mary F. Wheeler","Multiscale Methods for Model Order Reduction of Non Linear Multiphase
  Flow Problems",,,,,"math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Numerical simulations for flow and transport in subsurface porous media often
prove computationally prohibitive due to property data availability at multiple
spatial scales that can vary by orders of magnitude. A number of model order
reduction approaches are available in the existing literature that alleviate
this issue by approximating the solution at a coarse scale. We attempt to
present a comparison between two such model order reduction techniques, namely:
(1) adaptive numerical homogenization and (2) generalized multiscale basis
functions. We rely upon a non-linear, multi-phase, black-oil model formulation,
commonly encountered in the oil and gas industry, as the basis for comparing
the aforementioned two approaches. An expanded mixed finite element formulation
is used to separate the spatial scales between non-linear, flow and transport
problems. To the author's knowledge this is the first time these approaches
have been described for a practical non-linear, multiphase flow problem of
interest. A numerical benchmark is setup using fine scale property information
from the 10$^{th}$ SPE comparative project dataset for the purpose of comparing
accuracies of these two schemes. An adaptive criterion is employed in by both
the schemes for local enrichment that allows us to preserve solution accuracy
compared to the fine scale benchmark problem. The numerical results indicate
that both schemes are able to adequately capture the fine scale features of the
model problem at hand.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 23:53:18 GMT""}]","2018-03-13"
"1803.03722","Jason Fulman","Jason Fulman and Nathan Kaplan","Random Partitions and Cohen-Lenstra Heuristics","21 pages, minor revisions to Section 5","Ann. Comb. 23 (2019), no. 2, 295-315","10.1007/s00026-019-00425-y",,"math.NT math.CO math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate combinatorial properties of a family of probability
distributions on finite abelian p-groups. This family includes several
well-known distributions as specializations. These specializations have been
studied in the context of Cohen-Lenstra heuristics and cokernels of families of
random p-adic matrices.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 23:56:36 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jan 2019 23:29:05 GMT""}]","2022-01-25"
"1803.03723","Mauricio Ayllon Unzueta","Mauricio Ayllon, Parker A. Adams, Joseph D. Bauer, Jon C. Batchelder,
  Tim A. Becker, Lee A. Bernstein, Su-Ann Chong, Jay James, Leo E. Kirsch,
  Ka-Ngo Leung, Eric F. Matthews, Jonathan T. Morrell, Paul R. Renne, Andrew M.
  Rogers, Daniel Rutte, Andrew S. Voyles, Karl Van Bibber, Cory S. Waltz","Design, construction, and characterization of a compact DD neutron
  generator designed for 40Ar/39Ar geochronology","31 pages, 20 figures",,"10.1016/j.nima.2018.04.020",,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A next-generation, high-flux DD neutron generator has been designed,
commissioned, and characterized, and is now operational in a new facility at
the University of California Berkeley. The generator, originally designed for
40Ar/39Ar dating of geological materials, has since served numerous additional
applications, including medical isotope production studies, with others planned
for the near future. In this work, we present an overview of the High Flux
Neutron Generator (HFNG) which includes a variety of simulations, analytical
models, and experimental validation of results. Extensive analysis was
performed in order to characterize the neutron yield, flux, and energy
distribution at specific locations where samples may be loaded for irradiation.
A notable design feature of the HFNG is the possibility for sample irradiation
internal to the cathode, just 8 mm away from the neutron production site, thus
maximizing the neutron flux (n/cm2/s). The generator's maximum neutron flux at
this irradiation position is 2.58e7 n/cm2/s +/- 5% (approximately 3e8 n/s total
yield) as measured via activation of small natural indium foils. However,
future development is aimed at achieving an order of magnitude increase in
flux. Additionally, the deuterium ion beam optics were optimized by simulations
for various extraction configurations in order to achieve a uniform neutron
flux distribution and an acceptable heat load. Finally, experiments were
performed in order to benchmark the modeling and characterization of the HFNG.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 23:58:40 GMT""},{""version"":""v2"",""created"":""Tue, 10 Apr 2018 00:24:01 GMT""}]","2018-10-17"
"1803.03724","Pablo Su\'arez-Serrato","P. Su\'arez-Serrato, E.I. Vel\'azquez Richards","Contour Parametrization via Anisotropic Mean Curvature Flows","30 pages, 20 images, source code for our numerical implementation is
  available in this URL https://github.com/V3du4rd0/AMCF",,,,"math.DG cs.CG cs.CV math.AP math.NA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present a new implementation of anisotropic mean curvature flow for
contour recognition. Our procedure couples the mean curvature flow of planar
closed smooth curves, with an external field from a potential of point-wise
charges. This coupling constrains the motion when the curve matches a picture
placed as background. We include a stability criteria for our numerical
approximation.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 00:05:01 GMT""}]","2018-03-13"
"1803.03725","Marios Xanthidis","Marios P. Xanthidis, Kostantinos J. Kyriakopoulos, and Ioannis
  Rekleitis","Dynamically Efficient Kinematics for Hyper-Redundant Manipulators","Published in the 24th Mediterranean Conference on Control and
  Automation (MED-2016)",,"10.1109/MED.2016.7535928",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A hyper-redundant robotic arm is a manipulator with many degrees of freedom,
capable of executing tasks in cluttered environments where robotic arms with
fewer degrees of freedom are unable to operate. This paper introduces a new
method for modeling those manipulators in a completely dynamic way. The
proposed method enables online changes of the kinematic structure with the use
of a special function; termed ""meta-controlling function"". This function can be
used to develop policies to reduce drastically the computational cost for a
single task, and to robustly control the robotic arm, even in the event of
partial damage. The direct and inverse kinematics are solved for a generic
three-dimensional articulated hyper-redundant arm, that can be used as a proof
of concept for more specific structures. To demonstrate the robustness of our
method, experimental simulation results, for a basic ""meta-controlling""
function, are presented.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 00:10:37 GMT""}]","2018-03-13"
"1803.03726","Graeme Milton","Graeme W. Milton","A new route to finding bounds on the generalized spectrum of many
  physical operators","39 pages 0 figures",,"10.1063/1.5032204",,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here we obtain bounds on the spectrum of that operator whose inverse, when it
exists, gives the Green's function. We consider the wide of physical problems
that can be cast in a form where a constitutive equation ${\bf J}({\bf x})={\bf
L}({\bf x}){\bf E}({\bf x})-{\bf h}({\bf x})$ with a source term ${\bf h}({\bf
x})$ holds for all ${\bf x}$ in some domain $\Omega$, and relates fields ${\bf
E}$ and ${\bf J}$ that satisfy appropriate differential constraints, symbolized
by ${\bf E}\in\cal{E}_\Omega$ and ${\bf J}\in\cal{J}_\Omega$ where
$\cal{E}_\Omega$ and $\cal{J}_\Omega$ are orthogonal spaces that span the space
$\cal{H}_\Omega$ of square-integrable fields in which ${\bf h}$ lies.
Boundedness and coercivity conditions on the moduli ${\bf L}({\bf x})$ ensure
there exists a unique ${\bf E}$ for any given ${\bf h}$, i.e., ${\bf E}={\bf
G}_\Omega{\bf h}$ which then establishes the existence of the Green's function
${\bf G}_\Omega$. We show that the coercivity condition is guaranteed to hold
if weaker conditions, involving generalized quasiconvex functions, are
satisfied. The advantage is that these weaker conditions are easier to verify,
and for multiphase materials they can be independent of the geometry of the
phases. For ${\bf L}({\bf x} )$ depending linearly on a vector of parameters
${\bf z}=(z_1, z_2,\ldots, z_n)$, we obtain constraints on ${\bf z}$ that
ensure the Green's function exists, and hence which provide bounds on the
spectrum.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 00:21:15 GMT""},{""version"":""v2"",""created"":""Tue, 3 Apr 2018 16:44:25 GMT""},{""version"":""v3"",""created"":""Fri, 1 Jun 2018 23:33:37 GMT""}]","2018-08-01"
"1803.03727","Md Arif Iqbal","Md Arif Iqbal, Naveen Kumar Macha, Wafi Danesh, Sehtab Hossain,
  Mostafizur Rahman","Thermal Management in Fine-Grained 3-D Integrated Circuits","9 Pages",,,,"cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For beyond 2-D CMOS logic, various 3-D integration approaches specially
transistor based 3-D integrations such as monolithic 3-D [1], Skybridge [2],
SN3D [3] holds most promise. However, such 3D architectures within small form
factor increase hotspots and demand careful consideration of thermal management
at all levels of integration [4] as stacked transistors are detached from the
substrate (i.e., heat sink). Traditional system level approaches such as liquid
cooling [5], heat spreader [6], etc. are inadequate for transistor level 3-D
integration and have huge cost overhead [7]. In this paper, we investigate the
thermal profile for transistor level 3-D integration approaches through finite
element based modeling. Additionally, we propose generic physical level heat
management features for such transistor level 3-D integration and show their
application through detailed thermal modeling and simulations. These features
include a thermal junction and heat conducting nano pillar. The heat junction
is a specialized junction to extract heat from a selected region in 3-D; it
allows heat conduction without interference with the electrical activities of
the circuit. In conjunction with the junction, our proposed thermal pillars
enable heat dissipation through the substrate; these pillars are analogous to
TSVs/Vias, but carry only heat. Such structures are generic and is applicable
to any transistor level 3-D integration approaches. We perform 3-D finite
element based analysis to capture both static and transient thermal behaviors
of 3-D circuits, and show the effectiveness of heat management features. Our
simulation results show that without any heat extraction feature, temperature
for 3-D integrated circuits increased by almost 100K-200K. However, proposed
heat extraction feature is very effective in heat management, reducing
temperature from heated area by up to 53%.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 00:31:34 GMT""}]","2018-03-13"
"1803.03728","Fabian Parsch","Fabian Parsch","Geodesic nets with three boundary vertices","further clarifications in proof of Special Combined Angle Lemma 3.6,
  clarified usage of Gauss-Bonnet in section 4, corrected typos, other minor
  edits",,,,"math.MG math.CO math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that a geodesic net with three boundary (= unbalanced) vertices on a
non-positively curved plane has at most one balanced vertex. We do not assume
any a priori bound for the degrees of unbalanced vertices. The result seems to
be new even in the Euclidean case. We demonstrate by examples that the result
is not true for metrics of positive curvature on the plane, and that there are
no immediate generalizations of this result for geodesic nets with four
unbalanced vertices.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 00:37:06 GMT""},{""version"":""v2"",""created"":""Thu, 15 Nov 2018 00:33:15 GMT""},{""version"":""v3"",""created"":""Thu, 21 Feb 2019 04:17:53 GMT""}]","2019-02-22"
"1803.03729","Jordan Malof","Jordan M. Malof, Daniel Reichman, Andrew Karem, Hichem Frigui, Dominic
  K. C. Ho, Joseph N. Wilson, Wen-Hsiung Lee, William Cummings, and Leslie M.
  Collins","A Large-Scale Multi-Institutional Evaluation of Advanced Discrimination
  Algorithms for Buried Threat Detection in Ground Penetrating Radar","IEEE Transactions on Geoscience and Remote Sensing (2019)",,"10.1109/TGRS.2019.2909665",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the development of algorithms for the automatic
detection of buried threats using ground penetrating radar (GPR) measurements.
GPR is one of the most studied and successful modalities for automatic buried
threat detection (BTD), and a large variety of BTD algorithms have been
proposed for it. Despite this, large-scale comparisons of GPR-based BTD
algorithms are rare in the literature. In this work we report the results of a
multi-institutional effort to develop advanced buried threat detection
algorithms for a real-world GPR BTD system. The effort involved five
institutions with substantial experience with the development of GPR-based BTD
algorithms. In this paper we report the technical details of the advanced
algorithms submitted by each institution, representing their latest technical
advances, and many state-of-the-art GPR-based BTD algorithms. We also report
the results of evaluating the algorithms from each institution on the large
experimental dataset used for development. The experimental dataset comprised
120,000 m^2 of GPR data using surface area, from 13 different lanes across two
US test sites. The data was collected using a vehicle-mounted GPR system, the
variants of which have supplied data for numerous publications. Using these
results, we identify the most successful and common processing strategies among
the submitted algorithms, and make recommendations for GPR-based BTD algorithm
design.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 00:37:44 GMT""},{""version"":""v2"",""created"":""Thu, 7 Jun 2018 18:49:29 GMT""}]","2019-05-16"
"1803.03730","Chas Beichman","Charles A. Beichman and Tom P. Greene","A White Paper Submitted to The National Academy of Science's Committee
  on Exoplanet Science Strategy: Observing Exoplanets with the James Webb Space
  Telescope","White Paper submitted to NAS Exoplanet Strategy Committee",,,,"astro-ph.IM astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The James Webb Space Telescope (JWST) will revolutionize our understanding of
exoplanets with transit spectroscopy of a wide range of mature planets close to
their host stars ($<$2 AU) and with coronagraphic imaging and spectroscopy of
young objects located further out ($>$10 AU). The census of exoplanets has
revealed an enormous variety of planets orbiting stars of all ages and spectral
types. With TESS adding to this census with its all-sky survey of the closest,
brightest stars, the challenge of the coming decade will be to move from
demography to physical characterization. This white paper discusses the wide
variety of exoplanet opportunities enabled by JWST's sensitivity and stability,
its high angular resolution, and its suite of powerful instruments. JWST
observations will advance our understanding of the atmospheres of young to
mature planets and will provide new insights into planet formation.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 00:48:23 GMT""}]","2018-03-14"
"1803.03731","Anthony DeGennaro","Anthony M. DeGennaro and Nathan M. Urban and Balasubramanya T. Nadiga
  and Terry Haut","Model Structural Inference using Local Dynamic Operators","30 pages, 14 figures",,"10.1615/Int.J.UncertaintyQuantification.2019025828",,"math.DS math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on the problem of quantifying the effects of
model-structure uncertainty in the context of time-evolving dynamical systems.
This is motivated by multi-model uncertainty in computer physics simulations:
developers often make different modeling choices in numerical approximations
and process simplifications, leading to different numerical codes that
ostensibly represent the same underlying dynamics. We consider model-structure
inference as a two-step methodology: the first step is to perform system
identification on numerical codes for which it is possible to observe the full
state; the second step is structural uncertainty quantification (UQ), in which
the goal is to search candidate models ""close"" to the numerical code surrogates
for those that best match a quantity-of-interest (QOI) from some empirical
dataset. Specifically, we: (1) define a discrete, local representation of the
structure of a partial differential equation, which we refer to as the ""local
dynamical operator"" (LDO); (2) identify model structure non-intrusively from
numerical code output; (3) non-intrusively construct a reduced order model
(ROM) of the numerical model through POD-DEIM-Galerkin projection; (4) perturb
the ROM dynamics to approximate the behavior of alternate model structures; and
(5) apply Bayesian inference and energy conservation laws to calibrate a LDO to
a given QOI. We demonstrate these techniques using the two-dimensional rotating
shallow water (RSW) equations as an example system.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 00:58:42 GMT""},{""version"":""v2"",""created"":""Thu, 31 Jan 2019 15:05:24 GMT""}]","2019-02-01"
"1803.03732","Slava G. Turyshev","Michael Shao, Slava G. Turyshev, Eduardo Bendek, Debra Fischer,
  Olivier Guyon, Barbara McArthur, Matthew Muterspaugh, Chengxing Zhai, and
  Celine Boehm","Precision Space Astrometry as a Tool to Find Earth-like Exoplanets","A White Paper to the National Academy of Sciences Committee on an
  Exoplanet Science Strategy Call for Papers. 6 pages, 2 figures, 1 table",,,,"astro-ph.IM astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Because of the recent technological advances, the key technologies needed for
precision space optical astrometry are now in hand. The Microarcsecond
Astrometry Probe (MAP) mission concept is designed to find 1 Earth mass planets
at 1AU orbit (scaled to solar luminosity) around the nearest ~90 FGK stars. The
MAP payload includes i) a single three-mirror anastigmatic telescope with a 1-m
primary mirror and metrology subsystems, and ii) a camera. The camera focal
plane consists of 42 detectors, providing a Nyquist sampled FOV of 0.4-deg. Its
metrology subsystems ensure that MAP can achieve the 0.8 uas astrometric
precision in 1 hr, which is required to detect Earth-like exoplanets in our
stellar neighborhood. MAP mission could provide ~10 specific targets for a much
larger coronagraphic mission that would measure its spectra. We argue for the
development of the space astrometric missions capable of finding Earth-2.0.
Given the current technology readiness such missions relying on precision
astrometry could be flown in the next decade, perhaps in collaboration with
other national space agencies.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 01:10:51 GMT""}]","2018-03-13"
"1803.03733","Jie Xu Dr.","Xiaowen Cao and Jie Xu and Rui Zhang","Mobile Edge Computing for Cellular-Connected UAV: Computation Offloading
  and Trajectory Optimization",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies a new mobile edge computing (MEC) setup where an unmanned
aerial vehicle (UAV) is served by cellular ground base stations (GBSs) for
computation offloading. The UAV flies between a give pair of initial and final
locations, during which it needs to accomplish certain computation tasks by
offloading them to some selected GBSs along its trajectory for parallel
execution. Under this setup, we aim to minimize the UAV's mission completion
time by optimizing its trajectory jointly with the computation offloading
scheduling, subject to the maximum speed constraint of the UAV, and the
computation capacity constraints at GBSs. The joint UAV trajectory and
computation offloading optimization problem is, however, non-convex and thus
difficult to be solved optimally. To tackle this problem, we propose an
efficient algorithm to obtain a high-quality suboptimal solution. Numerical
results show that the proposed design significantly reduces the UAV's mission
completion time, as compared to benchmark schemes.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 01:33:24 GMT""}]","2018-03-13"
"1803.03734","Jianhui Wang","Jianhui Wang, Jizhou He, and Yongli Ma","Quantum heat engine based on trapped Bose gases: Its maximum efficiency
  can approach the Carnot value at finite power","there is an error in our conclusion that the efficiency can approach
  the Carnot value at positive power",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It was reported that, if and only if the specific heat, correlation length,
and dynamical exponents $\alpha, \nu$ and $z$, fulfill the condition
$\alpha-z\nu>0$, the phase transitions can enable a quantum heat engine to
approach Carnot efficiency at finite power. We start our analysis via a
different approach in which the effects of interaction and fluctuations on the
Hamiltonian of a trapped dilute Bose gas belonging to the same universality as
$XY$ model. Based on models of quantum Otto heat engines, we find the general
expression of the efficiency which includes the correction due to interaction
and fluctuations at the critical point, and show that, near the
Bose-Einstein-condensation point with $\alpha-z\nu<0$, energy fluctuations
could enable attaintment of the Carnot efficiency with nonvanishing power. Such
quantum heat engines can also be realized by changing the shape of the trap
confining the ideal and weakly interacting Bose gas during the adiabatic
processes of the cycle. These quantum heat engines working with the trapped
Bose gases, which are based on techniques of cooling Bose condensates and could
be realizable at present technology.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 01:46:01 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 01:44:51 GMT""}]","2022-02-16"
"1803.03735","Kiran Koshy Thekumparampil","Kiran K. Thekumparampil, Chong Wang, Sewoong Oh, Li-Jia Li","Attention-based Graph Neural Network for Semi-supervised Learning",,,,,"stat.ML cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently popularized graph neural networks achieve the state-of-the-art
accuracy on a number of standard benchmark datasets for graph-based
semi-supervised learning, improving significantly over existing approaches.
These architectures alternate between a propagation layer that aggregates the
hidden states of the local neighborhood and a fully-connected layer. Perhaps
surprisingly, we show that a linear model, that removes all the intermediate
fully-connected layers, is still able to achieve a performance comparable to
the state-of-the-art models. This significantly reduces the number of
parameters, which is critical for semi-supervised learning where number of
labeled examples are small. This in turn allows a room for designing more
innovative propagation layers. Based on this insight, we propose a novel graph
neural network that removes all the intermediate fully-connected layers, and
replaces the propagation layers with attention mechanisms that respect the
structure of the graph. The attention mechanism allows us to learn a dynamic
and adaptive local summary of the neighborhood to achieve more accurate
predictions. In a number of experiments on benchmark citation networks
datasets, we demonstrate that our approach outperforms competing methods. By
examining the attention weights among neighbors, we show that our model
provides some interesting insights on how neighbors influence each other.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:01:35 GMT""}]","2018-03-13"
"1803.03736","Ebrahim Karami","Ebrahim Karami and Savo Glisic","Joint Optimization of Scheduling and Routing in Multicast Wireless
  Ad-Hoc Network Using Soft Graph Coloring and Non-linear Cubic Games","33 pages, 8 figures","IEEE Transactions on Vehicular Technology, vol 60, no. 7, Sept.
  2011","10.1109/TVT.2011.2161355",,"eess.SP cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present matrix game-theoretic models for joint routing,
network coding, and scheduling problem. First routing and network coding are
modeled by using a new approach based on compressed topology matrix that takes
into account the inherent multicast gain of the network. The scheduling is
optimized by a new approach called network graph soft coloring. Soft graph
coloring is designed by switching between different components of a wireless
network graph, which we refer to as graph fractals, with appropriate usage
rates. The network components, represented by graph fractals, are a new
paradigm in network graph partitioning that enables modeling of the network
optimization problem by using the matrix game framework. In the proposed game
which is a nonlinear cubic game, the strategy sets of the players are links,
path, and network components. The outputs of this game model are mixed strategy
vectors of the second and the third players at equilibrium. Strategy vector of
the second player specifies optimum multi-path routing and network coding
solution while mixed strategy vector of the third players indicates optimum
switching rate among different network components or membership probabilities
for optimal soft scheduling approach. Optimum throughput is the value of the
proposed nonlinear cubic game at equilibrium. The proposed nonlinear cubic game
is solved by extending fictitious playing method. Numerical and simulation
results prove the superior performance of the proposed techniques compared to
the conventional schemes using hard graph coloring.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:02:31 GMT""}]","2018-03-14"
"1803.03737","Xin Qiu","Xin Qiu and Risto Miikkulainen","Enhancing Evolutionary Conversion Rate Optimization via Multi-armed
  Bandit Algorithms","The Thirty-First Innovative Applications of Artificial Intelligence
  Conference",,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conversion rate optimization means designing web interfaces such that more
visitors perform a desired action (such as register or purchase) on the site.
One promising approach, implemented in Sentient Ascend, is to optimize the
design using evolutionary algorithms, evaluating each candidate design online
with actual visitors. Because such evaluations are costly and noisy, several
challenges emerge: How can available visitor traffic be used most efficiently?
How can good solutions be identified most reliably? How can a high conversion
rate be maintained during optimization? This paper proposes a new technique to
address these issues. Traffic is allocated to candidate solutions using a
multi-armed bandit algorithm, using more traffic on those evaluations that are
most useful. In a best-arm identification mode, the best candidate can be
identified reliably at the end of evolution, and in a campaign mode, the
overall conversion rate can be optimized throughout the entire evolution
process. Multi-armed bandit algorithms thus improve performance and reliability
of machine discovery in noisy real-world environments.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:07:46 GMT""},{""version"":""v2"",""created"":""Mon, 26 Mar 2018 18:52:46 GMT""},{""version"":""v3"",""created"":""Fri, 16 Nov 2018 06:05:29 GMT""}]","2018-11-19"
"1803.03738","Ebrahim Karami","Ebrahim Karami and Savo Glisic","Stochastic Models of Coalition Games for Spectrum Sharing in Large Scale
  Interference Channels","6 pages, 4 figures, IEEE International Conference on Communications
  (ICC), 2011. arXiv admin note: text overlap with arXiv:0905.4057 by other
  authors",,"10.1109/icc.2011.5963190",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a framework for the analysis of self-organized
distributed coalition formation process for spectrum sharing in interference
channel for large-scale ad hoc networks. In this approach, we use the concept
of coalition clusters within the network where mutual interdependency between
different clusters is characterized by the concept of spatial network
correlation. Then by using stochastic models of the process we give up some
details characteristic for coalition game theory in order to be able to include
some additional parameters for network scaling. Applications of this model are
a) Estimation of average time to reach grand coalition and its variance through
closed-form equations. These parameters are important in designing the process
in a dynamic environment. b) Dimensioning the coalition cluster within the
network c) Modelling the network spatial correlation characterizing mutual
visibility of the interfering links. d) Modeling of the effect of the new link
activation/inactivation on the coalition forming process. e) Modeling the
effect of link mobility on the coalition-forming process.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:10:51 GMT""}]","2018-03-13"
"1803.03739","Srimanta Middey","S. Middey, D. Meyers, M. Kareev, Y. Cao, X. Liu, P. Shafer, J. W.
  Freeland, J. W. Kim, P. J. Ryan, and J. Chakhalian","Disentangled cooperative orderings in artificial rare-earth nickelates","Accepted in Phys. Rev. Lett","Phys. Rev. Lett, 120, 156801 (2018)","10.1103/PhysRevLett.120.156801",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coupled transitions between distinct ordered phases are important aspects
behind the rich phase complexity of correlated oxides that hinders our
understanding of the underlying phenomena. For this reason, fundamental control
over complex transitions has become a leading motivation of the designer
approach to materials. We have devised a series of new superlattices by
combining a Mott insulator and a correlated metal to form ultra-short period
superlattices, which allow one to disentangle the simultaneous orderings in
$RE$NiO$_3$. Tailoring an incommensurate heterostructure period relative to the
bulk charge ordering pattern suppresses the charge order transition while
preserving metal-insulator and antiferromagnetic transitions. Such selective
decoupling of the entangled phases resolves the long-standing puzzle about the
driving force behind the metal-insulator transition and points to the site
selective Mott transition as the operative mechanism. This designer approach
emphasizes the potential of heterointerfaces for selective control of
simultaneous transitions in complex materials with entwined broken symmetries.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:15:34 GMT""}]","2018-04-12"
"1803.03740","Ebrahim Karami","Ebrahim Karami and Amir H. Banihashemi","Cluster Size Optimization in Cooperative Spectrum Sensing","5 pages, 5 figures, CSNR2011",,"10.1109/CNSR.2011.11",,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study and optimize the cooperation cluster size in
cooperative spectrum sensing to maximize the throughput of secondary users
(SUs). To calculate the effective throughput, we assume each SU spends just 1
symbol to negotiate with the other SUs in its transmission range. This is the
minimum overhead required for each SU to broadcast its sensing decision to the
other members of the cluster. When the number of SUs is large, the throughput
spent for the negotiation is noticeable and therefore increasing the
cooperation cluster size does not improve the effective throughput anymore. In
this paper, we calculate the effective throughput as a function of the
cooperation cluster size, and then we maximize the throughput by finding the
optimal cluster size. Various numerical results show that when decisions are
combined by the OR-rule, the optimum cooperation cluster size is less than when
the AND-rule is used. On the other hand, the optimum cluster size monotonically
decreases with the increase in the average SNR of the SUs. Another interesting
result is that when the cluster size is optimized the OR-rule always
outperforms the AND-rule.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:18:20 GMT""}]","2018-03-13"
"1803.03741","Yevgeniy Kovchegov","Yevgeniy Kovchegov and Ilya Zaliapin","Tokunaga self-similarity arises naturally from time invariance","3 figures",,"10.1063/1.5029937",,"math.DS math.PR nlin.AO nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Tokunaga condition is an algebraic rule that provides a detailed
description of the branching structure in a self-similar tree. Despite a solid
empirical validation and practical convenience, the Tokunaga condition lacks a
theoretical justification. Such a justification is suggested in this work. We
define a geometric branching processes $\mathcal{G}(s)$ that generates
self-similar rooted trees. The main result establishes the equivalence between
the invariance of $\mathcal{G}(s)$ with respect to a time shift and a
one-parametric version of the Tokunaga condition. In the parameter region where
the process satisfies the Tokunaga condition (and hence is time invariant),
$\mathcal{G}(s)$ enjoys many of the symmetries observed in a critical binary
Galton-Watson branching process and reproduce the latter for a particular
parameter value.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:18:43 GMT""},{""version"":""v2"",""created"":""Wed, 11 Apr 2018 02:17:55 GMT""}]","2018-05-09"
"1803.03742","Nir Lahav","Nir Lahav, Baruch Ksherim, Eti Ben-Simon, Adi Maron-Katz, Reuven Cohen
  and Shlomo Havlin","K-shell decomposition reveals hierarchical cortical organization of the
  human brain","New Journal of Physics, Volume 18, August 2016",,"10.1088/1367-2630/18/8/083013",,"q-bio.NC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In recent years numerous attempts to understand the human brain were
undertaken from a network point of view. A network framework takes into account
the relationships between the different parts of the system and enables to
examine how global and complex functions might emerge from network topology.
Previous work revealed that the human brain features 'small world'
characteristics and that cortical hubs tend to interconnect among themselves.
However, in order to fully understand the topological structure of hubs one
needs to go beyond the properties of a specific hub and examine the various
structural layers of the network. To address this topic further, we applied an
analysis known in statistical physics and network theory as k-shell
decomposition analysis. The analysis was applied on a human cortical network,
derived from MRI\DSI data of six participants. Such analysis enables us to
portray a detailed account of cortical connectivity focusing on different
neighborhoods of interconnected layers across the cortex. Our findings reveal
that the human cortex is highly connected and efficient, and unlike the
internet network contains no isolated nodes. The cortical network is comprised
of a nucleus alongside shells of increasing connectivity that formed one
connected giant component. All these components were further categorized into
three hierarchies in accordance with their connectivity profile, with each
hierarchy reflecting different functional roles. Such a model may explain an
efficient flow of information from the lowest hierarchy to the highest one,
with each step enabling increased data integration. At the top, the highest
hierarchy (the nucleus) serves as a global interconnected collective and
demonstrates high correlation with consciousness related regions, suggesting
that the nucleus might serve as a platform for consciousness to emerge.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:19:09 GMT""}]","2018-03-13"
"1803.03743","Chang Sub Kim","Dmitrii Pashin, Arkady M. Satanin, and Chang Sub Kim","Classical and quantum dissipative dynamics in Josephson junctions: an
  Arnold problem, bifurcation and capture into resonance","23 pages, 15 figures","Phys. Rev. E 99, 062223 (2019)","10.1103/PhysRevE.99.062223",,"cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically study the phase dynamics in Josephson junctions, which maps
onto the oscillatory motion of a point-like particle in the washboard
potential. Under appropriate driving and damping conditions, the Josephson
phase undergoes intriguing bistable dynamics near a saddle point in the
quasienergy landscape. The bifurcation mechanism plays a critical role in
superconducting quantum circuits with relevance to non-demolition measurements
such as high-fidelity readout of qubit states. We address the question `what is
the probability of capture into either basin of attraction' and answer it
concerning both classical and quantum dynamics. Consequently, we derive the
Arnold probability and numerically analyze its implementation of the controlled
dynamical switching between two steady states under the various nonequilibrium
conditions.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:32:33 GMT""},{""version"":""v2"",""created"":""Wed, 20 Feb 2019 06:28:25 GMT""}]","2019-07-03"
"1803.03744","Hormoz Shahrzad","Hormoz Shahrzad, Daniel Fink, Risto Miikkulainen","Enhanced Optimization with Composite Objectives and Novelty Selection","7 pages","ALIFE 2018: The 2018 Conference on Artificial Life July 2018
  p.616-622","10.1162/isal_a_00113",,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An important benefit of multi-objective search is that it maintains a diverse
population of candidates, which helps in deceptive problems in particular. Not
all diversity is useful, however: candidates that optimize only one objective
while ignoring others are rarely helpful. This paper proposes a solution: The
original objectives are replaced by their linear combinations, thus focusing
the search on the most useful tradeoffs between objectives. To compensate for
the loss of diversity, this transformation is accompanied by a selection
mechanism that favors novelty. In the highly deceptive problem of discovering
minimal sorting networks, this approach finds better solutions, and finds them
faster and more consistently than standard methods. It is therefore a promising
approach to solving deceptive problems through multi-objective optimization.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:32:39 GMT""},{""version"":""v2"",""created"":""Thu, 5 Jul 2018 23:26:24 GMT""}]","2019-06-11"
"1803.03745","Jason Liang","Jason Liang, Elliot Meyerson, and Risto Miikkulainen","Evolutionary Architecture Search For Deep Multitask Networks",,,,,"cs.NE cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multitask learning, i.e. learning several tasks at once with the same neural
network, can improve performance in each of the tasks. Designing deep neural
network architectures for multitask learning is a challenge: There are many
ways to tie the tasks together, and the design choices matter. The size and
complexity of this problem exceeds human design ability, making it a compelling
domain for evolutionary optimization. Using the existing state of the art soft
ordering architecture as the starting point, methods for evolving the modules
of this architecture and for evolving the overall topology or routing between
modules are evaluated in this paper. A synergetic approach of evolving custom
routings with evolved, shared modules for each task is found to be very
powerful, significantly improving the state of the art in the Omniglot
multitask, multialphabet character recognition domain. This result demonstrates
how evolution can be instrumental in advancing deep neural network and complex
system design in general.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 03:02:09 GMT""},{""version"":""v2"",""created"":""Tue, 17 Apr 2018 18:46:05 GMT""}]","2018-04-19"
"1803.03746","Fengjiao Luo","Fengjiao Luo, Zhimin Wang, Zhonghua Qin, Yuekun Heng","Signal Optimization with HV divider of MCP-PMT for JUNO","6 pages,6 figures",,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Jiangmen Underground Neutrino Observatory (JUNO) is proposed to determine
the neutrino mass hierarchy using a 20 kiloton underground liquid scintillator
detector (CD). One of the keys is the energy resolution of the CD to reach <3%
at 1 MeV, where totally 15,000 MCP-PMT will be used. The optimization of the
20-inch MCP-PMT is very important for better detection efficiency and stable
performance. In this work, we will show the study to optimize the MCP-PMT
working configuration for charge measurement. Particularly, the quality of PMT
signal is another key for high-precision neutrino experiments while most of
these experiments are affected by the overshoot of PMT signal from the positive
HV scheme. The overshoot coupled with positive HV which is troubling trigger,
dead time and precise charge measurement, we have studied to control it to less
than 1% of signal amplitude for a better physics measurement. In this article,
on the one hand, the optimized HV divider ratio will be presented here to
improve its collection efficiency; on the other hand, we will introduce the
method to reduce the ratio of overshoot from 10% to 1%.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 03:18:34 GMT""}]","2018-03-13"
"1803.03747","Toshiaki Kanai","Toshiaki Kanai, Wei Guo, Makoto Tsubota","Emergence of spiral dark solitons in the merging of rotating
  Bose-Einstein condensates","9 pages, 9 figures","J Low Temp Phys (2019) 195: 37","10.1007/s10909-018-2110-1",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Merging of isolated Bose-Einstein condensates (BECs) is an important topic
due to its relevance to matter-wave interferometry and the Kibble-Zurek
mechanism. Many past research focused on merging of BECs with uniform initial
phases. In our recent numerical study (Phys. Rev. A 97, 013612 (2018)), we
revealed that upon merging of rotating BECs with non-uniform initial phases,
spiral-shaped dark solitons can emerge. These solitons facilitate angular
momentum transfer and allow the merged condensate to rotate even in the absence
of quantized vortices. More strikingly, the sharp endpoints of these spiral
solitons can induce rotational motion in the BECs like vortices but with
effectively a fraction of a quantized circulation. This paper reports our
systematic study on the merging dynamics of rotating BECs. We discuss how the
potential barrier that initially separates the BECs can affect the profile of
the spiral solitons. We also show that the number of spiral solitons created in
the BECs matches the relative winding number of the rotating BECs. The
underlying mechanism of the observed soliton dynamics is explained.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 03:22:36 GMT""}]","2019-06-04"
"1803.03748","Song Chen","Song Chen, Jinglei Huang, Xiaodong Xu, and Qi Xu","Integrated Optimization of Partitioning, Scheduling and Floorplanning
  for Partially Dynamically Reconfigurable Systems","14 pages, accepted by IEEE Transactions on computer-aided design for
  review (A 4-page preliminary version was published on ACM GLSVLSI 2017.)",,"10.1109/TCAD.2018.2883982",,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Confronted with the challenge of high performance for applications and the
restriction of hardware resources for field-programmable gate arrays (FPGAs),
partial dynamic reconfiguration (PDR) technology is anticipated to accelerate
the reconfiguration process and alleviate the device shortage. In this paper,
we propose an integrated optimization framework for task partitioning,
scheduling and floorplanning on partially dynamically reconfigurable FPGAs. The
partitions, schedule, and floorplan of the tasks are represented by the
partitioned sequence triple P-ST (PS,QS,RS), where (PS,QS) is a hybrid nested
sequence pair (HNSP) for representing the spatial and temporal partitions, as
well as the floorplan, and RS is the partitioned dynamic configuration order of
the tasks. The floorplanning and scheduling of task modules can be computed
from the partitioned sequence triple P-ST in O(n^2) time. To integrate the
exploration of the scheduling and floorplanning design space, we use a
simulated annealing-based search engine and elaborate a perturbation method,
where a randomly chosen task module is removed from the partition sequence
triple and then inserted back into a proper position selected from all the
(n+1)^3 possible combinations of partitions, schedule and floorplan. The
experimental results demonstrate the efficiency and effectiveness of the
proposed framework.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 03:23:10 GMT""},{""version"":""v2"",""created"":""Wed, 26 Dec 2018 12:57:17 GMT""}]","2018-12-27"
"1803.03749","Anton Petrunin","Anton Petrunin","Counting trees in a graph","(Russian)","Kvant, 2018, no. 9, 9--13","10.4213/kvant20180902",,"math.HO math.CO","http://creativecommons.org/publicdomain/zero/1.0/","  We discuss a recursive formula for number of spanning trees in a graph. The
paper is written primary for school students.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 03:34:23 GMT""}]","2018-11-27"
"1803.03750","Qi Yao","Q. Yao, D.W. Shen, C. H. P. Wen, C. Q. Hua, L. Q. Zhang, N. Z. Wang,
  X. H. Niu, Q. Y. Chen, P. Dudin, Y. H. Lu, Y. Zheng, X. H. Chen, X. G. Wan,
  and D. L. Feng","Charge Transfer Effects in Naturally Occurring van der Waals
  Heterostructures (PbSe)1.16(TiSe2)m (m=1, 2)","6 Pages, 4 figures","Phys. Rev. Lett.120, 106401 (2018)","10.1103/PhysRevLett.120.106401",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Van der Waals heterostructures (VDWHs) exhibit rich properties and thus has
potential for applications, and charge transfer between different layers in a
heterostructure often dominates its properties and device performance. It is
thus critical to reveal and understand the charge transfer effects in VDWHs,
for which electronic structure measurements have proven to be effective. Using
angle-resolved photoemission spectroscopy, we studied the electronic structures
of (PbSe)1.16(TiSe2)m(m=1, 2), which are naturally occurring VDWHs, and
discovered several striking charge transfer effects. When the thickness of the
TiSe2 layers is halved from m=2 to m=1, the amount of charge transferred
increases unexpectedly by more than 250%. This is accompanied by a dramatic
drop in the electron-phonon interaction strength far beyond the prediction by
first-principles calculations and, consequently, superconductivity only exists
in the m=2 compound with strong electron-phonon interaction, albeit with lower
carrier density. Furthermore, we found that the amount of charge transferred in
both compounds is nearly halved when warmed from below 10 K to room
temperature, due to the different thermal expansion coefficients of the
constituent layers of these misfit compounds. These unprecedentedly large
charge transfer effects might widely exist in VDWHs composed of
metal-semiconductor contacts; thus, our results provide important insights for
further understanding and applications of VDWHs.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 03:38:15 GMT""}]","2018-04-04"
"1803.03751","Vladimir Airapetian","V. S. Airapetian (GSFC/SEEC and American University, DC), V. Adibekyan
  (UPORTO), M. Ansdell (University of Hawaii), O. Cohen (University of
  Massachusetts Lowell), M. Cuntz (UFZ), W. Danchi (GSFC/SEEC), C. F. Dong
  (Princeton University), J. J. Drake (Harvard-Cfa), A. Fahrenbach (Caltech),
  K. France (CU Boulder), K. Garcia-Sage (GSFC/SEEC/CUA), A. Glocer
  (GSFC/SEEC), J. L. Grenfell (German Aerospace Center), G. Gronoff (NASA
  LaRC/SSAI), H. Hartnett (Arizona State University), W. Henning (NASA GSFC),
  N. R. Hinkel (Arizona State University), A. G. Jensen (UNK), M. Jin (LMSAL),
  P. Kalas (UC Berkeley), S. R. Kane (UC Riverside), K. Kobayashi (Yokohama
  National University), R. Kopparapu (GSFC/SEEC/UMD), J. Leake (GSFC), M.
  L\'opez-Puertas (Inst de Astrofisica de Andaluc\'ia), T. Lueftinger
  (University of Vienna), B. Lynch (UC Berkeley), W. Lyra (Max Planck Institute
  for Astronomy), A. M. Mandell (GSFC/SEEC), K. E. Mandt (Johns Hopkins
  University APL), W. B. Moore (Hampton University and National Institute of
  Aerospace), D. Nna-Mvondo (NASA GSFC/USRA), Y. Notsu (Kyoto University),
  H.Maehara (Kyoto University), Y.Yamashiki (Kyoto University), K. Shibata
  (Kyoto University), L. D. Oman (GSFC/SEEC), R. A. Osten (STScI, JHU), A.
  Pavlov (GSFC/SEEC), R. M. Ramirez (ELSI), S. Rugheimer (University of St
  Andrews), J. E. Schlieder (GSFC/SEEC), J. D. Schnittman (NASA GSFC), E. L.
  Shock (Arizona State University), C. Sousa-Silva (Massachusetts Institute of
  Technology), M. J. Way (NASA GISS), Y. Yang (NASA GSFC), P. A. Young (Arizona
  State University), G. P. Zank (University of Alabama)","Exploring Extreme Space Weather Factors of Exoplanetary Habitability","6 pages, the white paper submitted to the US National Academy of
  Sciences call on Exoplanet Science Strategy",,,,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  It is currently unknown how common life is on exoplanets, or how long planets
can remain viable for life. To date, we have a superficial notion of
habitability, a necessary first step, but so far lacking an understanding of
the detailed interaction between stars and planets over geological timescales,
dynamical evolution of planetary systems, and atmospheric evolution on planets
in other systems. A planet mass, net insolation, and atmospheric composition
alone are insufficient to determine the probability that life on a planet could
arise or be detected. The latter set of planetary considerations, among others,
underpin the concept of the habitable zone (HZ), defined as the circumstellar
region where standing bodies of liquid water could be supported on the surface
of a rocky planet. However, stars within the same spectral class are often
treated in the same way in HZ studies, without any regard for variations in
activity among individual stars. Such formulations ignore differences in how
nonthermal emission and magnetic energy of transient events in different stars
affect the ability of an exoplanet to retain its atmosphere.In the last few
years there has been a growing appreciation that the atmospheric chemistry, and
even retention of an atmosphere in many cases, depends critically on the
high-energy radiation and particle environments around these stars. Indeed,
recent studies have shown stellar activity and the extreme space weather, such
as that created by the frequent flares and coronal mass ejections (CMEs) from
the active stars and young Sun, may have profoundly affected the chemistry and
climate and thus habitability of the early Earth and terrestrial type
exoplanets. The goal of this white paper is to identify and describe promising
key research goals to aid the field of the exoplanetary habitability for the
next 20 years.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 03:54:52 GMT""}]","2018-03-13"
"1803.03752","Hikmet Yildiz","Hikmet Yildiz and Babak Hassibi","Optimum Linear Codes with Support Constraints over Small Fields",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of designing optimal linear codes (in terms of having
the largest minimum distance) subject to a support constraint on the generator
matrix. We show that the largest minimum distance can be achieved by a subcode
of a Reed-Solomon code of small field size. As a by-product of this result, we
settle the GM-MDS conjecture of Dau et. al. in the affirmative.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 04:01:00 GMT""}]","2018-03-13"
"1803.03753","Takayuki Kihara","Takayuki Kihara","On a metric generalization of the $tt$-degrees and effective dimension
  theory",,,,,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we study an analogue of $tt$-reducibility for points in
computable metric spaces. We characterize the notion of the metric $tt$-degree
in the context of first-level Borel isomorphism. Then, we study this concept
from the perspectives of effective topological dimension theory and of
effective fractal dimension theory.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 04:12:32 GMT""}]","2018-03-13"
"1803.03754","Kang Wei","Kang Wei","Extensions of $\overline\partial$-closed forms on compact generalized
  Hermitian manifolds",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we first get a criterion formula for whether a differential
form is holomorphic with respect to the generalized complex structure induced
by $\epsilon$. Next, we get the local extensions of $\overline\partial$-closed
forms on a smooth family of compact generalized Hermitian manifolds by using
this criterion. Finally, as an application, we use this extension to get the
invariance of the generalized Hodge number of the deformations of compact
generalized Hermitian manifolds with $\partial\overline\partial$-lemma holds.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 04:14:51 GMT""}]","2018-03-13"
"1803.03755","Lijun Liu","Lijun Liu and Xiaodan Wei and Naimin Zhang","Global stability of a network-based SIRS epidemic model with nonmonotone
  incidence rate","19 pages, 7 figures",,"10.1016/j.physa.2018.09.152",,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies the dynamics of a network-based SIRS epidemic model with
vaccination and a nonmonotone incidence rate. This type of nonlinear incidence
can be used to describe the psychological or inhibitory effect from the
behavioral change of the susceptible individuals when the number of infective
individuals on heterogeneous networks is getting larger. Using the analytical
method, epidemic threshold $R_0$ is obtained. When $R_0$ is less than one, we
prove the disease-free equilibrium is globally asymptotically stable and the
disease dies out, while $R_0$ is greater than one, there exists a unique
endemic equilibrium. By constructing a suitable Lyapunov function, we also
prove the endemic equilibrium is globally asymptotically stable if the
inhibitory factor $\alpha$ is sufficiently large. Numerical experiments are
also given to support the theoretical results. It is shown both theoretically
and numerically a larger $\alpha$ can accelerate the extinction of the disease
and reduce the level of disease.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 04:37:11 GMT""},{""version"":""v2"",""created"":""Sat, 28 Jul 2018 07:01:07 GMT""}]","2018-11-14"
"1803.03756","Lili Zhang","Lili Zhang, Jennifer Priestley and Xuelei Ni","Influence of the Event Rate on Discrimination Abilities of Bankruptcy
  Prediction Models",,"International Journal of Database Management Systems. 2018
  February 10(1): 1-14","10.5121/ijdms.2018.10101",,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In bankruptcy prediction, the proportion of events is very low, which is
often oversampled to eliminate this bias. In this paper, we study the influence
of the event rate on discrimination abilities of bankruptcy prediction models.
First the statistical association and significance of public records and
firmographics indicators with the bankruptcy were explored. Then the event rate
was oversampled from 0.12% to 10%, 20%, 30%, 40%, and 50%, respectively. Seven
models were developed, including Logistic Regression, Decision Tree, Random
Forest, Gradient Boosting, Support Vector Machine, Bayesian Network, and Neural
Network. Under different event rates, models were comprehensively evaluated and
compared based on Kolmogorov-Smirnov Statistic, accuracy, F1 score, Type I
error, Type II error, and ROC curve on the hold-out dataset with their best
probability cut-offs. Results show that Bayesian Network is the most
insensitive to the event rate, while Support Vector Machine is the most
sensitive.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 04:51:31 GMT""}]","2018-03-14"
"1803.03757","Shengyou Yang","Shengyou Yang","Surface wrinkling of an elastic block subject to biaxial loading by an
  energy method",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wrinkles are often observed on the surfaces of compressed soft materials in
nature. In the past few decades, the fascinating surface patterns have been
studied extensively by using the linear bifurcation analysis under plane
strain. The bifurcation concerns the non-uniqueness solutions, however, it
delivers little information about the surface instability before and after the
threshold. In this paper, we study surface wrinkling of a finite elastic block
of general elastic materials subject to biaxial loading by an energy method.
The first and second variations of the strain energy functional are
systematically studied, and an eigenvalue problem is proposed whether the
second variation is positive definite. We illustrate our analysis by using
neo-Hookean materials as an example. Accordingly, we show that the initially
flat state has the lowest energy and is stable before the stretches reach the
threshold at which the surface wrinkling occurs. We also find that the
threshold is independent of the size of the block and coincides with that of
the surface instability of an elastic half-space studied by Biot (1963) with
the linear bifurcation analysis. However, the stability region cannot be
obtained by using the linear stability analysis. In contrast to the
size-independent threshold, the wavelength of surface wrinkling depends on the
size of the block. We first show that a two-dimensional rather than a
three-dimensional perturbation has lower energy and is more likely to trigger
the surface wrinkling in the instability region. The same stretch threshold of
a finite block and a half-space could shed light on the relation of surface
instabilities between finite and infinite bodies.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 05:01:43 GMT""}]","2018-03-13"
"1803.03758","Ali Boyali","Ali Boyali, Seichi Mita, Vijay John","A Tutorial On Autonomous Vehicle Steering Controller Design, Simulation
  and Implementation",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this tutorial, we detailed simple controllers for autonomous parking and
path following for self-driving cars providing practical methods for curvature
computation.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 05:11:32 GMT""},{""version"":""v2"",""created"":""Mon, 13 Apr 2020 18:18:44 GMT""},{""version"":""v3"",""created"":""Fri, 5 Feb 2021 02:42:36 GMT""},{""version"":""v4"",""created"":""Wed, 31 Mar 2021 15:42:06 GMT""},{""version"":""v5"",""created"":""Mon, 26 Apr 2021 05:52:29 GMT""},{""version"":""v6"",""created"":""Tue, 13 Jul 2021 06:16:24 GMT""}]","2021-07-14"
"1803.03759","Sanjay Krishna Gouda","Sanjay Krishna Gouda, Salil Kanetkar, David Harrison and Manfred K
  Warmuth","Speech Recognition: Keyword Spotting Through Image Recognition",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  The problem of identifying voice commands has always been a challenge due to
the presence of noise and variability in speed, pitch, etc. We will compare the
efficacies of several neural network architectures for the speech recognition
problem. In particular, we will build a model to determine whether a one second
audio clip contains a particular word (out of a set of 10), an unknown word, or
silence. The models to be implemented are a CNN recommended by the Tensorflow
Speech Recognition tutorial, a low-latency CNN, and an adversarially trained
CNN. The result is a demonstration of how to convert a problem in audio
recognition to the better-studied domain of image classification, where the
powerful techniques of convolutional neural networks are fully developed.
Additionally, we demonstrate the applicability of the technique of Virtual
Adversarial Training (VAT) to this problem domain, functioning as a powerful
regularizer with promising potential future applications.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 05:16:18 GMT""},{""version"":""v2"",""created"":""Tue, 24 Nov 2020 17:10:43 GMT""}]","2020-11-25"
"1803.03760","Jason Doctor","Jason N. Doctor, Jaideep Vaidya, Xiaoqian Jiang, Shuang Wang, Lisa M.
  Schilling, Toan Ong, Michael E. Matheny, Lucila Ohno-Machado, and Daniella
  Meeker","Efficient Determination of Equivalence for Encrypted Data",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Secure computation of equivalence has fundamental application in many
different areas, including healthcare. We study this problem in the context of
matching an individual identity to link medical records across systems. We
develop an efficient solution for equivalence based on existing work that can
evaluate the greater than relation. We implement the approach and demonstrate
its effectiveness on data, as well as demonstrate how it meets regulatory
criteria for risk.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 05:20:48 GMT""}]","2018-03-13"
"1803.03761","Christian Majenz","Gorjan Alagic, Christian Majenz, Alexander Russell and Fang Song","Quantum-secure message authentication via blind-unforgeability","37 pages, v4: Erratum added. We removed a result that had an error in
  its proof","In: Canteaut A., Ishai Y. (eds) Advances in Cryptology --
  EUROCRYPT 2020. EUROCRYPT 2020. Lecture Notes in Computer Science, vol 12107.
  Springer, Cham","10.1007/978-3-030-45727-3_27",,"quant-ph cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Formulating and designing authentication of classical messages in the
presence of adversaries with quantum query access has been a longstanding
challenge, as the familiar classical notions of unforgeability do not directly
translate into meaningful notions in the quantum setting. A particular
difficulty is how to fairly capture the notion of ""predicting an unqueried
value"" when the adversary can query in quantum superposition.
  We propose a natural definition of unforgeability against quantum adversaries
called blind unforgeability. This notion defines a function to be predictable
if there exists an adversary who can use ""partially blinded"" oracle access to
predict values in the blinded region. We support the proposal with a number of
technical results. We begin by establishing that the notion coincides with
EUF-CMA in the classical setting and go on to demonstrate that the notion is
satisfied by a number of simple guiding examples, such as random functions and
quantum-query-secure pseudorandom functions. We then show the suitability of
blind unforgeability for supporting canonical constructions and reductions. We
prove that the ""hash-and-MAC"" paradigm and the Lamport one-time digital
signature scheme are indeed unforgeable according to the definition. To support
our analysis, we additionally define and study a new variety of quantum-secure
hash functions called Bernoulli-preserving.
  Finally, we demonstrate that blind unforgeability is stronger than a previous
definition of Boneh and Zhandry [EUROCRYPT '13, CRYPTO '13] in the sense that
we can construct an explicit function family which is forgeable by an attack
that is recognized by blind-unforgeability, yet satisfies the definition by
Boneh and Zhandry.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 05:31:38 GMT""},{""version"":""v2"",""created"":""Sun, 25 Nov 2018 21:24:40 GMT""},{""version"":""v3"",""created"":""Fri, 3 Jul 2020 07:03:10 GMT""},{""version"":""v4"",""created"":""Thu, 20 Apr 2023 09:23:06 GMT""}]","2023-04-21"
"1803.03762","Madad Ali Valuyan","M. A. Valuyan","The Dirichlet Casimir Energy for $\phi^4$ Theory in a Rectangle","12 pages, 5 Figures","Eur. Phys. J. Plus (2018) 133: 401","10.1140/epjp/i2018-12206-8",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we present the zero and first-order radiative correction to
the Dirichlet Casimir energy for massive and massless scalar field confined in
a rectangle. This calculation procedure was conducted in two spatial dimensions
and for the case of the first-order correction term is new. The renormalization
program that we have used in this work, allows all influences from the dominant
boundary conditions (e.g. the Dirichlet boundary condition) be automatically
reflected in the counterterms. This permission usually makes the counterterms
position-dependent. Along with the renormalization program, a supplementary
regularization technique was performed in this work. In this regularization
technique, that we have named Box Subtraction Scheme (BSS), two similar
configurations were introduced and the zero point energies of these two
configurations were subtracted from each other using appropriate limits. This
regularization procedure makes the usage of any analytic continuation
techniques unnecessary. In the present work, first, we briefly present
calculation of the leading order Casimir energy for the massive scalar field in
a rectangle via BSS. Next, the first order correction to the Casimir energy is
calculated by applying the mentioned renormalization and regularization
procedures. Finally, all the necessary limits of obtained answers for both
massive and massless cases are discussed.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 05:50:08 GMT""}]","2018-10-16"
"1803.03763","Alireza Talebian Ashkezari","Alireza Talebian-Ashkezari and Nahid Ahmadi","\bf $\delta M$ Formalism and Anisotropic Chaotic Inflation Power
  Spectrum","15 pages",,"10.1088/1475-7516/2018/05/047",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new analytical approach to linear perturbations in anisotropic inflation
has been introduced in [A. Talebian-Ashkezari, N. Ahmadi and A.A. Abolhasanib,
JCAP 03(2018)001] under the name of $\delta M$ formalism. In this paper we
apply the mentioned approach to a model of anisotropic inflation driven by a
scalar field, coupled to the kinetic term of a vector field with a $U(1)$
symmetry. The $\delta M$ formalism provides an efficient way of computing
tensor- tensor, tensor- scalar as well as scalar- scalar 2-point correlations
that are needed for the analysis of the observational features of an
anisotropic model on the CMB. A comparison between $\delta M$ results and the
tedious calculations using in-in formalism shows the aptitude of the $\delta M$
formalism in calculating accurate two point correlation functions between
physical modes of the system.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 05:55:06 GMT""}]","2018-05-23"
"1803.03764","Arsenii Ashukha","Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, Dmitry Vetrov","Variance Networks: When Expectation Does Not Meet Your Expectations",,,,,"stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Ordinary stochastic neural networks mostly rely on the expected values of
their weights to make predictions, whereas the induced noise is mostly used to
capture the uncertainty, prevent overfitting and slightly boost the performance
through test-time averaging. In this paper, we introduce variance layers, a
different kind of stochastic layers. Each weight of a variance layer follows a
zero-mean distribution and is only parameterized by its variance. We show that
such layers can learn surprisingly well, can serve as an efficient exploration
tool in reinforcement learning tasks and provide a decent defense against
adversarial attacks. We also show that a number of conventional Bayesian neural
networks naturally converge to such zero-mean posteriors. We observe that in
these cases such zero-mean parameterization leads to a much better training
objective than conventional parameterizations where the mean is being learned.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 06:01:40 GMT""},{""version"":""v2"",""created"":""Tue, 13 Mar 2018 08:41:11 GMT""},{""version"":""v3"",""created"":""Tue, 20 Mar 2018 10:07:40 GMT""},{""version"":""v4"",""created"":""Wed, 4 Jul 2018 08:24:14 GMT""},{""version"":""v5"",""created"":""Mon, 18 Feb 2019 08:45:19 GMT""}]","2019-02-19"
"1803.03765","Haakon Bakka","Haakon Bakka","How to solve the stochastic partial differential equation that gives a
  Mat\'ern random field using the finite element method","17 pages, Links to code examples updated",,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This tutorial teaches parts of the finite element method (FEM), and solves a
stochastic partial differential equation (SPDE). The contents herein are
considered ""known"" in the numerics literature, but for statisticians it is very
difficult to find a resource for learning these ideas in a timely manner
(without doing a year's worth of courses in numerics). The goal of this
tutorial is to be pedagogical and explain the computations/theory to a
statistician. This is not a practical tutorial, there is little computer code,
and no data analysis.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 06:02:04 GMT""},{""version"":""v2"",""created"":""Tue, 8 Oct 2019 11:32:38 GMT""},{""version"":""v3"",""created"":""Sat, 12 Feb 2022 09:22:59 GMT""}]","2022-02-15"
"1803.03766","Leonard Schue","Leonard Schue, Lorenzo Sponza, Alexandre Plaud, Hakima Bensalah, Kenji
  Watanabe, Takashi Taniguchi, Fran\c{c}ois Ducastelle, Annick Loiseau and
  Julien Barjon","Bright luminescence from indirect and strongly bound excitons in hBN",,"Phys. Rev. Lett. 122, 067401 (2019)","10.1103/PhysRevLett.122.067401",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A quantitative analysis of the excitonic luminescence efficiency in hexagonal
boron nitride (hBN) is carried out by cathodoluminescence in the ultraviolet
range and compared with zinc oxide and diamond single crystals. A high quantum
yield value of ~50% is found for hBN at 10 K comparable to that of direct
bandgap semiconductors. This bright luminescence at 215 nm remains stable up to
room temperature, evidencing the strongly bound character of excitons in bulk
hBN. Ab initio calculations of the exciton dispersion confirm the indirect
nature of the lowest-energy exciton whose binding energy is found equal to 300
meV, in agreement with the thermal stability observed in luminescence. The
direct exciton is found at a higher energy but very close to the indirect one,
which solves the long debated Stokes shift in bulk hBN.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 06:02:38 GMT""},{""version"":""v2"",""created"":""Sat, 9 Feb 2019 02:19:51 GMT""}]","2019-02-20"
"1803.03767","Richard Santiago","Richard Santiago, F. Bruce Shepherd","Multi-Agent Submodular Optimization","arXiv admin note: text overlap with arXiv:1612.05222","Proceedings of the 21st International Conference on Approximation
  Algorithms for Combinatorial Optimization Problems (APPROX), 116:23:1-23:20,
  2018","10.4230/LIPIcs.APPROX-RANDOM.2018.23",,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent years have seen many algorithmic advances in the area of submodular
optimization: (SO) $\min/\max~f(S): S \in \mathcal{F}$, where $\mathcal{F}$ is
a given family of feasible sets over a ground set $V$ and $f:2^V \rightarrow
\mathbb{R}$ is submodular. This progress has been coupled with a wealth of new
applications for these models. Our focus is on a more general class of
\emph{multi-agent submodular optimization} (MASO) which was introduced by Goel
et al. in the minimization setting: $\min \sum_i f_i(S_i): S_1 \uplus S_2
\uplus \cdots \uplus S_k \in \mathcal{F}$. Here we use $\uplus$ to denote
disjoint union and hence this model is attractive where resources are being
allocated across $k$ agents, each with its own submodular cost function
$f_i()$. In this paper we explore the extent to which the approximability of
the multi-agent problems are linked to their single-agent {\em primitives},
referred to informally as the {\em multi-agent gap}.
  We present different reductions that transform a multi-agent problem into a
single-agent one. For maximization we show that (MASO) admits an
$O(\alpha)$-approximation whenever (SO) admits an $\alpha$-approximation over
the multilinear formulation, and thus substantially expanding the family of
tractable models. We also discuss several family classes (such as spanning
trees, matroids, and $p$-systems) that have a provable multi-agent gap of 1. In
the minimization setting we show that (MASO) has an $O(\alpha \cdot \min \{k,
\log^2 (n)\})$-approximation whenever (SO) admits an $\alpha$-approximation
over the convex formulation. In addition, we discuss the class of ""bounded
blocker"" families where there is a provably tight O$(\log n)$ gap between
(MASO) and (SO).
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 06:22:46 GMT""},{""version"":""v2"",""created"":""Sun, 4 Nov 2018 01:57:00 GMT""}]","2019-08-23"
"1803.03768","Riccarda Rossi","Riccarda Rossi","Visco-Energetic solutions to some rate-independent systems in damage,
  delamination, and plasticity",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper revolves around a newly introduced weak solvability concept for
rate-independent systems, alternative to the notions of Energetic and Balanced
Viscosity solutions. Visco-Energetic solutions have been recently obtained by
passing to the time-continuous limit in a time-incremental scheme, akin to that
for Energetic solutions, but perturbed by a `viscous' correction term, as in
the case of Balanced Viscosity solutions. However, for Visco-Energetic
solutions this viscous correction is tuned by a fixed parameter. The resulting
solution notion turns out to describe a kind of evolution in between Energetic
and Balanced Viscosity evolution.
  In this paper we aim to investigate the application of Visco-Energetic
solutions to the paradigmatic example of perfect plasticity, and to nonsmooth
rate-independent processes in solid mechanics such as damage and plasticity at
finite strains. With the limit passage from adhesive contact to brittle
delamination, we also provide a first result of Evolutionary Gamma-convergence
for Visco-Energetic solutions. The analysis of these applications reveals the
wide applicability of this solution concept and confirms its intermediate
character.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 06:43:26 GMT""}]","2018-03-13"
"1803.03769","Siong Thye Goh","Siong Thye Goh, Cynthia Rudin","A Minimax Surrogate Loss Approach to Conditional Difference Estimation","33 pages, 12 figures",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new machine learning approach to estimate personalized treatment
effects in the classical potential outcomes framework with binary outcomes. To
overcome the problem that both treatment and control outcomes for the same unit
are required for supervised learning, we propose surrogate loss functions that
incorporate both treatment and control data. The new surrogates yield tighter
bounds than the sum of losses for treatment and control groups. A specific
choice of loss function, namely a type of hinge loss, yields a minimax support
vector machine formulation. The resulting optimization problem requires the
solution to only a single convex optimization problem, incorporating both
treatment and control units, and it enables the kernel trick to be used to
handle nonlinear (also non-parametric) estimation. Statistical learning bounds
are also presented for the framework, and experimental results.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 07:01:52 GMT""},{""version"":""v2"",""created"":""Fri, 4 May 2018 03:36:42 GMT""}]","2018-05-07"
"1803.03770","Xiao Tang","Xiao Tang, Weinian Zhang","Continuous solutions of a second order iterative equation","24 pages, 3 figures",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the existence of continuous solutions and their
constructions for a second order iterative functional equation, which involves
iterate of the unknown function and a nonlinear term. Imposing Lipschitz
conditions to those given functions, we prove the existence of continuous
solutions on the whole $\mathbb{R}$ by applying the contraction principle. In
the case without Lipschitz conditions we hardly use the contraction principle,
but we construct continuous solutions on $\mathbb{R}$ recursively with a
partition of $\mathbb{R}$.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 07:07:44 GMT""}]","2018-03-13"
"1803.03771","Krishnakanta Bhattacharya","Krishnakanta Bhattacharya, Ashmita Das, Bibhas Ranjan Majhi","Noether and Abbott-Deser-Tekin conserved quantities in scalar-tensor
  theory of gravity both in Jordan and Einstein frames","Published Version","Phys. Rev. D 97, 124013 (2018)","10.1103/PhysRevD.97.124013",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the thermodynamic aspects of the scalar-tensor theory of gravity
in the Jordan and in the Einstein frame. Examining the {\it missing links} of
this theory carefully, we establish the thermodynamic descriptions from the
conserved currents and potentials by following both the Noether and the
Abbott-Deser-Tekin (ADT) formalism. With the help of conserved Noether current
and potential, we define the thermodynamic quantities, which we show to be {\it
conformally invariant}. Moreover, the defined quantities are shown to fit
nicely in the laws of (the first and the second) black hole thermodynamics
formulated by the Wald's method. We stretch the study of the conformal
equivalence of the physical quantities in these two frames by following the ADT
formalism. Our further study reveals that there is a connection between the ADT
and the Noether conserved quantities, which signifies that the ADT approach
provide the equivalent thermodynamic description in the two frames as obtained
in Noether prescription. Our whole analysis is very general as the conserved
Noether and ADT currents and potentials are formulated {\it off-shell} and the
analysis is exempted from any prior assumption or boundary condition.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 07:09:33 GMT""},{""version"":""v2"",""created"":""Mon, 28 May 2018 05:23:26 GMT""},{""version"":""v3"",""created"":""Mon, 11 Jun 2018 04:48:14 GMT""}]","2018-06-13"
"1803.03772","Shao-Bo Lin","Shao-Bo Lin","Generalization and Expressivity for Deep Nets",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Along with the rapid development of deep learning in practice, the
theoretical explanations for its success become urgent. Generalization and
expressivity are two widely used measurements to quantify theoretical behaviors
of deep learning. The expressivity focuses on finding functions expressible by
deep nets but cannot be approximated by shallow nets with the similar number of
neurons. It usually implies the large capacity. The generalization aims at
deriving fast learning rate for deep nets. It usually requires small capacity
to reduce the variance. Different from previous studies on deep learning,
pursuing either expressivity or generalization, we take both factors into
account to explore the theoretical advantages of deep nets. For this purpose,
we construct a deep net with two hidden layers possessing excellent
expressivity in terms of localized and sparse approximation. Then, utilizing
the well known covering number to measure the capacity, we find that deep nets
possess excellent expressive power (measured by localized and sparse
approximation) without enlarging the capacity of shallow nets. As a
consequence, we derive near optimal learning rates for implementing empirical
risk minimization (ERM) on the constructed deep nets. These results
theoretically exhibit the advantage of deep nets from learning theory
viewpoints.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 07:41:25 GMT""},{""version"":""v2"",""created"":""Fri, 23 Mar 2018 13:53:06 GMT""}]","2018-03-26"
"1803.03773","Huaqing Huang","Huaqing Huang, Kyung-Hwan Jin and Feng Liu","Alloy engineering of topological semimetal phase transition in
  MgTa$_{2-x}$Nb$_x$N$_3$","in press, Phys. Rev. Lett. (2018)","Phys. Rev. Lett. 120, 136403 (2018)","10.1103/PhysRevLett.120.136403",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dirac, triple-point and Weyl fermions represent three topological semimetal
phases, characterized with a descending degree of band degeneracy, which have
been realized separately in specific crystalline materials with different
lattice symmetries. Here we demonstrate an alloy engineering approach to
realize all three types of fermions in one single material system of
MgTa$_{2-x}$Nb$_x$N$_3$. Based on symmetry analysis and first-principles
calculations, we map out a phase diagram of topological order in the parameter
space of alloy concentration and crystalline symmetry, where the intrinsic
MgTa$_2$N$_3$ with the highest symmetry hosts the Dirac semimetal phase which
transforms into the triple-point and then the Weyl semimetal phase with the
increasing Nb concentration that lowers the crystalline symmetries. Therefore,
alloy engineering affords a unique approach for experimental investigation of
topological transitions of semimetallic phases manifesting different fermionic
behaviors.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 07:50:10 GMT""}]","2018-04-02"
"1803.03774","Masayuki Hayashi","Masayuki Hayashi","Long-period limit of exact periodic traveling wave solutions for the
  derivative nonlinear Schr\""{o}dinger equation","34 pages, 1 figure. Minor revision; updated references. To appear in
  Annales de l'Institut Henri Poincar\'e / Analyse Non Lin\'eaire","Annales de l'Institut Henri Poincar\'e / Analyse Non Lin\'eaire 36
  (2019), no. 5, 1331-1360","10.1016/j.anihpc.2018.12.003",,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the periodic traveling wave solutions of the derivative nonlinear
Schr\""{o}dinger equation (DNLS). It is known that DNLS has two types of
solitons on the whole line; one has exponential decay and the other has
algebraic decay. The latter corresponds to the soliton for the massless case.
In the new global results recently obtained by Fukaya, Hayashi and Inui, the
properties of two-parameter of the solitons are essentially used in the proof,
and especially the soliton for the massless case plays an important role. To
investigate further properties of the solitons, we construct exact periodic
traveling wave solutions which yield the solitons on the whole line including
the massless case in the long-period limit. Moreover, we study the regularity
of the convergence of these exact solutions in the long-period limit.
Throughout the paper, the theory of elliptic functions and elliptic integrals
is used in the calculation.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 07:57:43 GMT""},{""version"":""v2"",""created"":""Sun, 9 Dec 2018 06:50:15 GMT""}]","2020-01-24"
"1803.03775","Ryo Tazaki","Ryo Tazaki, Hidekazu Tanaka","Light Scattering by Fractal Dust Aggregates. II. Opacity and Asymmetry
  Parameter","version accepted in ApJ","The Astrophysical Journal, 860:79 (2018)","10.3847/1538-4357/aac32d",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optical properties of dust aggregates are important at various astrophysical
environments. To find a reliable approximation method for optical properties of
dust aggregates, we calculate the opacity and the asymmetry parameter of dust
aggregates by using a rigorous numerical method, the T-Matrix Method (TMM), and
then the results are compared to those obtained by approximate methods; the
Rayleigh-Gans-Debye (RGD) theory, the effective medium theory (EMT), and the
distribution of hollow spheres method (DHS). First of all, we confirm that the
RGD theory breaks down when multiple scattering is important. In addition, we
find that both EMT and DHS fail to reproduce the optical properties of dust
aggregates with fractal dimension of 2 when the incident wavelength is shorter
than the aggregate radius. In order to solve these problems, we test the mean
field theory (MFT), where multiple scattering can be taken into account. We
show that the extinction opacity of dust aggregates can be well reproduced by
MFT. However, it is also shown that MFT is not able to reproduce the scattering
and absorption opacities when multiple scattering is important. We successfully
resolve this weak point of MFT, by newly developing a modified mean field
theory (MMF). Hence, we conclude that MMF can be a useful tool to investigate
radiative transfer properties of various astrophysical environments. We also
point out an enhancement of the absorption opacity of dust aggregates in the
Rayleigh domain, which would be important to explain the large millimeter-wave
opacity inferred from observations of protoplanetary disks.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 08:23:37 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jun 2018 04:52:00 GMT""}]","2018-06-20"
"1803.03776","Paddy Royall","Rhiannon Pinney, Tanniemola B. Liverpool and C. Patrick Royall","Yielding of a Model Glassformer: an Interpretation with an Effective
  System of Icosahedra","13 pages, accepted in Phys. Rev. E",,"10.1103/PhysRevE.97.032609",,"cond-mat.soft cond-mat.mtrl-sci cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the yielding under simple shear of a binary Lennard-Jones
glassformer whose super-Arrhenius dynamics are correlated with the formation of
icosahedral structures. We recast this glassformer as an effective system of
icosahedra [Pinney et al. J. Chem. Phys. 143 244507 (2015)]. Looking at the
small-strain region of sheared simulations, we observe that shear rates affect
the shear localisation behavior particularly at temperatures below the glass
transition as defined with a fit to the Vogel-Fulcher-Tamman equation. At
higher temperature, shear localisation starts immediately upon shearing for all
shear rates. At lower temperatures, faster shear rates can result in a delayed
start in shear localisation; which begins close to the yield stress. Building
from a previous work which considered steady-state shear [Pinney et al. J.
Chem. Phys. 143 244507 (2016)], we interpret the response to shear and the
shear localisation in terms of a \emph{local} effective temperature with our
system of icosahedra. We find that the effective temperatures of the regions
undergoing shear localisation increase significantly with increasing strain
(before reaching a steady state plateau).
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 08:25:46 GMT""}]","2018-04-18"
"1803.03777","Yuxin Peng","Xin Huang and Yuxin Peng","Deep Cross-media Knowledge Transfer","10 pages, accepted by IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR), 2018",,,,"cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cross-media retrieval is a research hotspot in multimedia area, which aims to
perform retrieval across different media types such as image and text. The
performance of existing methods usually relies on labeled data for model
training. However, cross-media data is very labor consuming to collect and
label, so how to transfer valuable knowledge in existing data to new data is a
key problem towards application. For achieving the goal, this paper proposes
deep cross-media knowledge transfer (DCKT) approach, which transfers knowledge
from a large-scale cross-media dataset to promote the model training on another
small-scale cross-media dataset. The main contributions of DCKT are: (1)
Two-level transfer architecture is proposed to jointly minimize the media-level
and correlation-level domain discrepancies, which allows two important and
complementary aspects of knowledge to be transferred: intra-media semantic and
inter-media correlation knowledge. It can enrich the training information and
boost the retrieval accuracy. (2) Progressive transfer mechanism is proposed to
iteratively select training samples with ascending transfer difficulties, via
the metric of cross-media domain consistency with adaptive feedback. It can
drive the transfer process to gradually reduce vast cross-media domain
discrepancy, so as to enhance the robustness of model training. For verifying
the effectiveness of DCKT, we take the largescale dataset XMediaNet as source
domain, and 3 widelyused datasets as target domain for cross-media retrieval.
Experimental results show that DCKT achieves promising improvement on retrieval
accuracy.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 08:53:07 GMT""}]","2018-03-13"
"1803.03778","Liangfu Chen","Liangfu Chen, Zeng Yang, Jianjun Ma, Zheng Luo","Driving Scene Perception Network: Real-time Joint Detection, Depth
  Estimation and Semantic Segmentation","9 pages, 7 figures, WACV'18",,"10.1109/WACV.2018.00145",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the demand for enabling high-level autonomous driving has increased in
recent years and visual perception is one of the critical features to enable
fully autonomous driving, in this paper, we introduce an efficient approach for
simultaneous object detection, depth estimation and pixel-level semantic
segmentation using a shared convolutional architecture. The proposed network
model, which we named Driving Scene Perception Network (DSPNet), uses
multi-level feature maps and multi-task learning to improve the accuracy and
efficiency of object detection, depth estimation and image segmentation tasks
from a single input image. Hence, the resulting network model uses less than
850 MiB of GPU memory and achieves 14.0 fps on NVIDIA GeForce GTX 1080 with a
1024x512 input image, and both precision and efficiency have been improved over
combination of single tasks.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 08:55:46 GMT""}]","2018-03-13"
"1803.03779","Lihua Wang","Lihua Wang and Kwang S. Kim","Quantum Dimensional Transition in Spin-$\frac{1}{2}$ Antiferromagnetic
  Heisenberg Model on A Square Lattice and Space Reduction in Matrix Product
  State","26 pages, 22 figures","Phys. Rev. B 99, 134441 (2019)","10.1103/PhysRevB.99.134441",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the spin-$\frac{1}{2}$ antiferromagnetic Heisenberg model on an
infinity-by-$N$ square lattice for even $N$'s up to $14$. Previously, the
nonlinear sigma model perturbatively predicts that its spin rotational symmetry
asymptotically breaks when $N\rightarrow \infty$, i.e., when it is
two-dimensional (2D). However, we identified a critical width $N_c = 10$ for
which this symmetry breaks spontaneously. It defines a dimensional transition
from one-dimension (1D) including quasi-1D to 2D. The finite-size effect
differs from that of the $N$-by-$N$ lattice. The ground state (GS) energy per
site approaches the thermodynamic limit value, in agreement with the previously
accepted value, by one order of $1/N$ faster than when using $N$-by-$N$
lattices in the literature. We build and variationally solve a matrix product
state (MPS) on a chain, converting the $N$ sites in the rung into an effective
site. We show that the area law of entanglement entropy does not apply when $N$
increases in our method, and show that the reduced density matrix of each
effective site will have a saturating number of dominant diagonal elements with
increasing $N$. These two characteristics make the MPS rank needed to obtain a
demanded energy accuracy quickly saturate when $N$ is large, making our
algorithm efficient for large $N$'s. And, the latter enables space reduction in
MPS. Within the framework of MPS, we prove a theorem that the spin-spin
correlation at infinite separation is the square of staggered magnetization and
demonstrate that the eigenvalue structure of a building MPS unit of $\langle
g\mid g\rangle$, $\mid g\rangle$ being the GS, is responsible for order,
disorder and quasi-long-range order.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 08:55:48 GMT""},{""version"":""v2"",""created"":""Mon, 3 Sep 2018 05:19:13 GMT""}]","2019-05-01"
"1803.03780","Hao Wu","Hao Wu, Hancheng Lu","Energy and Delay Optimization for Cache-Enabled Dense Small Cell
  Networks","12 pages, 7 figures, 2 tables",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Caching popular files in small base stations (SBSs) has been proved to be an
effective way to reduce bandwidth pressure on the backhaul links of dense small
cell networks (DSCNs). Many existing studies on cache-enabled DSCNs attempt to
improve user experience by optimizing end-to-end file delivery delay. However,
under practical scenarios where files (e.g., video files) have diverse quality
of service requirements, energy consumption at SBSs should also be concerned
from the network perspective. In this paper,we attempt to optimize these two
critical metrics in cache-enabled DSCNs. Firstly, we formulate the energy-delay
optimization problem as a Mixed Integer Programming (MIP) problem, where file
placement, user association and power control are jointly considered. To model
the tradeoff relationship between energy consumption and end-to-end file
delivery delay, a utility function linearly combining these two metrics is used
as an objective function of the optimization problem. Then, we solve the
problem in two stages, i.e. caching stage and delivery stage, based on the
observation that caching is performed during off-peak time. At the caching
stage, a local popular file placement policy is proposed by estimating user
preference at each SBS. At the delivery stage, with given caching status at
SBSs, the MIP problem is further decomposed by Benders' decomposition method.
An efficient algorithm is proposed to approach the optimal association and
power solution by iteratively shrinking the gap of the upper and lower bounds.
Finally, extension simulations are performed to validate our analytical and
algorithmic work. The results demonstrate that the proposed algorithms can
achieve the optimal tradeoff between energy consumption and end-to-end file
delivery delay.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 09:04:29 GMT""}]","2018-03-13"
"1803.03781","Andrzej Niedzwiecki","Andrzej Niedzwiecki, Andrzej A. Zdziarski","The lamppost model: effects of photon trapping, the bottom lamp and disc
  truncation","submitted to MNRAS",,"10.1093/mnras/sty873",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the lamppost model, in which the primary X-ray sources in accreting
black-hole systems are located symmetrically on the rotation axis on both sides
of the black hole surrounded by an accretion disc. We show the importance of
the emission of the source on the opposite side to the observer. Due to
gravitational light bending, its emission can increase the direct (i.e., not
re-emitted by the disc) flux by as much as an order of magnitude. This happens
for near to face-on observers when the disc is even moderately truncated. For
truncated discs, we also consider effects of emission of the top source
gravitationally bent around the black hole. We also present results for the
attenuation of the observed radiation with respect to that emitted by the
lamppost as functions of the lamppost height, black-hole spin and the degree of
disc truncation. This attenuation, which is due to the time dilation,
gravitational redshift and the loss of photons crossing the black-hole horizon,
can be as severe as by several orders of magnitude for low lamppost heights. We
also consider the contribution to the observed flux due to re-emission by
optically-thick matter within the innermost stable circular orbit.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 09:04:31 GMT""}]","2018-04-25"
"1803.03782","Igor Luk'yanchuk A","I.Luk'yanchuk, A. Sen\'e, V. Vinokour","Electrodynamics of ferroelectric films with negative capacitance",,"Phys. Rev. B 98, 024107 (2018)","10.1103/PhysRevB.98.024107",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a comprehensive theory of the electrodynamic response of
ferroelectric ultra-thin films containing periodic domain textures (PDT) with
180{\deg} polarization-oriented domains. The focal point of the theory is the
negative-capacitance phenomenon which naturally arises from the depolarization
field induced by PDT. We derive frequency-dependent dielectric permittivity
related to the PDT dynamics across the entire frequency range. We find the
resonance mode of domain oscillations in the THz spectral band and the singular
points in the phase of the reflected THz beam that are intimately related to
the negative capacitance. Our findings provide a platform for the THz negative
capacitance-based optics of ferroelectric films and for engineering the
epsilon-near-zero plasmonic THz metamaterials.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 09:15:03 GMT""}]","2018-08-01"
"1803.03783","Abdellatif Ben Makhlouf","D. Boucenna, A. Ben Makhlouf, O. Naifar, A. Guezane-Lakoud, M. A.
  Hammami","Linearized stability analysis of Caputo-Katugampola fractional-order
  nonlinear systems","12 pages",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a linearized asymptotic stability result for a
Caputo-Katugampola fractional-order systems is described. An application is
given to demonstrate the validity of the proposed results.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 09:32:28 GMT""},{""version"":""v2"",""created"":""Thu, 29 Mar 2018 23:44:04 GMT""}]","2018-04-02"
"1803.03784","Arun Singh","Arun Kumar Singh, Reza Ghabcheloo, Andreas Muller, Harit Pandya","Combining Method of Alternating Projections and Augmented Lagrangian for
  Task Constrained Trajectory Optimization","8 pages",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motion planning for manipulators under task space constraints is difficult as
it constrains the joint configurations to always lie on an implicitly defined
manifold. It is possible to view task constrained motion planning as an
optimization problem with non-linear equality constraints which can be solved
by general non-linear optimization techniques. In this paper, we present a
novel custom optimizer which exploits the underlying structure present in many
task constraints.
  At the core of our approach are some simple reformulations, which when
coupled with the \emph{method of alternating projection}, leads to an efficient
convex optimization based routine for computing a feasible solution to the task
constraints. We subsequently build on this result and use the concept of
Augmented Lagrangian to guide the feasible solutions towards those which also
minimize the user defined cost function. We show that the proposed optimizer is
fully distributive and thus, can be easily parallelized. We validate our
formulation on some common robotic benchmark problems. In particular, we show
that the proposed optimizer achieves cyclic motion in the joint space
corresponding to a similar nature trajectory in the task space. Furthermore, as
a baseline, we compare the proposed optimizer with an off-the-shelf non-linear
solver provide in open source package SciPy. We show that for similar task
constraint residuals and smoothness cost, it can be upto more than three times
faster than the SciPy alternative.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 10:03:09 GMT""}]","2018-03-13"
"1803.03785","Pavel Timonin","P. N. Timonin","Statistical mechanics of high-density bond percolation","12 pages, 1 figure","Phys. Rev. E 97, 052119 (2018)","10.1103/PhysRevE.97.052119",,"cond-mat.stat-mech cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-density (HD) percolation describes the percolation over specific
$\kappa$ -clusters, which are the compact sets of sites each connected to
$\kappa$ nearest filled sites at least. It takes place in the classical
patterns of independently distributed sites or bonds in which the ordinary
percolation transition also exsists. Hence, the study of series of $\kappa$
-type percolations amounts to the description of structure of classical
clusters for which $\kappa$ -clusters constitute $\kappa$ -cores nested one
into another. Such data are needed for description of a number of physical,
biological information and other properties of complex systems on random
lattices, graphs and networks. They range from magnetic properties of
semiconductor alloys to anomalies in supercooled water and clustering in
biological and social networks. Here we present the statistical mechanics
approach to study HD bond percolation on arbitrary graph. It is shown that
generating function for $\kappa$ -clusters' size distribution can be obtained
from partition function of specific $q$-state Potts-Ising model in $q \to 1$
limit. Using this approach we find exact $\kappa$ -clusters' size distribution
for Bethe lattice and Erdos Renyi graph. The application of the method to
Euclidean lattices is also discussed.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 10:03:49 GMT""},{""version"":""v2"",""created"":""Fri, 4 May 2018 12:25:15 GMT""}]","2018-05-17"
"1803.03786","Georgi Karadzhov","Georgi Karadzhov, Pepa Gencheva, Preslav Nakov, Ivan Koychev","We Built a Fake News & Click-bait Filter: What Happened Next Will Blow
  Your Mind!","RANLP'2017, 7 pages, 1 figure",,"10.26615/978-954-452-049-6_045",,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is completely amazing! Fake news and click-baits have totally invaded the
cyber space. Let us face it: everybody hates them for three simple reasons.
Reason #2 will absolutely amaze you. What these can achieve at the time of
election will completely blow your mind! Now, we all agree, this cannot go on,
you know, somebody has to stop it. So, we did this research on fake
news/click-bait detection and trust us, it is totally great research, it really
is! Make no mistake. This is the best research ever! Seriously, come have a
look, we have it all: neural networks, attention mechanism, sentiment lexicons,
author profiling, you name it. Lexical features, semantic features, we
absolutely have it all. And we have totally tested it, trust us! We have
results, and numbers, really big numbers. The best numbers ever! Oh, and
analysis, absolutely top notch analysis. Interested? Come read the shocking
truth about fake news and click-bait in the Bulgarian cyber space. You won't
believe what we have found!
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 10:09:13 GMT""}]","2018-03-13"
"1803.03787","Stephan Michael","Stephan Michael, Michael Lorke, Marian Cepok, Christian Carmesin,
  Frank Jahnke","Interplay of structural design and interaction processes in
  tunnel-injection semiconductor lasers",,"Phys. Rev. B 98, 165431 (2018)","10.1103/PhysRevB.98.165431",,"physics.app-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tunnel-injection lasers promise various advantages in comparison to
conventional laser designs. In this paper, we present a theoretical analysis
for the physics of the tunnel-injection process in quantum-dot based laser
devices. We describe the carrier dynamics in terms of scattering between states
of the coupled system consisting of injector quantum-well, tunnel-barrier, and
quantum-dots. Our analysis demonstrates how current quantum-dot based lasers
can benefit from the tunnel-injection design. We find that the often assumed
LO-phonon resonance condition for the level alignment only weakly influences
the injection rate of carriers into the quantum-dot states. On the other hand,
our investigations show that the energetic alignment of quantum-dot and
quantum-well states modifies the injection efficiency, as it controls the
hybridization strength. Our description of tunneling includes the
phonon-mediated and the Coulomb scattering contributions and is based on
material realistic electronic structure calculations.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 10:12:06 GMT""},{""version"":""v2"",""created"":""Tue, 30 Oct 2018 13:29:49 GMT""}]","2018-10-31"
"1803.03788","Bal\'azs B\'ar\'any Dr.","Bal\'azs B\'ar\'any and Micha{\l} Rams and K\'aroly Simon","Dimension of the repeller for a piecewise expanding affine map",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the dimension theory of a class of piecewise affine
systems in euclidean spaces suggested by Michael Barnsley, with some
applications to the fractal image compression. It is a more general version of
the class considered in the work of Keane, Simon and Solomyak [The dimension of
graph directed attractors with overlaps on the line, with an application to a
problem in fractal image recognition. {\it Fund. Math.}, {\bf 180}(3):279-292,
2003] and can be considered as the continuation of the works [On the dimension
of self-affine sets and measures with overlaps. {\it Proc. Amer. Math. Soc.},
{\bf 144}(10):4427-4440, 2016], [On the dimension of triangular self-affine
sets. {\it Erg. Th. \& Dynam. Sys.}, to appear.] by the authors. We also
present some applications of our results for the generalized Takagi functions
and fractal interpolation functions.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 10:33:03 GMT""},{""version"":""v2"",""created"":""Fri, 11 May 2018 14:24:16 GMT""},{""version"":""v3"",""created"":""Fri, 6 Mar 2020 12:55:14 GMT""}]","2020-03-09"
"1803.03789","Lewis Weinberger","Lewis H. Weinberger (Cambridge), Girish Kulkarni (Cambridge), Martin
  G. Haehnelt (Cambridge), Tirthankar Roy Choudhury (NCRA) and Ewald Puchwein
  (Cambridge)","Lyman-alpha emitters gone missing: the different evolution of the bright
  and faint populations","26 pages, 16 figures, 2 appendices; accepted for publication by MNRAS",,"10.1093/mnras/sty1563",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We model the transmission of the Lyman-alpha line through the circum- and
intergalactic media around dark matter haloes expected to host Lyman-alpha
emitters (LAEs) at z > 5.7, using the high-dynamic-range Sherwood simulations.
We find very different CGM environments around more massive haloes (~10^11
M_sun) compared to less massive haloes (~10^9 M_sun) at these redshifts, which
can contribute to a different evolution of the Lyman-alpha transmission from
LAEs within these haloes. Additionally we confirm that part of the differential
evolution could result from bright LAEs being more likely to reside in larger
ionized regions. We conclude that a combination of the CGM environment and the
IGM ionization structure is likely to be responsible for the differential
evolution of the bright and faint ends of the LAE luminosity function at z > 6.
More generally, we confirm the suggestion that the self-shielded neutral gas in
the outskirts of the host halo can strongly attenuate the Lyman-alpha emission
from high redshift galaxies. We find that this has a stronger effect on the
more massive haloes hosting brighter LAEs. The faint-end of the LAE luminosity
function is thus a more reliable probe of the average ionization state of the
IGM. Comparing our model for LAEs with a range of observational data we find
that the favoured reionization histories are our previously advocated `Late'
and `Very Late' reionization histories, in which reionization finishes rather
rapidly at around z ~ 6.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 10:33:17 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jun 2018 08:22:25 GMT""}]","2018-06-27"
"1803.03790","Junzhong Shen","Junzhong Shen, Yuran Qiao, You Huang, Mei Wen, Chunyuan Zhang","Towards a Multi-array Architecture for Accelerating Large-scale Matrix
  Multiplication on FPGAs","This paper has been accepet by IEEE International Symposium on
  Circuits and Systems (ISCAS 2018)",,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale floating-point matrix multiplication is a fundamental kernel in
many scientific and engineering applications. Most existing work only focus on
accelerating matrix multiplication on FPGA by adopting a linear systolic array.
This paper towards the extension of this architecture by proposing a scalable
and highly configurable multi-array architecture. In addition, we propose a
work-stealing scheme to ensure the equality in the workload partition among
multiple linear arrays. Furthermore, an analytical model is developed to
determine the optimal design parameters. Experiments on a real-life
convolutional neural network (CNN) show that we can obtain the optimal
extension of the linear array architecture.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 10:33:28 GMT""}]","2018-03-13"
"1803.03791","Vincent Lafforgue","Vincent Lafforgue","Shtukas for reductive groups and Langlands correspondence for function
  fields","ICM report",,,,"math.AG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss recent developments in the Langlands program for function fields,
and in the geometric Langlands program. In particular we explain a canonical
decomposition of the space of cuspidal automorphic forms for any reductive
group G over a function field, indexed by global Langlands parameters. The
proof uses the cohomology of G-shtukas with multiple modifications and the
geometric Satake equivalence.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 10:39:50 GMT""}]","2018-03-13"
"1803.03792","Nitin Agarwal","Daniel Rangel Rojas, Irmgard Tegeder, Rohini Kuner, Nitin Agarwal","Hypoxia-inducible factor 1a protects peripheral sensory neurons from
  diabetic peripheral neuropathy by suppressing accumulation of reactive oxygen
  species",,,,,"q-bio.CB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diabetic peripheral neuropathy (DPN) is one of the most common diabetic
complications. Mechanisms underlying nerve damage and sensory loss following
metabolic dysfunction remain large unclear. Recently, hyperglycemia-induced
mitochondrial dysfunction and the generation of ROS have gained attention as
possible mechanisms of organ damage in diabetes. Hypoxia-inducible factor
1(HIF1a) is a key transcription factor activated by hypoxia, hyperglycemia,
nitric oxide as well as ROS, suggesting a fundamental role in DPN
susceptibility. Genetically-modified mutant mice, which conditionally lack
HIF1a in peripheral sensory neurons (SNS-HIF1a-/-), were analyzed
longitudinally up to 6 months in the streptozotocin (STZ) model of type1
diabetes. Behavioral measurements of sensitivity to thermal and mechanical
stimuli, quantitative morphological analyses of intraepidermal nerve fiber
density and measurements of reactive oxygen species (ROS) in sensory neurons in
vivo were undertaken over several months post-STZ injections to delineate the
role of HIF1a in DPN. Longitudinal behavioral and morphological analyses at 5,
13 and 24 wks post-STZ treatment revealed that SNS-HIF1a-/- developed stronger
hyperglycemia-evoked losses of peripheral nociceptive sensory axons associated
with stronger losses of mechano- and heat sensation with a faster onset than
HIF1afl/fl mice. Mechanistically, these histomorphologic and behavioral
differences were associated with significantly higher level of STZ-induced
production of ROS in sensory neurons of SNS-HIF1a-/- mice as compared with
HIF1afl/fl. Our results indicate that HIF1a is as an upstream modulator of ROS
in peripheral sensory neurons and exerts a protective function in suppressing
hyperglycemia-induced nerve damage by limiting ROS levels. HIF1a stabilization
may be thus a new strategy target for limiting sensory loss, a debilitating
late complication of diabetes.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 11:29:56 GMT""}]","2018-03-13"
"1803.03793","Robert Hancock","Robert Hancock","The Maker-Breaker Rado game on a random set of integers","25 pages, 2 figures. Author accepted manuscript. Paper to appear in
  SIDMA",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given an integer-valued matrix $A$ of dimension $\ell \times k$ and an
integer-valued vector $b$ of dimension $\ell$, the Maker-Breaker $(A,b)$-game
on a set of integers $X$ is the game where Maker and Breaker take turns
claiming previously unclaimed integers from $X$, and Maker's aim is to obtain a
solution to the system $Ax=b$, whereas Breaker's aim is to prevent this. When
$X$ is a random subset of $\{1,\dots,n\}$ where each number is included with
probability $p$ independently of all others, we determine the threshold
probability $p_0$ for when the game is Maker or Breaker's win, for a large
class of matrices and vectors. This class includes but is not limited to all
pairs $(A,b)$ for which $Ax=b$ corresponds to a single linear equation. The
Maker's win statement also extends to a much wider class of matrices which
include those which satisfy Rado's partition theorem.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 11:34:09 GMT""},{""version"":""v2"",""created"":""Tue, 27 Nov 2018 22:44:57 GMT""}]","2018-11-29"
"1803.03794","Roxana Dumitrescu","Roxana Dumitrescu, Christoph Reisinger and Yufei Zhang","Approximation schemes for mixed optimal stopping and control problems
  with nonlinear expectations and jumps",,,,,"math.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a class of numerical schemes for mixed optimal stopping and
control of processes with infinite activity jumps and where the objective is
evaluated by a nonlinear expectation. Exploiting an approximation by switching
systems, piecewise constant policy timestepping reduces the problem to nonlocal
semi-linear equations with different control parameters, uncoupled over
individual time steps, which we solve by fully implicit monotone approximations
to the controlled diffusion and the nonlocal term, and specifically the
Lax-Friedrichs scheme for the nonlinearity in the gradient. We establish a
comparison principle for the switching system and demonstrate the convergence
of the schemes, which subsequently gives a constructive proof for the existence
of a solution to the switching system. Numerical experiments are presented for
a recursive utility maximization problem to demonstrate the effectiveness of
the new schemes.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 11:38:44 GMT""}]","2018-03-13"
"1803.03795","Toshitaka Aoki","Toshitaka Aoki","Classifying torsion classes for algebras with radical square zero via
  sign decomposition","25 pages. Change title. Many improvements and changes compared to the
  first version (in particular, mainly study torsion classes and $\tau$-tilting
  theory. The results in the first version is appeared in Section 3.4 and
  Section 5)",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To study the set of torsion classes of a finite dimensional basic algebra, we
use a decomposition, called sign-decomposition, parametrized by elements of
$\{\pm1\}^n$ where $n$ is the number of simple modules. If $A$ is an algebra
with radical square zero, then for each $\epsilon \in \{\pm1\}^n$ there is a
hereditary algebra $A_{\epsilon}^!$ with radical square zero and a bijection
between the set of torsion classes of $A$ associated to $\epsilon$ and the set
of faithful torsion classes of $A_{\epsilon}^!$. Furthermore, this bijection
preserves the property of being functorially finite. As an application in
$\tau$-tilting theory, we prove that the number of support $\tau$-tilting
modules over Brauer line algebras (resp. Brauer odd-cycle algebras) having $n$
edges is $\binom{2n}{n}$ (resp. $2^{2n-1}$).
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 11:39:10 GMT""},{""version"":""v2"",""created"":""Thu, 12 Sep 2019 20:00:45 GMT""}]","2019-09-16"
"1803.03796","Marion Barbeau","M. M. S. Barbeau and M. Eckstein and M. I. Katsnelson and J. H.
  Mentink","Optical control of competing exchange interactions and coherent
  spin-charge coupling in two-orbital Mott insulators","3 pages, 6 figures","SciPost Phys. 6, 027 (2019)","10.21468/SciPostPhys.6.3.027",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to have a better understanding of ultrafast electrical control of
exchange interactions in multi-orbital systems, we study a two-orbital Hubbard
model at half filling under the action of a time-periodic electric field. Using
suitable projection operators and a generalized time-dependent canonical
transformation, we derive an effective Hamiltonian which describes two
different regimes. First, for a wide range of non-resonant frequencies, we find
a change of the bilinear Heisenberg exchange $J_{\textrm{ex}}$ that is
analogous to the single-orbital case. Moreover we demonstrate that also the
additional biquadratic exchange interaction $B_{\textrm{ex}}$ can be enhanced,
reduced and even change sign depending on the electric field. Second, for
special driving frequencies, we demonstrate a novel spin-charge coupling
phenomenon enabling coherent transfer between spin and charge degrees of
freedom of doubly ionized states. These results are confirmed by an exact
time-evolution of the full two-orbital Mott-Hubbard Hamiltonian.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 11:39:47 GMT""},{""version"":""v2"",""created"":""Fri, 1 Feb 2019 11:37:14 GMT""}]","2019-03-06"
"1803.03797","Pawan Kumar","Sahithi Rampalli, Natasha Sehgal, Ishita Bindlish, Tanya Tyagi, and
  Pawan Kumar","Efficient FPGA Implementation of Conjugate Gradient Methods for
  Laplacian System using HLS","10 pages, 11 figures, 5 tables",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study FPGA based pipelined and superscalar design of two
variants of conjugate gradient methods for solving Laplacian equation on a
discrete grid; the first version corresponds to the original conjugate gradient
algorithm, and the second version corresponds to a slightly modified version of
the same.
  In conjugate gradient method to solve partial differential equations, matrix
vector operations are required in each iteration; these operations can be
implemented as 5 point stencil operations on the grid without explicitely
constructing the matrix. We show that a pipelined and superscalar design using
high level synthesis written in C language leads to a significant reduction in
latencies for both methods. When comparing these two, we show that the later
has roughly two times lower latency than the former given the same degree of
superscalarity. These reductions in latencies for the newer variant of CG is
due to parallel implementations of stencil operation on subdomains of the grid,
and dut to overlap of these stencil operations with dot product operations. In
a superscalar design, domain needs to be partitioned, and boundary data needs
to be copied, which requires padding. In 1D partition, the padding latency
increases as the number of partitions increase. For a streaming data flow
model, we propose a novel traversal of the grid for 2D domain decomposition
that leads to 2 times reduction in latency cost involved with padding compared
to 1D partitions. Our implementation is roughly 10 times faster than software
implementation for linear system of dimension $10000 \times 10000.$
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 12:05:35 GMT""}]","2018-03-13"
"1803.03798","Ilaria Caiazzo","Ilaria Caiazzo and Jeremy Heyl","Vacuum birefringence and the X-ray polarization from black-hole
  accretion disks","11 pages, 3 figures","Physical Review D 97, 083001 (2018)","10.1103/PhysRevD.97.083001",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the next decade, x-ray polarimetry will open a new window on the
high-energy Universe, as several missions that include an x-ray polarimeter are
currently under development. Observations of the polarization of x-rays coming
from the accretion disks of stellar-mass and supermassive black holes are among
the new polarimeters' major objectives. In this paper, we show that these
observations can be affected by the quantum electrodynamic (QED) effect of
vacuum birefringence: after an x-ray photon is emitted from the accretion disk,
its polarization changes as the photon travels through the accretion disk's
magnetosphere, as a result of the vacuum becoming birefringent in presence of a
magnetic field. We show that this effect can be important for black holes in
the energy band of the upcoming polarimeters, and has to be taken into account
in a complete model of the x-ray polarization that we expect to detect from
black-hole accretion disks, both for stellar mass and for supermassive black
holes. We find that, for a chaotic magnetic field in the disk, QED can
significantly decrease the linear polarization fraction of edge-on photons,
depending on the spin of the hole and on the strength of the magnetic field.
This effect can provide, for the first time, a direct way to probe the magnetic
field strength close to the innermost stable orbit of black-hole accretion
disks and to study the role of magnetic fields in astrophysical accretion in
general.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 12:14:55 GMT""},{""version"":""v2"",""created"":""Wed, 4 Apr 2018 18:40:25 GMT""}]","2018-04-10"
"1803.03799","Peng Gao","Mengchao Liu, Lichuan Jin, Jingmin Zhang, Qinghui Yang, Huaiwu Zhang,
  Peng Gao, and Dapeng Yu","Atomic-scale structure and chemistry of YIG/GGG Interface",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Y3Fe5O12 (YIG) is a promising candidate for spin wave devices. In the thin
film devices, the interface between YIG and substrate may play important roles
in determining the device properties. Here, we use spherical
aberration-corrected scanning electron microscopy and spectroscopy to study the
atomic arrangement, chemistry and electronic structure of the YIG/Gd3Ga5O12
(GGG) interface. We find that the chemical bonding of the interface is
FeO-GdGaO and the interface remains sharp in both atomic and electronic
structures. These results provide necessary information for understanding the
properties of interface and also for atomistic calculation.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 12:31:24 GMT""}]","2018-03-13"
"1803.03800","Pramod Kompalli","Srayanta Mukherjee, Devashish Shankar, Atin Ghosh, Nilam Tathawadekar,
  Pramod Kompalli, Sunita Sarawagi, Krishnendu Chaudhury","ARMDN: Associative and Recurrent Mixture Density Networks for eRetail
  Demand Forecasting",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate demand forecasts can help on-line retail organizations better plan
their supply-chain processes. The challenge, however, is the large number of
associative factors that result in large, non-stationary shifts in demand,
which traditional time series and regression approaches fail to model. In this
paper, we propose a Neural Network architecture called AR-MDN, that
simultaneously models associative factors, time-series trends and the variance
in the demand. We first identify several causal features and use a combination
of feature embeddings, MLP and LSTM to represent them. We then model the output
density as a learned mixture of Gaussian distributions. The AR-MDN can be
trained end-to-end without the need for additional supervision. We experiment
on a dataset of an year's worth of data over tens-of-thousands of products from
Flipkart. The proposed architecture yields a significant improvement in
forecasting accuracy when compared with existing alternatives.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 12:45:11 GMT""},{""version"":""v2"",""created"":""Fri, 16 Mar 2018 04:49:15 GMT""}]","2018-03-19"
"1803.03801","Claudia Andrei","Claudia Andrei","Properties of the coordinate ring of a convex polyomino",,,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify all convex polyomino whose coordinate rings are Gorenstein. We
also compute the Castelnuovo-Mumford regularity of the coordinate ring of any
stack polyomino in terms of the smallest interval which contains its vertices.
We give a recursive formula for computing the multiplicity of a stack
polyomino.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 12:51:00 GMT""}]","2018-03-13"
"1803.03802","Jingyi Zhao","M.Ablikim, M.N.Achasov, S. Ahmed, M.Albrecht, M.Alekseev, A.Amoroso,
  F.F.An, Q.An, Y.Bai, O.Bakina, R.Baldini Ferroli, Y.Ban, K.Begzsuren,
  D.W.Bennett, J.V.Bennett, N.Berger, M.Bertani, D.Bettoni, F.Bianchi, E.Boger,
  I.Boyko, R.A.Briere, H.Cai, X.Cai, O. Cakir, A.Calcaterra, G.F.Cao,
  S.A.Cetin, J.Chai, J.F.Chang, W.L.Chang, G.Chelkov, G.Chen, H.S.Chen,
  J.C.Chen, M.L.Chen, P.L.Chen, S.J.Chen, X.R.Chen, Y.B.Chen, X.K.Chu,
  G.Cibinetto, F.Cossio, H.L.Dai, J.P.Dai, A.Dbeyssi, D.Dedovich, Z.Y.Deng,
  A.Denig, I.Denysenko, M.Destefanis, F.DeMori, Y.Ding, C.Dong, J.Dong,
  L.Y.Dong, M.Y.Dong, Z.L.Dou, S.X.Du, P.F.Duan, J.Fang, S.S.Fang, Y.Fang,
  R.Farinelli, L.Fava, S.Fegan, F.Feldbauer, G.Felici, C.Q.Feng, E.Fioravanti,
  M.Fritsch, C.D.Fu, Q.Gao, X.L.Gao, Y.Gao, Y.G.Gao, Z.Gao, B. Garillon,
  I.Garzia, A.Gilman, K.Goetzen, L.Gong, W.X.Gong, W.Gradl, M.Greco, L.M.Gu,
  M.H.Gu, Y.T.Gu, A.Q.Guo, L.B.Guo, R.P.Guo, Y.P.Guo, A.Guskov, Z.Haddadi,
  S.Han, X.Q.Hao, F.A.Harris, K.L.He, X.Q.He, F.H.Heinsius, T.Held, Y.K.Heng,
  T.Holtmann, Z.L.Hou, H.M.Hu, J.F.Hu, T.Hu, Y.Hu, G.S.Huang, J.S.Huang,
  X.T.Huang, X.Z.Huang, Z.L.Huang, T.Hussain, W.Ikegami Andersson, M.Irshad,
  Q.Ji, Q.P.Ji, X.B.Ji, X.L.Ji, X.S.Jiang, X.Y.Jiang, J.B.Jiao, Z.Jiao,
  D.P.Jin, S.Jin, Y.Jin, T.Johansson, A.Julin, N.Kalantar-Nayestanaki,
  X.S.Kang, M.Kavatsyuk, B.C.Ke, T.Khan, A.Khoukaz, P. Kiese, R.Kliemt, L.Koch,
  O.B.Kolcu, B.Kopf, M.Kornicer, M.Kuemmel, M.Kuessner, A.Kupsc, M.Kurth,
  W.K\""uhn, J.S.Lange, M.Lara, P. Larin, L.Lavezzi, S.Leiber, H.Leithoff, C.Li,
  Cheng Li, D.M.Li, F.Li, F.Y.Li, G.Li, H.B.Li, H.J.Li, J.C.Li, J.W.Li, K.J.Li,
  Kang Li, Ke Li, Lei Li, P.L.Li, P.R.Li, Q.Y.Li, T. Li, W.D.Li, W.G.Li,
  X.L.Li, X.N.Li, X.Q.Li, Z.B.Li, H.Liang, Y.F.Liang, Y.T.Liang, G.R.Liao,
  L.Z.Liao, J.Libby, C.X.Lin, D.X.Lin, B.Liu, B.J.Liu, C.X.Liu, D.Liu, D.Y.Liu,
  F.H.Liu, Fang Liu, Feng Liu, H.B.Liu, H.LLiu, H.M.Liu, Huanhuan Liu, Huihui
  Liu, J.B.Liu, J.Y.Liu, K.Liu, K.Y.Liu, Ke Liu, L.D.Liu, Q.Liu, S.B.Liu,
  X.Liu, Y.B.Liu, Z.A.Liu, Zhiqing Liu, Y. F.Long, X.C.Lou, H.J.Lu, J.G.Lu,
  Y.Lu, Y.P.Lu, C.L.Luo, M.X.Luo, X.L.Luo, S.Lusso, X.R.Lyu, F.C.Ma, H.L.Ma,
  L.L. Ma, M.M.Ma, Q.M.Ma, X.N.Ma, X.Y.Ma, Y.M.Ma, F.E.Maas, M.Maggiora,
  Q.A.Malik, A.Mangoni, Y.J.Mao, Z.P.Mao, S.Marcello, Z.X.Meng,
  J.G.Messchendorp, G.Mezzadri, J.Min, T.J.Min, R.E.Mitchell, X.H.Mo, Y.J.Mo,
  C.Morales Morales, G.Morello, N.Yu.Muchnoi, H.Muramatsu, A.Mustafa,
  S.Nakhoul, Y.Nefedov, F.Nerling, I.B.Nikolaev, Z.Ning, S.Nisar, S.L.Niu,
  X.Y.Niu, S.L.Olsen, Q.Ouyang, S.Pacetti, Y.Pan, M.Papenbrock, P.Patteri,
  M.Pelizaeus, J.Pellegrino, H.P.Peng, Z.Y.Peng, K.Peters, J.Pettersson,
  J.L.Ping, R.G.Ping, A.Pitka, R.Poling, V.Prasad, H.R.Qi, M.Qi, T.Y.Qi,
  S.Qian, C.F.Qiao, N.Qin, X.S.Qin, Z.H.Qin, J.F.Qiu, K.H.Rashid, C.F.Redmer,
  M.Richter, M.Ripka, M.Rolo, G.Rong, Ch.Rosner, X.D.Ruan, A.Sarantsev,
  M.Savri\'e, C.Schnier, K.Schoenning, W.Shan, X.Y.Shan, M.Shao, C.P.Shen,
  P.X.Shen, X.Y.Shen, H.Y.Sheng, X.Shi, J.J.Song, W.M.Song, X.Y.Song, S.Sosio,
  C.Sowa, S.Spataro, G.X.Sun, J.F.Sun, L.Sun, S.S.Sun, X.H.Sun, Y.J.Sun,
  Y.KSun, Y.Z.Sun, Z.J.Sun, Z.T.Sun, Y.TTan, C.J.Tang, G.Y.Tang, X.Tang,
  I.Tapan, M.Tiemens, B.Tsednee, I.Uman, G.S.Varner, B.Wang, B.L.Wang,
  C.W.Wang, D.Wang, D.Y.Wang, Dan Wang, K.Wang, L.L.Wang, L.S.Wang, M.Wang,
  Meng Wang, P.Wang, P.L.Wang, W.P.Wang, X.F.Wang, Y.Wang, Y.F.Wang, Y.Q.Wang,
  Z.Wang, Z.G.Wang, Z.Y.Wang, Zongyuan Wang, T.Weber, D.H.Wei, P.Weidenkaff,
  S.P.Wen, U.Wiedner, M.Wolke, L.H.Wu, L.J.Wu, Z.Wu, L.Xia, X.Xia, Y.Xia,
  D.Xiao, Y.J.Xiao, Z.J.Xiao, Y.G.Xie, Y.H.Xie, X.A.Xiong, Q.L.Xiu, G.F.Xu,
  J.J.Xu, L.Xu, Q.J.Xu, Q.N.Xu, X.P.Xu, F.Yan, L.Yan, W.B.Yan, W.C.Yan,
  Y.H.Yan, H.J.Yang, H.X.Yang, L.Yang, S.L.Yang, Y.H.Yang, Y.X.Yang, Yifan
  Yang, M.Ye, M.H.Ye, J.H.Yin, Z.Y.You, B.X.Yu, C.X.Yu, J.S.Yu, C.Z.Yuan,
  Y.Yuan, A.Yuncu, A.A.Zafar, A.Zallo, Y.Zeng, Z.Zeng, B.X.Zhang, B.Y.Zhang,
  C.C.Zhang, D.H.Zhang, H.H.Zhang, H.Y.Zhang, J.Zhang, J.L.Zhang, J.Q.Zhang,
  J.W.Zhang, J.Y.Zhang, J.Z.Zhang, K.Zhang, L.Zhang, S.F.Zhang, T.J.Zhang,
  X.Y.Zhang, Y.Zhang, Y.H.Zhang, Y.T.Zhang, Yang Zhang, Yao Zhang, Yu Zhang,
  Z.H.Zhang, Z.P.Zhang, Z.Y.Zhang, G.Zhao, J.W.Zhao, J.Y.Zhao, J.Z.Zhao, Lei
  Zhao, Ling Zhao, M.G.Zhao, Q.Zhao, S.J.Zhao, T.C.Zhao, Y.B.Zhao, Z.G.Zhao,
  A.Zhemchugov, B.Zheng, J.P.Zheng, W.J.Zheng, Y.H.Zheng, B.Zhong, L.Zhou,
  Q.Zhou, X.Zhou, X.K.Zhou, X.R.Zhou, X.Y.Zhou, A.N.Zhu, J.Zhu, J.Zhu, K.Zhu,
  K.J.Zhu, S.Zhu, S.H.Zhu, X.L.Zhu, Y.C.Zhu, Y.S.Zhu, Z.A.Zhu, J.Zhuang,
  B.S.Zou, J.H.Zou","Measurement of the Integrated Luminosities of Cross-section Scan Data
  Samples Around the $\psi(3770)$ Mass Region",,"Chinese Physics C, 2018, 42(6): 063001","10.1088/1674-1137/42/6/063001",,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To investigate the nature of the $\psi(3770)$ resonance and to measure the
cross section for $e^+e^- \to D\bar{D}$, a cross-section scan data sample,
distributed among 41 center-of-mass energy points from 3.73 to 3.89~GeV, was
taken with the BESIII detector operated at the BEPCII collider in the year
2010. By analyzing the large angle Bhabha scattering events, we measure the
integrated luminosity of the data sample at each center-of-mass energy point.
The total integrated luminosity of the data sample is
$76.16\pm0.04\pm0.61$~pb$^{-1}$, where the first uncertainty is statistical and
the second systematic.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 12:52:23 GMT""},{""version"":""v2"",""created"":""Thu, 17 May 2018 16:37:30 GMT""}]","2018-05-18"
"1803.03803","Thomas Deschatre","Deschatre Thomas and F\'eron Olivier and Hoffmann Marc","Estimating fast mean-reverting jumps in electricity market models",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on empirical evidence of fast mean-reverting spikes, we model
electricity price processes $X+Z^\beta$ as the sum of a continuous It\^o
semimartingale $X$ and a a mean-reverting compound Poisson process $Z_t^\beta =
\int_0^t \int_{\mathbb{R}} xe^{-\beta(t-s)}\underline{p}(ds,dt)$ where
$\underline{p}(ds,dt)$ is Poisson random measure with intensity $\lambda
ds\otimes dt$. In a first part, we investigate the estimation of
$(\lambda,\beta)$ from discrete observations and establish asymptotic
efficiency in various asymptotic settings. In a second part, we discuss the use
of our inference results for correcting the value of forward contracts on
electricity markets in presence of spikes. We implement our method on real data
in the French, Greman and Australian market over 2015 and 2016 and show in
particular the effect of spike modelling on the valuation of certain strip
options. In particular, we show that some out-of-the-money options have a
significant value if we incorporate spikes in our modelling, while having a
value close to $0$ otherwise.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 13:14:11 GMT""},{""version"":""v2"",""created"":""Fri, 8 Jan 2021 14:31:58 GMT""}]","2021-01-11"
"1803.03804","I. A. Fomin","I. A. Fomin","Analog of Anderson theorem for the polar phase of liquid 3He in nematic
  aerogel","10 pages. Russian version will be published in ZhETF vol.154,
  iss.,5(11)","JETP, 2018, Vol. 127, No 5, pp.933-938: original ZhETF 2018,
  Vol.154, 1034-1040","10.1134/S106377611811002X",,"cond-mat.dis-nn cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that if impurities in superfluid 3He have form of infinitely long
non-magnetic strands, which are straight, parallel to each other and reflect
quasi-particles specularly, the temperature of transition of liquid 3He from
the normal into the polar phase coincides with that for the bulk liquid without
impurities. Magnetic scattering lowers transition temperature for the polar
phase in analogy with the conventional superconductors. These results are
discussed in connection with the recent experimental findings.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 13:27:40 GMT""},{""version"":""v2"",""created"":""Mon, 3 Sep 2018 16:55:26 GMT""}]","2019-04-22"
"1803.03805","Itai Benjamini","Itai Benjamini and Gady Kozma","Two comments on balls in vertex transitive graphs","The main result appeared already in arXiv:1411.6534",,,,"math.CO math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We observe that a ball of radius $1$ in the grandfather graph can not be
realized as a ball of radius $1$ in a finite vertex transitive graph. We remark
on when a ball in a finite vertex transitive graph appears as a ball in an
infinite vertex transitive graph.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 13:39:03 GMT""},{""version"":""v2"",""created"":""Tue, 13 Mar 2018 16:28:33 GMT""}]","2018-03-14"
"1803.03806","Reudismam Rolim","Reudismam Rolim, Gustavo Soares, Rohit Gheyi, Titus Barik, Loris
  D'Antoni","Learning Quick Fixes from Code Repositories","12 pages",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Code analyzers such as Error Prone and FindBugs detect code patterns
symptomatic of bugs, performance issues, or bad style. These tools express
patterns as quick fixes that detect and rewrite unwanted code. However, it is
difficult to come up with new quick fixes and decide which ones are useful and
frequently appear in real code. We propose to rely on the collective wisdom of
programmers and learn quick fixes from revision histories in software
repositories. We present REVISAR, a tool for discovering common Java edit
patterns in code repositories. Given code repositories and their revision
histories, REVISAR (i) identifies code edits from revisions and (ii) clusters
edits into sets that can be described using an edit pattern. The designers of
code analyzers can then inspect the patterns and add the corresponding quick
fixes to their tools. We ran REVISAR on nine popular GitHub projects, and it
discovered 89 useful edit patterns that appeared in 3 or more projects.
Moreover, 64% of the discovered patterns did not appear in existing tools. We
then conducted a survey with 164 programmers from 124 projects and found that
programmers significantly preferred eight out of the nine of the discovered
patterns. Finally, we submitted 16 pull requests applying our patterns to 9
projects and, at the time of the writing, programmers accepted 6 (60%) of them.
The results of this work aid toolsmiths in discovering quick fixes and making
informed decisions about which quick fixes to prioritize based on patterns
programmers actually apply in practice.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 13:41:48 GMT""},{""version"":""v2"",""created"":""Sat, 8 Sep 2018 00:10:38 GMT""}]","2018-09-11"
"1803.03807","Tomer Golomb","Tomer Golomb, Yisroel Mirsky and Yuval Elovici","CIoTA: Collaborative IoT Anomaly Detection via Blockchain","Appears in the workshop on Decentralized IoT Security and Standards
  (DISS) of the Network and Distributed Systems Security Symposium (NDSS) 2018",,,,"cs.CY cs.CR cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to their rapid growth and deployment, Internet of things (IoT) devices
have become a central aspect of our daily lives. However, they tend to have
many vulnerabilities which can be exploited by an attacker. Unsupervised
techniques, such as anomaly detection, can help us secure the IoT devices.
However, an anomaly detection model must be trained for a long time in order to
capture all benign behaviors. This approach is vulnerable to adversarial
attacks since all observations are assumed to be benign while training the
anomaly detection model.
  In this paper, we propose CIoTA, a lightweight framework that utilizes the
blockchain concept to perform distributed and collaborative anomaly detection
for devices with limited resources. CIoTA uses blockchain to incrementally
update a trusted anomaly detection model via self-attestation and consensus
among IoT devices. We evaluate CIoTA on our own distributed IoT simulation
platform, which consists of 48 Raspberry Pis, to demonstrate CIoTA's ability to
enhance the security of each device and the security of the network as a whole.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 13:53:19 GMT""},{""version"":""v2"",""created"":""Mon, 9 Apr 2018 19:09:08 GMT""}]","2018-04-11"
"1803.03808","Sathiyadevi K","K. Sathiyadevi, V. K. Chandrasekar, D. V. Senthilkumar and M.
  Lakshmanan","Distinct collective states due to the trade-off between attractive and
  repulsive couplings","Accepted for publication in Phys. Rev. E",,"10.1103/PhysRevE.97.032207",,"nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the effect of repulsive coupling together with an attractive
coupling in a network of nonlocally coupled oscillators. To understand the
complex interaction between these two couplings we introduce a control
parameter in the repulsive coupling which plays a crucial role in inducing
distinct complex collective patterns. In particular, we show the emergence of
various cluster chimera death states through a dynamically distinct transition
route, namely the oscillatory cluster state and coherent oscillation death
state as a function of the repulsive coupling in the presence of the attractive
coupling. In the oscillatory cluster state, the oscillators in the network are
grouped into two distinct dynamical states of homogeneous and inhomogeneous
oscillatory states. Further, the network of coupled oscillators follows the
same transition route in the entire coupling range. Depending upon distinct
coupling ranges the system displays a different number of clusters in the death
state and oscillatory state. We also observe that the number of coherent
domains in the oscillatory cluster state exponentially decreases with increase
in coupling range and obeys a power law decay. Additionally, we show analytical
stability for observed solitary state, synchronized state, and incoherent
oscillation death state.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:00:40 GMT""}]","2018-04-04"
"1803.03809","Bertrand Roehner","Ruiqi Li, Peter Richmond and Bertrand M. Roehner","Effect of population density on epidemics","16 pages, 7 figures",,"10.1016/j.physa.2018.07.025",,"physics.soc-ph physics.bio-ph q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Investigations of a possible connection between population density and the
propagation and magnitude of epidemics have so far led to mixed and
unconvincing results. There are three reasons for that. (i) Previous studies
did not focus on the appropriate density interval. (ii) For the density to be a
meaningful variable the population must be distributed as uniformly as
possible. If an area has towns and cities where a majority of the population is
concentrated its average density is meaningless. (iii) In the propagation of an
epidemic the initial proportion of susceptibles (that is to say persons who
have not developed an immunity) is an essential, yet usually unknown, factor.
The assumption that most of the population is susceptible holds only for new
strain of diseases.
  It will be shown that when these requirements are taken care of, the size of
epidemics is indeed closely connected with the population density. This
empirical observation comes as a welcome confirmation of the classical KMK
(Kermack-McKendrick 1927) model. Indeed, one of its key predictions is that the
size of the epidemic increases strongly (and in a non linear way) with the
initial density of susceptibles.
  An interesting consequence is that, contrary to common beliefs, in sparsely
populated territories, like Alaska, Australia or the west coast of the United
states the size of epidemics among native populations must have been limited by
the low density even for diseases for which the natives had no immunity (i.e.,
were susceptibles).
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:05:02 GMT""}]","2018-08-15"
"1803.03810","Habib Marzougui","Habib Marzougui and Issam Naghmouchi","Minimal sets and orbit space for group actions on local dendrites","16 pages","Math. Z. (2018)","10.1007/s00209-018-2226-7",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a group $G$ acting on a local dendrite $X$ (in particular on a
graph). We give a full characterization of minimal sets of $G$ by showing that
any minimal set $M$ of $G$ (whenever $X$ is different from a dendrite) is
either a finite orbit, or a Cantor set, or a circle. If $X$ is a graph
different from a circle, such a minimal $M$ is a finite orbit. These results
extend those of the authors for group actions on dendrites. On the other hand,
we show that, for any group $G$ acting on a local dendrite $X$ different from a
circle, the following properties are equivalent: (1) ($G, X$) is pointwise
almost periodic. (2) The orbit closure relation $R = \{(x, y)\in X\times X:
y\in \overline{G(x)}\}$ is closed. (3) Every non-endpoint of $X$ is periodic.
In addition, if $G$ is countable and $X$ is a local dendrite, then ($G, X$) is
pointwise periodic if and only if the orbit space $X/G$ is Hausdorff.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:08:25 GMT""}]","2019-01-15"
"1803.03811","Alireza Saffarzadeh","Hassan Ghadiri and Alireza Saffarzadeh","Band-offset-induced lateral shift of valley electrons in ferromagnetic
  MoS$_2$/WS$_2$ planar heterojunctions","9 pages, 7 figures","J. Appl. Phys. 123, 104301 (2018)","10.1063/1.5012775",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-energy coherent transport and Goos-H\""{a}nchen (GH) lateral shift of
valley electrons in planar heterojunctions composed of normal MoS$_2$ and
ferromagnetic WS$_2$ monolayers are theoretically investigated. Two types of
heterojunctions in the forms of WS$_2$/MoS$_2$/WS$_2$ (type-A) and
MoS$_2$/WS$_2$/MoS$_2$ (type-B) with incident electrons in MoS$_2$ region are
considered in which the lateral shift of electrons is induced by band
alignments of the two constituent semiconductors. It is shown that the type-A
heterojunction can act as an electron waveguide due to electron confinement
between the two WS$_2$/MoS$_2$ interfaces which cause the incident electrons
with an appropriate incidence angle to propagate along the interfaces. In this
case the spin- and valley-dependent GH shifts of totally reflected electrons
from the interface lead to separated electrons with distinct spin-valley
indexes after traveling a sufficiently long distance. In type-B heterojunction,
however, transmission resonances occur for incident electron beams passing
through the structure, and large spin- and valley-dependent lateral shift
values in propagating states can be achieved. Consequently, the transmitted
electrons are spatially well-separated into electrons with distinct spin-valley
indexes. Our findings reveal that the planar heterojunctions of transition
metal dichalcogenides can be utilized as spin-valley beam filter and/or
splitter without external gating.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:10:48 GMT""}]","2018-03-13"
"1803.03812","Ravi Kumar Kopparapu","Ravi Kopparapu, Eric Hebrard, Rus Belikov, Natalie M. Batalha, Gijs D.
  Mulders, Chris Stark, Dillon Teal, Shawn Domagal-Goldman, Dawn Gelino, Avi
  Mandell, Aki Roberge, Stephen Rinehart, Stephen R. Kane, Yasuhiro Hasegawa,
  Wade Henning, Brian Hicks, Vardan Adibekyan, Edward W. Schwieterman, Erika
  Kohler, Johanna Teske, Natalie Hinkel, Conor Nixon, Kevin France, William
  Danchi, Jacob Haqq-Misra, Eric T. Wolf, Scott D. Guzewich, Benjamin Charnay,
  Giada Arney, Hilairy E. Hartnett, Eric D. Lopez, Dante Minniti, Joe Renaud,
  Vladimir Airapetian, Chuanfei Dong, Anthony D. Del Genio, Melissa Trainer,
  Gioia Rau, Adam Jensen, Michael Way, Carey M. Lisse, Wladimir Lyra, Franck
  Marchis, Daniel Jontof-Hutter, Patrick Young, Ray Pierrehumbert, Chester E.
  Harman, Jonathan Fortney, Bill Moore, Steven Beckwith, Everett Shock, Steve
  Desch, Kathleen E. Mandt, Noam Izenberg, Eric B. Ford, Shannon Curry, Caleb
  Scharf, Ariel Anbar","Exoplanet Diversity in the Era of Space-based Direct Imaging Missions","A white paper submitted to the National Academy of Sciences Exoplanet
  Science Strategy",,,,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This whitepaper discusses the diversity of exoplanets that could be detected
by future observations, so that comparative exoplanetology can be performed in
the upcoming era of large space-based flagship missions. The primary focus will
be on characterizing Earth-like worlds around Sun-like stars. However, we will
also be able to characterize companion planets in the system simultaneously.
This will not only provide a contextual picture with regards to our Solar
system, but also presents a unique opportunity to observe size dependent
planetary atmospheres at different orbital distances. We propose a preliminary
scheme based on chemical behavior of gases and condensates in a planet's
atmosphere that classifies them with respect to planetary radius and incident
stellar flux.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:18:37 GMT""}]","2018-03-13"
"1803.03813","Dorin Bucur","Dorin Bucur, Ilaria Fragal\`a, Alessandro Giacomini","Optimal partitions for Robin Laplacian eigenvalues",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the existence of an optimal partition for the multiphase shape
optimization problem which consists in minimizing the sum of the first Robin
Laplacian eigenvalue of $k$ mutually disjoint {\it open} sets which have a
$\mathcal H ^ {d-1}$-countably rectifiable boundary and are contained into a
given box $D$ in $R^d$
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:21:16 GMT""}]","2018-03-13"
"1803.03814","Maresuke Shiraishi","Gabriele Franciolini, Alex Kehagias, Antonio Riotto, Maresuke
  Shiraishi","Detecting higher spin fields through statistical anisotropy in the CMB
  bispectrum","11 pages, 5 figures","Phys. Rev. D 98, 043533 (2018)","10.1103/PhysRevD.98.043533",,"astro-ph.CO gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inflation may provide a suitable collider to probe physics at very high
energies. In this paper we investigate the impact on the CMB bispectrum of
higher spin fields which are long-lived on super-Hubble scales, e.g. partially
massless higher spin fields. We show that distinctive statistical anisotropic
signals on the CMB three-point correlator are induced and we investigate their
detectability.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:24:16 GMT""}]","2018-08-30"
"1803.03815","Kashif Ammar Yasir","Kashif Ammar Yasir, Lin Zhuang, and Wu-Ming Liu","Topological Nonlinear Optics with Spin-Orbit coupled Bose-Einstein
  Condensate in Cavity","10 pages, 9 figures",,,,"physics.optics cond-mat.quant-gas physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report topological nonlinear optics with spin-orbit coupled Bose-Einstein
condensate in a cavity. The cavity is driven by a pump laser and weak probe
laser which excite Bose-Einstein condensate to an intermediate storage level,
where the standard Raman process engineers spin-orbit coupling. We show that
the nonlinear photonic interactions at the transitional pathways of dressed
states result in new type of optical transparencies, which get completely
inverted with atom induced gain. These nonlinear interactions also implant
topological sort of features in probe transmission modes by inducing gapless
Dirac-like cones, which become gaped in presence of Raman detuning. The
topological features get interestingly enhanced in gain regime where the
gapless topological edge-like states emerge among the probe modes, which can
cause non-trivial phase transition. We show that spin-orbit coupling and Zeeman
field effects also impressively revamp fast and slow probe light. The
manipulation of dressed states for quantum nonlinear optics with topological
characteristics in our findings could be a crucial step towards topological
quantum computation.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:28:10 GMT""}]","2018-03-13"
"1803.03816","Mostafa Gamal","Mostafa Gamal, Mennatullah Siam, Moemen Abdel-Razek","ShuffleSeg: Real-time Semantic Segmentation Network","6 pages, under review by ICIP 2018",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-time semantic segmentation is of significant importance for mobile and
robotics related applications. We propose a computationally efficient
segmentation network which we term as ShuffleSeg. The proposed architecture is
based on grouped convolution and channel shuffling in its encoder for improving
the performance. An ablation study of different decoding methods is compared
including Skip architecture, UNet, and Dilation Frontend. Interesting insights
on the speed and accuracy tradeoff is discussed. It is shown that skip
architecture in the decoding method provides the best compromise for the goal
of real-time performance, while it provides adequate accuracy by utilizing
higher resolution feature maps for a more accurate segmentation. ShuffleSeg is
evaluated on CityScapes and compared against the state of the art real-time
segmentation networks. It achieves 2x GFLOPs reduction, while it provides on
par mean intersection over union of 58.3% on CityScapes test set. ShuffleSeg
runs at 15.7 frames per second on NVIDIA Jetson TX2, which makes it of great
potential for real-time applications.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:28:45 GMT""},{""version"":""v2"",""created"":""Thu, 15 Mar 2018 10:08:00 GMT""}]","2018-03-16"
"1803.03817","Hiroshi Isono","Ignatios Antoniadis, Auttakit Chatrabhuti, Hiroshi Isono, Rob Knoops","Fayet-Iliopoulos terms in supergravity and D-term inflation","19 pages, 7 figures",,"10.1140/epjc/s10052-018-5861-6",,"hep-th astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyse the consequences of a new gauge invariant Fayet-Iliopoulos (FI)
term proposed recently to a class of inflation models driven by supersymmetry
breaking with the inflaton being the superpartner of the goldstino. We first
show that charged matter fields can be consistently added with the new term, as
well as the standard FI term in supergravity in a K\""ahler frame where the
$U(1)$ is not an R-symmetry. We then show that the slow-roll conditions can be
easily satisfied with inflation driven by a D-term depending on the two FI
parameters. Inflation starts at initial conditions around the maximum of the
potential where the $U(1)$ symmetry is restored and stops when the inflaton
rolls down to the minimum describing the present phase of our Universe. The
resulting tensor-to-scalar ratio of primordial perturbations can be even at
observable values in the presence of higher order terms in the K\""ahler
potential.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:29:24 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jun 2018 11:21:04 GMT""}]","2018-06-19"
"1803.03818","Hendrik Schatz","R. Lau, M. Beard, S. S. Gupta, H. Schatz, A. V. Afanasjev, E. F.
  Brown, A. Deibel, L. R. Gasques, G. W. Hitt, W. R. Hix, L. Keek, P. M\""oller,
  P. S. Shternin, A. Steiner, M. Wiescher, Y. Xu","Nuclear Reactions in the Crusts of Accreting Neutron Stars","25 Pages, accepted for publication in Ap. J",,"10.3847/1538-4357/aabfe0",,"astro-ph.HE astro-ph.SR nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  X-ray observations of transiently accreting neutron stars during quiescence
provide information about the structure of neutron star crusts and the
properties of dense matter. Interpretation of the observational data requires
an understanding of the nuclear reactions that heat and cool the crust during
accretion, and define its nonequilibrium composition. We identify here in
detail the typical nuclear reaction sequences down to a depth in the inner
crust where the mass density is 2E12 g/cm^3 using a full nuclear reaction
network for a range of initial compositions. The reaction sequences differ
substantially from previous work. We find a robust reduction of crust impurity
at the transition to the inner crust regardless of initial composition, though
shell effects can delay the formation of a pure crust somewhat to densities
beyond 2E12 g/cm^3. This naturally explains the small inner crust impurity
inferred from observations of a broad range of systems. The exception are
initial compositions with A >= 102 nuclei, where the inner crust remains impure
with an impurity parameter of Qimp~20 due to the N = 82 shell closure. In
agreement with previous work we find that nuclear heating is relatively robust
and independent of initial composition, while cooling via nuclear Urca cycles
in the outer crust depends strongly on initial composition. This work forms a
basis for future studies of the sensitivity of crust models to nuclear physics
and provides profiles of composition for realistic crust models.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:54:09 GMT""},{""version"":""v2"",""created"":""Sat, 21 Apr 2018 12:40:08 GMT""}]","2018-06-06"
"1803.03819","Rikito Ohta","Rikito Ohta, Shinnosuke Okawa","On ruled surfaces with big anti-canonical divisor and numerically
  trivial divisors on weak log Fano surfaces","14 pages. This is version 2; minor changes",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the structure of geometrically ruled surfaces whose
anti-canonical class is big. As an application we show that the Picard group of
a normal projective surface whose anti-canonical class is nef and big is a free
abelian group of finite rank.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 14:55:14 GMT""},{""version"":""v2"",""created"":""Tue, 15 Sep 2020 09:06:12 GMT""}]","2020-09-16"
"1803.03820","Atsushi Hariki","Atsushi Hariki, Mathias Winder, and Jan Kune\v{s}","Continuum Charge Excitations in High-Valence Transition-Metal Oxides
  Revealed by Resonant Inelastic X-ray Scattering",,"Phys. Rev. Lett. 121, 126403 (2018)","10.1103/PhysRevLett.121.126403",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a theoretical investigation of the origin of Raman-like and
fluorescencelike (FL) features of resonant inelastic x-ray scattering (RIXS)
spectra. Using a combination of local-density approximation + dynamical
mean-field theory and a configuration interaction solver for Anderson impurity
model, we calculate the $L$-edge RIXS and x-ray absorption spectra of
high-valence transition-metal oxides LaCuO$_3$ and NaCuO$_2$. We analyze in
detail the behavior of the FL feature and show how it is connected to the
details of electronic and crystal structure. On the studied compounds we
demonstrate how material details determine whether the electron-hole continuum
can be excited in the $L$-edge RIXS process.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 15:08:07 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jun 2018 07:58:08 GMT""},{""version"":""v3"",""created"":""Thu, 6 Sep 2018 14:50:17 GMT""},{""version"":""v4"",""created"":""Thu, 13 Sep 2018 12:00:39 GMT""}]","2018-09-26"
"1803.03821","Nikolay Kuznetsov","Maria Kiseleva, Nikolay Kuznetsov and Gennady Leonov","Theory of differential inclusions and its application in mechanics",,,"10.1007/978-3-319-62464-8_9",,"math.DS nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The following chapter deals with systems of differential equations with
discontinuous right-hand sides. The key question is how to define the solutions
of such systems. The most adequate approach is to treat discontinuous systems
as systems with multivalued right-hand sides (differential inclusions). In this
work three well-known definitions of solution of discontinuous system are
considered. We will demonstrate the difference between these definitions and
their application to different mechanical problems. Mathematical models of
drilling systems with discontinuous friction torque characteristics are
considered. Here, opposite to classical Coulomb symmetric friction law, the
friction torque characteristic is asymmetrical. Problem of sudden load change
is studied. Analytical methods of investigation of systems with such
asymmetrical friction based on the use of Lyapunov functions are demonstrated.
The Watt governor and Chua system are considered to show different aspects of
computer modeling of discontinuous systems.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 15:09:32 GMT""}]","2018-03-14"
"1803.03822","Adam Prenosil","Adam Prenosil","Cut elimination, identity elimination, and interpolation in super-Belnap
  logics",,"Studia Logica 105 (6), pp. 1255-1289, 2017",,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a Gentzen-style proof theory for super-Belnap logics (extensions
of the four-valued Dunn-Belnap logic), expanding on an approach initiated by
Pynko. We show that just like substructural logics may be understood
proof-theoretically as logics which relax the structural rules of classical
logic but keep its logical rules as well as the rules of Identity and Cut,
super-Belnap logics may be seen as logics which relax Identity and Cut but keep
the logical rules as well as the structural rules of classical logic. A
generalization of the cut elimination theorem for classical propositional logic
is then proved and used to establish interpolation for various super-Belnap
logics. In particular, we obtain an alternative syntactic proof of a refinement
of the Craig interpolation theorem for classical propositional logic discovered
recently by Milne.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 15:09:52 GMT""}]","2018-03-13"
"1803.03823","Emad Ali Al-Hilaly Dr.","Emad Ali Al-Hilaly, Israa Jameel","Examining the Efficiency of Sun Lightening and Shadow Tools in AutoCAD
  Program","25 pages, 7 figures",,,,"physics.pop-ph physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  The AutoCAD is one of the most famous Computer Aided Drawing programs with
high and accurate specifications in the engineering design. It is highly
qualified and contains many of the tools it needs in many engineering
departments. A useful tool is the lighting tool because it gives a simulated
rendering of reality to a great degree that benefits the architect as well as
urban designers. This tool includes simulating sunlight by date during the
year, timing of day, and position of the body on the Earth. We tested the
sunlight status tools in this program in the limit of our test region to see
how accurate it was and it turned out to have a 45% error difference. The sun
shadow in AutoCAD rendering is longer than the real by 145%. There is another
error in the direction of shadow also. It is essential to note these errors for
any designer need to calculate the shadow length and direction from the AutoCAD
program.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 15:10:00 GMT""}]","2018-03-13"
"1803.03824","Anton Andronic","R. Rapp, P.B. Gossiaux, A. Andronic, R.Averbeck, S.Masciocchi, A.
  Beraudo, E. Bratkovskaya, P. Braun-Munzinger, S. Cao, A. Dainese, S.K. Das,
  M. Djordjevic, V. Greco, M. He, H. van Hees, G. Inghirami, O. Kaczmarek,
  Y.-J. Lee, J. Liao, S.Y.F. Liu, G. Moore, M. Nahrgang, J. Pawlowski, P.
  Petreczky, S. Plumari, F. Prino, S. Shi, T. Song, J. Stachel, I. Vitev, X.-N.
  Wang","Extraction of Heavy-Flavor Transport Coefficients in QCD Matter","78 pages, 29 figures, report on an EMMI Rapid Reaction Task Force;
  v2: small revision, accepted for publication in Nucl. Phys. A",,"10.1016/j.nuclphysa.2018.09.002",,"nucl-th hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on broadly based systematic investigations of the modeling
components for open heavy-flavor diffusion and energy loss in strongly
interacting matter in their application to heavy-flavor observables in
high-energy heavy-ion collisions, conducted within an EMMI Rapid Reaction Task
Force framework. Initial spectra including cold-nuclear-matter effects, a wide
variety of space-time evolution models, heavy-flavor transport coefficients,
and hadronization mechanisms are scrutinized in an effort to quantify pertinent
uncertainties in the calculations of nuclear modification factors and elliptic
flow of open heavy-flavor particles in nuclear collisions. We develop
procedures for error assessments and criteria for common model components to
improve quantitative estimates for the (low-momentum) heavy-flavor diffusion
coefficient as a long-wavelength characteristic of QCD matter as a function of
temperature, and for energy loss coefficients of high-momentum heavy-flavor
particles.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 15:13:41 GMT""},{""version"":""v2"",""created"":""Fri, 7 Sep 2018 19:03:39 GMT""}]","2018-10-17"
"1803.03825","Yogesh Singh","Amit, R. K. Gopal, and Yogesh Singh","Observation of Chiral character deep in the topological insulating
  regime in Bi$_{1-x}$Sb$_x$","5 Pages, 4 figures",,,,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bi$_{1-x}$Sb$_x$ is a topological insulator (TI) for $x \approx 0.03
$--$0.20$. Close to the Topological phase transition at $x = 0.03$, a magnetic
field induced Weyl semi-metal (WSM) state is stabilized due to the splitting of
the Dirac cone into two Weyl cones of opposite chirality. A signature of the
Weyl state is the observation of a Chiral anomaly [negative longitudnal
magnetoresistance (LMR)] and a violation of the Ohm's law (non-linear $I-V$).
We report the unexpected discovery of a Chiral anomaly in the whole range ($x =
0.032, 0.072, 0.16$) of the TI state. This points to a field induced WSM state
in an extended $x$ range and not just near the topological transition at $x =
0.03$. Surprisingly, the strongest Weyl phase is found at $x = 0.16$ with a
non-saturating negative LMR much larger than observed for $x = 0.03$. The
negative LMR vanishes rapidly with increasing angle between $B$ and $I$.
Additionally, non-linear $I$--$V$ is found for $x = 0.16$ indicating a
violation of Ohm's law. This unexpected observation of a strong Weyl state in
the whole TI regime in Bi$_{1-x}$Sb$_x$ points to a gap in our understanding of
the detailed electronic structure evolution in this alloy system.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 15:25:52 GMT""}]","2018-03-13"
"1803.03826","Joa Weber","Urs Frauenfelder and Joa Weber","The shift map on Floer trajectory spaces","32 pages, 3 figures","J. Symplectic Geom. 19 no.2 (2021), 351-397","10.4310/JSG.2021.v19.n2.a2",,"math.SG math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we give a uniform proof why the shift map on Floer homology
trajectory spaces is scale smooth. This proof works for various Floer
homologies, periodic, Lagrangian, Hyperk\""ahler, elliptic or parabolic, and
uses Hilbert space valued Sobolev theory.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 15:31:20 GMT""}]","2022-10-20"
"1803.03827","Albert Gatt","Albert Gatt, Marc Tanti, Adrian Muscat, Patrizia Paggio, Reuben A.
  Farrugia, Claudia Borg, Kenneth P. Camilleri, Mike Rosner, Lonneke van der
  Plas","Face2Text: Collecting an Annotated Image Description Corpus for the
  Generation of Rich Face Descriptions","Proceedings of the 11th edition of the Language Resources and
  Evaluation Conference (LREC'18)",,,,"cs.CL cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The past few years have witnessed renewed interest in NLP tasks at the
interface between vision and language. One intensively-studied problem is that
of automatically generating text from images. In this paper, we extend this
problem to the more specific domain of face description. Unlike scene
descriptions, face descriptions are more fine-grained and rely on attributes
extracted from the image, rather than objects and relations. Given that no data
exists for this task, we present an ongoing crowdsourcing study to collect a
corpus of descriptions of face images taken `in the wild'. To gain a better
understanding of the variation we find in face description and the possible
issues that this may raise, we also conducted an annotation study on a subset
of the corpus. Primarily, we found descriptions to refer to a mixture of
attributes, not only physical, but also emotional and inferential, which is
bound to create further challenges for current image-to-text methods.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 15:52:08 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 07:32:51 GMT""}]","2021-03-08"
"1803.03828","Oluwarotimi Giwa","Oluwarotimi Giwa and Abdsamad Benkrid","Fire detection in a still image using colour information",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Colour analysis is a crucial step in image-based fire detection algorithms.
Many of the proposed fire detection algorithms in a still image are prone to
false alarms caused by objects with a colour similar to fire. To design a
colour-based system with a better false alarm rate, a new
colour-differentiating conversion matrix, efficient on images of high colour
complexity, is proposed. The elements of this conversion matrix are obtained by
performing K-medoids clustering and Particle Swarm Optimisation procedures on a
fire sample image with a background of high fire-colour similarity. The
proposed conversion matrix is then used to construct two new fire colour
detection frameworks. The first detection method is a two-stage non-linear
image transformation framework, while the second is a direct transformation of
an image with the proposed conversion matrix. A performance comparison of the
proposed methods with alternate methods in the literature was carried out.
Experimental results indicate that the linear image transformation method
outperforms other methods regarding false alarm rate while the non-linear
two-stage image transformation method has the best performance on the F-score
metric and provides a better trade-off between missed detection and false alarm
rate.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 15:52:46 GMT""}]","2018-03-13"
"1803.04407","Ming Gao","Yang-Yang Fei, Xiang-Dong Meng, Ming Gao, Hong Wang and Zhi Ma","Quantum man-in-the-middle attack on the calibration process of quantum
  key distribution","7 figures",,"10.1038/s41598-018-22700-3",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum key distribution (QKD) protocol has been proved to provide
unconditionally secure key between two remote legitimate users in theory. Key
distribution signals are transmitted in a quantum channel which is established
by the calibration process to meet the requirement of high count rate and low
error rate. All QKD security proofs implicitly assume that the quantum channel
has been established securely. However, the eavesdropper may attack the
calibration process to break the security assumption of QKD and provide
precondition to steal information about the final key successfully. Inspired by
N. Jain et al., Phys. Rev. Lett.107,110501(2011), we reveal the security risk
of the calibration process of a passive-basis-choice BB84 QKD system by
launching a quantum man-in-the-middle attack which intercepts all calibration
signals and resends faked ones. Large temporal bit-dependent or basis-dependent
detector efficiency mismatch can be induced. Then we propose a basis-dependent
detector efficiency mismatch (BEM) based faked states attack on a single photon
BB84 QKD to stress the threat of BEM. Moreover, the security of single photon
QKD systems with BEM is studied simply and intuitively. Two effective
countermeasures are suggested to remove the general security risk of the
calibration process.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:43:09 GMT""}]","2018-03-14"
"1803.04774","Rion Brattig Correia","Rion Brattig Correia and Alexander J. Gates and Xuan Wang and Luis M.
  Rocha","CANA: A python package for quantifying control and canalization in
  Boolean Networks","Submitted to the Systems Biology section of Frontiers in Physiology","Frontiers in Physiology, 9:1046, 2018","10.3389/fphys.2018.01046",,"cs.OH cs.CE cs.DM cs.SY q-bio.MN q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  Logical models offer a simple but powerful means to understand the complex
dynamics of biochemical regulation, without the need to estimate kinetic
parameters. However, even simple automata components can lead to collective
dynamics that are computationally intractable when aggregated into networks. In
previous work we demonstrated that automata network models of biochemical
regulation are highly canalizing, whereby many variable states and their
groupings are redundant (Marques-Pita and Rocha, 2013). The precise charting
and measurement of such canalization simplifies these models, making even very
large networks amenable to analysis. Moreover, canalization plays an important
role in the control, robustness, modularity and criticality of Boolean network
dynamics, especially those used to model biochemical regulation (Gates and
Rocha, 2016; Gates et al., 2016; Manicka, 2017). Here we describe a new
publicly-available Python package that provides the necessary tools to extract,
measure, and visualize canalizing redundancy present in Boolean network models.
It extracts the pathways most effective in controlling dynamics in these
models, including their effective graph and dynamics canalizing map, as well as
other tools to uncover minimum sets of control variables.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 20:07:52 GMT""},{""version"":""v2"",""created"":""Wed, 9 May 2018 18:15:06 GMT""}]","2018-08-30"
"1803.04779","Jaideep Pathak","Jaideep Pathak, Alexander Wikner, Rebeckah Fussell, Sarthak Chandra,
  Brian Hunt, Michelle Girvan, Edward Ott","Hybrid Forecasting of Chaotic Processes: Using Machine Learning in
  Conjunction with a Knowledge-Based Model",,,"10.1063/1.5028373",,"cs.LG nlin.CD stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A model-based approach to forecasting chaotic dynamical systems utilizes
knowledge of the physical processes governing the dynamics to build an
approximate mathematical model of the system. In contrast, machine learning
techniques have demonstrated promising results for forecasting chaotic systems
purely from past time series measurements of system state variables (training
data), without prior knowledge of the system dynamics. The motivation for this
paper is the potential of machine learning for filling in the gaps in our
underlying mechanistic knowledge that cause widely-used knowledge-based models
to be inaccurate. Thus we here propose a general method that leverages the
advantages of these two approaches by combining a knowledge-based model and a
machine learning technique to build a hybrid forecasting scheme. Potential
applications for such an approach are numerous (e.g., improving weather
forecasting). We demonstrate and test the utility of this approach using a
particular illustrative version of a machine learning known as reservoir
computing, and we apply the resulting hybrid forecaster to a low-dimensional
chaotic system, as well as to a high-dimensional spatiotemporal chaotic system.
These tests yield extremely promising results in that our hybrid technique is
able to accurately predict for a much longer period of time than either its
machine-learning component or its model-based component alone.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 21:02:25 GMT""}]","2018-05-09"
"1803.04793","Xiaohui Yang","Xiaohui Yang, Xiaoying Jiang, Wenming Wu, Juan Zhang, Dan Long, Funa
  Zhou, Yiming Xu","Low Rank Variation Dictionary and Inverse Projection Group Sparse
  Representation Model for Breast Tumor Classification","31 pages, 14 figures, 12 tables. arXiv admin note: text overlap with
  arXiv:1803.03562",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Sparse representation classification achieves good results by addressing
recognition problem with sufficient training samples per subject. However, SRC
performs not very well for small sample data. In this paper, an
inverse-projection group sparse representation model is presented for breast
tumor classification, which is based on constructing low-rank variation
dictionary. The proposed low-rank variation dictionary tackles tumor
recognition problem from the viewpoint of detecting and using variations in
gene expression profiles of normal and patients, rather than directly using
these samples. The inverse projection group sparsity representation model is
constructed based on taking full using of exist samples and group effect of
microarray gene data. Extensive experiments on public breast tumor microarray
gene expression datasets demonstrate the proposed technique is competitive with
state-of-the-art methods. The results of Breast-1, Breast-2 and Breast-3
databases are 80.81%, 89.10% and 100% respectively, which are better than the
latest literature.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 03:59:13 GMT""}]","2018-03-14"
"1803.04807","Silvano Simula","V. Lubicz, L. Riggio, G. Salerno, S. Simula, C. Tarantino","Tensor form factor of $D \to \pi(K) \ell \nu$ and $D \to \pi(K) \ell
  \ell$ decays with $N_f=2+1+1$ twisted-mass fermions","22 pages, 7 figures, 10 tables. Conclusions unchanged. Version to
  appear in PRD. arXiv admin note: text overlap with arXiv:1710.07121 and
  substantial text overlap with arXiv:1706.03017","Phys. Rev. D 98, 014516 (2018)","10.1103/PhysRevD.98.014516",,"hep-lat hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first lattice Nf=2+1+1 determination of the tensor form factor
$f_T^{D \pi(K)}(q^2)$ corresponding to the semileptonic and rare $D \to \pi(K)$
decays as a function of the squared 4-momentum transfer $q^2$. Together with
our recent determination of the vector and scalar form factors we complete the
set of hadronic matrix elements regulating the semileptonic and rare $D \to
\pi(K)$ transitions within and beyond the Standard Model, when a non-zero
tensor coupling is possible. Our analysis is based on the gauge configurations
produced by ETMC with Nf=2+1+1 flavors of dynamical quarks, which include in
the sea, besides two light mass-degenerate quarks, also the strange and charm
quarks with masses close to their physical values. We simulated at three
different values of the lattice spacing and with pion masses as small as 220
MeV. The matrix elements of the tensor current are determined for plenty of
kinematical conditions in which parent and child mesons are either moving or at
rest. As in the case of the vector and scalar form factors, Lorentz symmetry
breaking due to hypercubic effects is clearly observed also in the data for the
tensor form factor and included in the decomposition of the current matrix
elements in terms of additional form factors. After the extrapolations to the
physical pion mass and to the continuum and infinite volume limits we determine
the tensor form factor in the whole kinematical region accessible in the
experiments. A set of synthetic data points, representing our results for
$f_T^{D \pi(K)}(q^2)$ for several selected values of $q^2$, is provided and the
corresponding covariance matrix is also available. At zero four-momentum
transfer we get $f_T^{D \pi}(0) = 0.506 (79)$ and $f_T^{D K}(0) = 0.687 (54)$,
which correspond to $f_T^{D \pi}(0)/f_+^{D \pi}(0) = 0.827 (114)$ and $f_T^{D
K}(0)/f_+^{D K}(0)= 0.898 (50)$.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 11:55:33 GMT""},{""version"":""v2"",""created"":""Tue, 17 Jul 2018 16:22:24 GMT""}]","2018-08-08"
"1803.04864","Panagiotis Diamantoulakis","Panagiotis D. Diamantoulakis","Resource Allocation in Wireless Networks with Energy Constraints","Author's PhD Thesis",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This dissertation focuses on the development of novel scheduling and resource
allocation schemes, which take into account and regulate the energy constraints
imposed by the levels of harvested energy. To this direction, first, the
optimal energy, time, and bandwidth allocation problem for the downlink of
energy harvesting base stations (EHBSs) is investigated, with the main focus
being on autonomous EHBSs. The presented analysis considers the impact of the
energy constraint on users' preferences and the BS's revenue. In order to model
the competitive nature of the problem, game theory is used. The next two
chapters focus on wireless powered networks (WPNs) and simultaneous wireless
information and power transfer (SWIPT) using radio frequency (RF) technology.
One of the main contributions of these chapters is the introduction of both
uplink and downlink non-orthogonal multiple access (NOMA) for WPNs. Moreover,
the individual data rates and fairness are improved, while the formulated
problems are optimally and efficiently solved. It is shown that, compared to
orthogonal multiple access, NOMA offers a considerable improvement in
throughput, fairness, and energy efficiency. Rather than this, proportional
fairness is maximized and uplink/downlink of WPNs are jointly optimized, in
which cases, except for NOMA, time division multiple access (TDMA) is also
investigated. Furthermore, the role of interference is considered, which has
been recognized as one of the main reasons of the asymmetric overall
degradation of the users' performance, due to different path-loss values,
called from now on as cascaded near-far problem. Moreover, SWIPT is
investigated and efficiently optimized in the context of multicarrier
cooperative communication networks. Finally, simultaneous lightwave information
and power transfer (SLIPT) is introduced, while novel and fundamental
techniques are proposed.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 13:59:02 GMT""}]","2018-03-14"
"1803.05013","Thabet Abdeljawad","Raziye Mert, Thabet Abdeljawad, Allan Peterson","Sturm Liouville Equations in the frame of fractional operators with
  Mittag-Leffler kernels and their discrete versions",,,,,"math.CA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Very recently, some authors have studied new types of fractional derivatives
whose kernels are nonsingular. In this article, we study Sturm-Liouville
Equations ($SLEs$) in the frame of fractional operators with Mittag-Leffler
kernels. We formulate some Fractional Sturm-Liouville Problems ($FSLPs$) with
the diffferential part containing the left and right sided derivatives. We
investigate the self-adjointness, eigenvalue and eigenfunction properties of
the corresponding Fractional Sturm-Liouville Operators ($FSLOs$) by using
fractional integration by parts formulas. The nabla discrete version of our
results are also established.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 06:59:03 GMT""}]","2018-03-15"
"1803.05290","Ebrahim Karami","Ebrahim Karami and Savo Glisic","Optimization of Scheduling in Wireless Ad-Hoc Networks Using Matrix
  Games","5 pages, 4 figures, PIMRC2010. arXiv admin note: substantial text
  overlap with arXiv:1803.03736",,"10.1109/PIMRC.2010.5671633",,"cs.NI cs.GT eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a novel application of matrix game theory for
optimization of link scheduling in wireless ad-hoc networks. Optimum scheduling
is achieved by soft coloring of network graphs. Conventional coloring schemes
are based on assignment of one color to each region or equivalently each link
is member of just one partial topology. These algorithms based on coloring are
not optimal when links are not activated with the same rate. Soft coloring,
introduced in this paper, solves this problem and provide optimal solution for
any requested link usage rate. To define the game model for optimum scheduling,
first all possible components of the graph are identified. Components are
defined as sets of the wireless links can be activated simultaneously without
suffering from mutual interference. Then by switching between components with
appropriate frequencies (usage rate) optimum scheduling is achieved. We call
this kind of scheduling as soft coloring because any links can be member of
more than one partial topology, in different time segments. To simplify this
problem, we model relationship between link rates and components selection
frequencies by a matrix game which provides a simple and helpful tool to
simplify and solve the problem. This proposed game theoretic model is solved by
fictitious playing method. Simulation results prove the efficiency of the
proposed technique compared to conventional scheduling based on coloring
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 02:29:54 GMT""}]","2018-03-15"
"1803.05990","Muhammad Kamal Hossen","Muhammad Kamal Hossen, Md. Ali Faiad, Md. Shahnur Azad Chowdhury, and
  Md. Sajjatul Islam","Discovering Users Topic of Interest from Tweet",,"International Journal of Computer Science & Information Technology
  (IJCSIT) Vol 10, No 1, February 2018","10.5121/ijcsit.2018.10108",,"cs.CY cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays social media has become one of the largest gatherings of people in
online. There are many ways for the industries to promote their products to the
public through advertising. The variety of advertisement is increasing
dramatically. Businessmen are so much dependent on the advertisement that
significantly it really brought out success in the market and hence practiced
by major industries. Thus, companies are trying hard to draw the attention of
customers on social networks through online advertisement. One of the most
popular social media is Twitter which is popular for short text sharing named
Tweet. People here create their profile with basic information. To ensure the
advertisements are shown to relative people, Twitter targets people based on
language, gender, interest, follower, device, behavior, tailored audiences,
keyword, and geography targeting. Twitter generates interest sets based on
their activities on Twitter. What our framework does is that it determines the
topic of interest from a given list of Tweets if it has any. This process is
called Entity Intersect Categorizing Value (EICV). Each category topic
generates a set of words or phrases related to that topic. An entity set is
created from processing tweets by keyword generation and Twitters data using
Twitter API. Value of entities is matched with the set of categories. If they
cross a threshold value, it results in the category which matched the desired
interest category. For smaller amounts of data sizes, the results show that our
framework performs with higher accuracy rate.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 15:53:08 GMT""}]","2018-03-19"
"1803.06913","Anirban Nag","Anirban Nag, Ali Shafiee, Rajeev Balasubramonian, Vivek Srikumar and
  Naveen Muralimanohar","Newton: Gravitating Towards the Physical Limits of Crossbar Acceleration","13 pages with Appendix",,,,"cs.LG cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many recent works have designed accelerators for Convolutional Neural
Networks (CNNs). While digital accelerators have relied on near data
processing, analog accelerators have further reduced data movement by
performing in-situ computation. Recent works take advantage of highly parallel
analog in-situ computation in memristor crossbars to accelerate the many
vector-matrix multiplication operations in CNNs. However, these in-situ
accelerators have two significant short-comings that we address in this work.
First, the ADCs account for a large fraction of chip power and area. Second,
these accelerators adopt a homogeneous design where every resource is
provisioned for the worst case. By addressing both problems, the new
architecture, Newton, moves closer to achieving optimal energy-per-neuron for
crossbar accelerators.
  We introduce multiple new techniques that apply at different levels of the
tile hierarchy. Two of the techniques leverage heterogeneity: one adapts ADC
precision based on the requirements of every sub-computation (with zero impact
on accuracy), and the other designs tiles customized for convolutions or
classifiers. Two other techniques rely on divide-and-conquer numeric algorithms
to reduce computations and ADC pressure. Finally, we place constraints on how a
workload is mapped to tiles, thus helping reduce resource provisioning in
tiles. For a wide range of CNN dataflows and structures, Newton achieves a 77%
decrease in power, 51% improvement in energy efficiency, and 2.2x higher
throughput/area, relative to the state-of-the-art ISAAC accelerator.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 05:06:57 GMT""}]","2018-03-20"
"1803.09829","Nikolay Myagkov","V.A. Goloveshkin and N.N. Myagkov","Fragmentation model of a rapidly expanding ring with arbitrary
  cross-section","6 pages, 1 figure. arXiv admin note: text overlap with
  arXiv:1609.06963",,,,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the paper (Goloveshkin and Myagkov 2014) we proposed a two-dimensional
energy-based model of fragmentation of rapidly expanding cylinder under plane
strain conditions. The model allowed one to estimate the average fragment
length and the number of fragments produced by ductile fracture of the
cylinder. In present note we show that the proposed approach can be used to
estimate the number of fragments in a problem of fragmentation of a rapidly
expanding ring with arbitrary cross-section.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 04:03:24 GMT""}]","2018-03-28"
"1803.11440","Avi Mendelson","Ori Chalak, Cai Weiguang, Li Wei, Fang Lei, Zheng Libing, Wang
  Jintang, Wu Zuguang, Gu Xiongli, Wang Haibin, Avi Mendelson","ScaleSimulator: A Fast and Cycle-Accurate Parallel Simulator for
  Architectural Exploration","Was published in SIMUTools 2017
  https://drive.google.com/file/d/0B-bj84Yl7TM4R0NJRC16dnUxX0U/view",,,,"cs.DC cs.AR cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Design of next generation computer systems should be supported by simulation
infrastructure that must achieve a few contradictory goals such as fast
execution time, high accuracy, and enough flexibility to allow comparison
between large numbers of possible design points. Most existing architecture
level simulators are designed to be flexible and to execute the code in
parallel for greater efficiency, but at the cost of scarified accuracy. This
paper presents the ScaleSimulator simulation environment, which is based on a
new design methodology whose goal is to achieve near cycle accuracy while still
being flexible enough to simulate many different future system architectures
and efficient enough to run meaningful workloads. We achieve these goals by
making the parallelism a first-class citizen in our methodology. Thus, this
paper focuses mainly on the ScaleSimulator design points that enable better
parallel execution while maintaining the scalability and cycle accuracy of a
simulated architecture. The paper indicates that the new proposed
ScaleSimulator tool can (1) efficiently parallelize the execution of a
cycle-accurate architecture simulator, (2) efficiently simulate complex
architectures (e.g., out-of-order CPU pipeline, cache coherency protocol, and
network) and massive parallel systems, and (3) use meaningful workloads, such
as full simulation of OLTP benchmarks, to examine future architectural choices.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 18:20:20 GMT""}]","2018-04-02"
"1804.00701","Virendra Marathe","Virendra Marathe, Achin Mishra, Amee Trivedi, Yihe Huang, Faisal
  Zaghloul, Sanidhya Kashyap, Margo Seltzer, Tim Harris, Steve Byan, Bill
  Bridge, Dave Dice","Persistent Memory Transactions",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a comprehensive analysis of performance trade offs
between implementation choices for transaction runtime systems on persistent
memory. We compare three implementations of transaction runtimes: undo logging,
redo logging, and copy-on-write. We also present a memory allocator that plugs
into these runtimes. Our microbenchmark based evaluation focuses on
understanding the interplay between various factors that contribute to
performance differences between the three runtimes -- read/write access
patterns of workloads, size of the persistence domain (portion of the memory
hierarchy where the data is effectively persistent), cache locality, and
transaction runtime bookkeeping overheads. No single runtime emerges as a clear
winner. We confirm our analysis in more realistic settings of three ""real
world"" applications we developed with our transactional API: (i) a key-value
store we implemented from scratch, (ii) a SQLite port, and (iii) a persistified
version of memcached, a popular key-value store. These findings are not only
consistent with our microbenchmark analysis, but also provide additional
interesting insights into other factors (e.g. effects of multithreading and
synchronization) that affect application performance.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 22:46:42 GMT""}]","2018-04-04"
"1804.00702","Rodrigo Bruno","Rodrigo Bruno, Duarte Patr\'icio, Jos\'e Sim\~ao, Lu\'is Veiga and
  Paulo Ferreira","ROLP: Runtime Object Lifetime Profiling for Big Data Memory Management",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low latency services such as credit-card fraud detection and website targeted
advertisement rely on Big Data platforms (e.g., Lucene, Graphchi, Cassandra)
which run on top of memory managed runtimes, such as the JVM. These platforms,
however, suffer from unpredictable and unacceptably high pause times due to
inadequate memory management decisions (e.g., allocating objects with very
different lifetimes next to each other, resulting in memory fragmentation).
This leads to long and frequent application pause times, breaking Service Level
Agreements (SLAs). This problem has been previously identified and results show
that current memory management techniques are ill-suited for applications that
hold in memory massive amounts of middle to long-lived objects (which is the
case for a wide spectrum of Big Data applications).
  Previous works try to reduce such application pauses by allocating objects
off-heap or in special allocation regions/generations, thus alleviating the
pressure on memory management. However, all these solutions require a
combination of programmer effort and knowledge, source code access, or off-line
profiling, with clear negative impact on programmer productivity and/or
application performance.
  This paper presents ROLP, a runtime object lifetime profiling system. ROLP
profiles application code at runtime in order to identify which allocation
contexts create objects with middle to long lifetimes, given that such objects
need to be handled differently (regarding short-lived ones). This profiling
information greatly improves memory management decisions, leading to long tail
latencies reduction of up to 51% for Lucene, 85% for GraphChi, and 60% for
Cassandra, with negligible throughput and memory overhead. ROLP is implemented
for the OpenJDK 8 HotSpot JVM and it does not require any programmer effort or
source code access.
","[{""version"":""v1"",""created"":""Fri, 9 Mar 2018 16:53:44 GMT""}]","2018-04-04"
"1804.01842","Ashfaqul Anwar Siraji","Ashfaqul Anwar Siraji","Highly Sensitive and Robust Ultrahigh-Q Nanocavity on a
  Multiheterostructure Photonic Crystal","10 Pages, 10 Figures, 3 Tables",,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An ultrahigh-Q hybrid cavity using a graded multiheterostructure and space
modulation is designed in this work. Two high Q resonant modes exist in the
cavity and follow separate confinement mechanisms. We have demonstrated an
analytical method for designing the desired multiheterostructure. Space
modulation was used to create a robust and sensitive nanocavity. The
confinement mechanism and resonant characteristics of the resonant modes are
studied using the finite difference time domain method. We have shown that the
modes of the cavity are highly robust with respect to fabrication error. We
have also demonstrated that the nanocavity can act as a highly sensitive
refractive index sensor.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 12:47:49 GMT""}]","2018-04-06"
"1804.01843","Ashfaqul Anwar Siraji","Ashfaqul Anwar Siraji","Tunability of Planar Photonic Crystal Nanocavity: A Comparative study","Not intended for publication",,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A comparative study of the tunability of planar photonic crystal nanocavities
is done in this work. Three different types of cavities, e.g., defect cavity,
double heterostructure cavity and bandedge cavity are studied using finite
domain time domain method. Electrically tunable materials like Graphene and
ferroelectric BaTiO3 is used as the active materials. We found that high
quality factor cavities have lower tunability and greater loss in the material
leads to greater tunability.
","[{""version"":""v1"",""created"":""Sat, 10 Mar 2018 13:04:18 GMT""}]","2018-04-06"
